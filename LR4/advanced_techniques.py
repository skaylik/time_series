# advanced_techniques.py - –≠—Ç–∞–ø 8: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ (–ê–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ, –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤, —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è)

import pandas as pd
import numpy as np
import time
import warnings
warnings.filterwarnings('ignore')

import streamlit as st
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px

# –ë–∞–∑–æ–≤—ã–µ –∏–º–ø–æ—Ä—Ç—ã ML
from sklearn.ensemble import IsolationForest, RandomForestRegressor
from sklearn.cluster import KMeans
from sklearn.preprocessing import RobustScaler, StandardScaler
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.pipeline import Pipeline
from sklearn.model_selection import cross_val_score
from sklearn.metrics import mean_absolute_error, mean_squared_error

# –î–ª—è winsorization
from scipy.stats import mstats

# –î–ª—è –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
try:
    from sklearn.ensemble import StackingRegressor, VotingRegressor
    STACKING_AVAILABLE = True
except ImportError:
    STACKING_AVAILABLE = False

# –î–ª—è AutoGluon
try:
    from autogluon.tabular import TabularPredictor
    AUTOGLUON_AVAILABLE = True
except ImportError:
    AUTOGLUON_AVAILABLE = False

# ============================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ò–ù–¢–ï–ì–†–ê–¶–ò–ò
# ============================================================

def extract_best_models_from_previous_stages():
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–æ–≤"""
    
    best_models = {}
    model_predictions = {}
    
    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ 7 —ç—Ç–∞–ø–∞ (–æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞)
    if 'evaluation_results' in st.session_state:
        eval_results = st.session_state.evaluation_results
        ranked_df = eval_results.get('ranked_df')
        predictions = eval_results.get('predictions', {})
        
        if ranked_df is not None and not ranked_df.empty:
            # –ë–µ—Ä–µ–º —Ç–æ–ø-3 –º–æ–¥–µ–ª–∏
            top_models = ranked_df.head(3)['model'].tolist()
            
            for model_name in top_models:
                if model_name in predictions:
                    model_predictions[model_name] = predictions[model_name]
    
    # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ 5 —ç—Ç–∞–ø–∞ (–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è)
    elif 'integrated_results' in st.session_state:
        int_results = st.session_state.integrated_results
        integrated_df = int_results.get('integrated_df')
        
        if integrated_df is not None and not integrated_df.empty:
            # –ù–∞—Ö–æ–¥–∏–º –º–æ–¥–µ–ª—å —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º MAE
            if 'MAE' in integrated_df.columns:
                best_idx = integrated_df['MAE'].astype(float).idxmin()
                best_model = integrated_df.loc[best_idx]
                model_name = best_model.get('–ù–∞–∑–≤–∞–Ω–∏–µ', 'Best Model')
                
                # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã —Å–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫—É –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
                # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –ø—Ä–æ–≥–Ω–æ–∑—ã –º–æ–¥–µ–ª–µ–π
                model_predictions[model_name] = None
    
    # 3. –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ—Ç, –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    elif 'diagnostics_results' in st.session_state:
        diag_results = st.session_state.diagnostics_results
        best_model_info = diag_results.get('best_model_info', {})
        diagnostics = diag_results.get('diagnostics')
        
        if best_model_info and diagnostics:
            model_name = best_model_info.get('–ù–∞–∑–≤–∞–Ω–∏–µ', 'Diagnosed Model')
            if hasattr(diagnostics, 'y_test_pred'):
                model_predictions[model_name] = diagnostics.y_test_pred
    
    return model_predictions

def prepare_data_for_advanced_techniques():
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö —Ç–µ—Ö–Ω–∏–∫"""
    
    required_keys = ['df_features', 'feature_info', 'split_data']
    missing_keys = [key for key in required_keys if key not in st.session_state]
    
    if missing_keys:
        st.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ: {', '.join(missing_keys)}")
        return None, None, None, None, None
    
    feature_info = st.session_state.feature_info
    split_data = st.session_state.split_data
    df_features = st.session_state.df_features
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    date_col = feature_info['original_features'][0]
    target_col = feature_info['original_features'][1]
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    train_data = split_data['train'].copy()
    val_data = split_data['val'].copy()
    test_data = split_data['test'].copy()
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º train –∏ val –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    X_train_full = pd.concat([train_data, val_data], axis=0)
    
    # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
    feature_cols = []
    for col in X_train_full.columns:
        if col != date_col and col != target_col:
            if pd.api.types.is_numeric_dtype(X_train_full[col]):
                feature_cols.append(col)
    
    if not feature_cols:
        st.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        return None, None, None, None, None
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    X_train = X_train_full[feature_cols].copy()
    y_train = X_train_full[target_col].copy()
    
    X_test = test_data[feature_cols].copy()
    y_test = test_data[target_col].copy()
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
    X_train = X_train.fillna(X_train.median())
    X_test = X_test.fillna(X_train.median())
    y_train = y_train.fillna(y_train.median())
    y_test = y_test.fillna(y_test.median())
    
    return X_train, y_train, X_test, y_test, feature_cols

# ============================================================
# –ö–õ–ê–°–° –î–õ–Ø –ê–ù–°–ê–ú–ë–õ–ò–†–û–í–ê–ù–ò–Ø
# ============================================================

class AdvancedEnsembleTechniques:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö —Ç–µ—Ö–Ω–∏–∫ –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    def __init__(self, base_models=None):
        self.base_models = base_models if base_models else {}
        self.ensemble_models = {}
        self.ensemble_predictions = {}
        self.ensemble_weights = {}
    
    def weighted_average_ensemble(self, predictions_dict, y_true, method='mase'):
        """
        –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
        
        Parameters:
        -----------
        predictions_dict : dict
            –°–ª–æ–≤–∞—Ä—å {–∏–º—è –º–æ–¥–µ–ª–∏: –ø—Ä–æ–≥–Ω–æ–∑—ã}
        y_true : array-like
            –ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤–µ—Å–æ–≤
        method : str
            –ú–µ—Ç–æ–¥ —Ä–∞—Å—á–µ—Ç–∞ –≤–µ—Å–æ–≤: 'mase', 'mae', 'rmse', 'equal'
        """
        
        if not predictions_dict:
            return None, None
        
        model_names = list(predictions_dict.keys())
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
        metrics = {}
        for name, pred in predictions_dict.items():
            if pred is None or len(pred) == 0:
                metrics[name] = np.inf
                continue
            
            # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã
            min_len = min(len(y_true), len(pred))
            if min_len == 0:
                metrics[name] = np.inf
                continue
            
            y_true_trimmed = y_true[:min_len]
            y_pred_trimmed = pred[:min_len]
            
            if method == 'mase':
                # MASE —Ç—Ä–µ–±—É–µ—Ç –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö - –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
                mae = mean_absolute_error(y_true_trimmed, y_pred_trimmed)
                # –ü—Ä–æ—Å—Ç–∞—è –∞–ø–ø—Ä–æ–∫—Å–∏–º–∞—Ü–∏—è MASE
                if len(y_true_trimmed) > 1:
                    naive_error = mean_absolute_error(y_true_trimmed[1:], y_true_trimmed[:-1])
                    metric = mae / naive_error if naive_error != 0 else np.inf
                else:
                    metric = np.inf
            elif method == 'mae':
                metric = mean_absolute_error(y_true_trimmed, y_pred_trimmed)
            elif method == 'rmse':
                metric = np.sqrt(mean_squared_error(y_true_trimmed, y_pred_trimmed))
            elif method == 'equal':
                metric = 1.0  # –†–∞–≤–Ω—ã–µ –≤–µ—Å–∞
            else:
                metric = mean_absolute_error(y_true_trimmed, y_pred_trimmed)
            
            metrics[name] = metric
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ (–æ–±—Ä–∞—Ç–Ω–æ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –º–µ—Ç—Ä–∏–∫–µ)
        weights = {}
        if method == 'equal':
            # –†–∞–≤–Ω—ã–µ –≤–µ—Å–∞
            for name in model_names:
                weights[name] = 1.0 / len(model_names)
        else:
            # –í–µ—Å–∞, –æ–±—Ä–∞—Ç–Ω–æ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–µ
            total_inverse = sum(1.0 / max(metric, 1e-10) for metric in metrics.values())
            for name, metric in metrics.items():
                weights[name] = (1.0 / max(metric, 1e-10)) / total_inverse
        
        # –°–æ–∑–¥–∞–µ–º –≤–∑–≤–µ—à–µ–Ω–Ω—ã–π –∞–Ω—Å–∞–º–±–ª—å
        ensemble_pred = None
        
        for i, (name, pred) in enumerate(predictions_dict.items()):
            if pred is None or len(pred) == 0:
                continue
            
            weight = weights.get(name, 0)
            
            if ensemble_pred is None:
                ensemble_pred = pred * weight
            else:
                # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º –¥–ª–∏–Ω—ã
                min_len = min(len(ensemble_pred), len(pred))
                if min_len > 0:
                    ensemble_pred[:min_len] += pred[:min_len] * weight
        
        self.ensemble_weights['weighted_average'] = weights
        self.ensemble_predictions['weighted_average'] = ensemble_pred
        
        return ensemble_pred, weights
    
    def stacking_ensemble(self, X_train, y_train, X_test, base_models=None, meta_model=None):
        """
        Stacking –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ª–∏–Ω–µ–π–Ω–æ–π –º–µ—Ç–∞-–º–æ–¥–µ–ª—å—é
        
        Parameters:
        -----------
        X_train, y_train : –æ–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        X_test : —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        base_models : —Å–ø–∏—Å–æ–∫ –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π (–∏–º—è, –º–æ–¥–µ–ª—å)
        meta_model : –º–µ—Ç–∞-–º–æ–¥–µ–ª—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é Ridge)
        """
        
        if not STACKING_AVAILABLE:
            st.warning("StackingRegressor –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (—Ç—Ä–µ–±—É–µ—Ç—Å—è sklearn >= 0.22)")
            return None
        
        if base_models is None:
            base_models = self.base_models
        
        if not base_models:
            st.error("‚ùå –ù–µ—Ç –±–∞–∑–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è stacking")
            return None
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ª–æ–≤–∞—Ä—å –≤ —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π –¥–ª—è StackingRegressor
        estimators = []
        for name, model in base_models.items():
            if hasattr(model, 'predict'):
                estimators.append((name, model))
        
        if len(estimators) < 2:
            st.warning("–î–ª—è stacking –Ω—É–∂–Ω–æ —Ö–æ—Ç—è –±—ã 2 –º–æ–¥–µ–ª–∏")
            return None
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º Ridge –≤ –∫–∞—á–µ—Å—Ç–≤–µ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏
        if meta_model is None:
            meta_model = Ridge(alpha=1.0, random_state=42)
        
        # –°–æ–∑–¥–∞–µ–º stacking –∞–Ω—Å–∞–º–±–ª—å
        try:
            stacking_model = StackingRegressor(
                estimators=estimators,
                final_estimator=meta_model,
                cv=5,
                n_jobs=-1,
                passthrough=False
            )
            
            # –û–±—É—á–∞–µ–º stacking
            with st.spinner("–û–±—É—á–µ–Ω–∏–µ stacking –∞–Ω—Å–∞–º–±–ª—è..."):
                stacking_model.fit(X_train, y_train)
            
            # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º
            y_pred = stacking_model.predict(X_test)
            
            self.ensemble_models['stacking'] = stacking_model
            self.ensemble_predictions['stacking'] = y_pred
            
            return y_pred
            
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ stacking –∞–Ω—Å–∞–º–±–ª–µ: {str(e)}")
            return None
    
    def autogluon_weighted_ensemble(self, X_train, y_train, X_test, y_test, time_limit=60):
        """
        AutoGluon WeightedEnsemble (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
        """
        
        if not AUTOGLUON_AVAILABLE:
            st.warning("AutoGluon –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install autogluon")
            return None
        
        try:
            # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è AutoGluon
            train_data = pd.concat([X_train, y_train], axis=1)
            test_data = pd.concat([X_test, y_test], axis=1)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
            target_column = y_train.name
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å AutoGluon
            predictor = TabularPredictor(
                label=target_column,
                problem_type='regression',
                eval_metric='mean_absolute_error'
            )
            
            # –û–±—É—á–∞–µ–º —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
            with st.spinner(f"AutoGluon –æ–±—É—á–µ–Ω–∏–µ (–ª–∏–º–∏—Ç: {time_limit} —Å–µ–∫)..."):
                predictor.fit(
                    train_data=train_data,
                    tuning_data=test_data,
                    time_limit=time_limit,
                    presets=['medium_quality'],
                    use_bag_holdout=True,
                    verbosity=0
                )
            
            # –ü–æ–ª—É—á–∞–µ–º WeightedEnsemble –º–æ–¥–µ–ª—å (–æ–±—ã—á–Ω–æ —ç—Ç–æ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å)
            leaderboard = predictor.leaderboard(test_data, silent=True)
            
            # –ò—â–µ–º WeightedEnsemble –≤ –ª–∏–¥–µ—Ä–±–æ—Ä–¥–µ
            ensemble_model_name = None
            for model in leaderboard['model']:
                if 'WeightedEnsemble' in str(model) or 'ensemble' in str(model).lower():
                    ensemble_model_name = model
                    break
            
            if ensemble_model_name is None:
                # –ë–µ—Ä–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
                ensemble_model_name = leaderboard.iloc[0]['model']
            
            # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º
            y_pred = predictor.predict(test_data)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            self.ensemble_models['autogluon_ensemble'] = predictor
            self.ensemble_predictions['autogluon_ensemble'] = y_pred
            self.ensemble_weights['autogluon_ensemble'] = {
                'model_name': ensemble_model_name,
                'leaderboard': leaderboard
            }
            
            return y_pred
            
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ AutoGluon –∞–Ω—Å–∞–º–±–ª–µ: {str(e)}")
            return None

# ============================================================
# –ö–õ–ê–°–° –î–õ–Ø –û–ë–†–ê–ë–û–¢–ö–ò –í–´–ë–†–û–°–û–í
# ============================================================

class OutlierHandler:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã–±—Ä–æ—Å–æ–≤"""
    
    def __init__(self):
        self.isolation_forest = None
        self.scalers = {}
        self.outlier_stats = {}
    
    def isolation_forest_detection(self, X, contamination=0.1):
        """
        –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤ —Å –ø–æ–º–æ—â—å—é Isolation Forest
        
        Returns:
        --------
        outlier_mask : array-like
            –ú–∞—Å–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤ (True - –≤—ã–±—Ä–æ—Å)
        """
        
        iso_forest = IsolationForest(
            contamination=contamination,
            random_state=42,
            n_jobs=-1
        )
        
        outlier_mask = iso_forest.fit_predict(X) == -1
        
        self.isolation_forest = iso_forest
        self.outlier_stats['isolation_forest'] = {
            'contamination': contamination,
            'n_outliers': np.sum(outlier_mask),
            'outlier_percentage': np.mean(outlier_mask) * 100
        }
        
        return outlier_mask
    
    def apply_robust_scaling(self, X, with_scaling=False):
        """
        –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ RobustScaler (—É—Å—Ç–æ–π—á–∏–≤ –∫ –≤—ã–±—Ä–æ—Å–∞–º)
        
        Parameters:
        -----------
        X : –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
        with_scaling : bool, –µ—Å–ª–∏ True - –ø—Ä–∏–º–µ–Ω—è–µ—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
        
        Returns:
        --------
        X_scaled : –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        
        if with_scaling:
            robust_scaler = RobustScaler()
            X_scaled = robust_scaler.fit_transform(X)
            self.scalers['robust'] = robust_scaler
            return X_scaled
        else:
            # –ü—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            return X
    
    def winsorization(self, X, limits=(0.05, 0.05)):
        """
        Winsorization (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤)
        
        Parameters:
        -----------
        X : –¥–∞–Ω–Ω—ã–µ
        limits : tuple, –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª–∏ –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è (–Ω–∏–∂–Ω–∏–π, –≤–µ—Ä—Ö–Ω–∏–π)
        
        Returns:
        --------
        X_winsorized : –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ winsorization
        """
        
        X_winsorized = X.copy()
        
        if isinstance(X_winsorized, pd.DataFrame):
            for col in X_winsorized.columns:
                if pd.api.types.is_numeric_dtype(X_winsorized[col]):
                    try:
                        X_winsorized[col] = mstats.winsorize(
                            X_winsorized[col].values,
                            limits=limits
                        )
                    except:
                        pass
        elif isinstance(X_winsorized, np.ndarray):
            try:
                X_winsorized = mstats.winsorize(X_winsorized, limits=limits)
            except:
                pass
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self.outlier_stats['winsorization'] = {
            'limits': limits,
            'method': f'–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ {limits[0]*100}%/{limits[1]*100}%'
        }
        
        return X_winsorized
    
    def compare_scaling_methods(self, X, y):
        """
        –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
        """
        
        results = {}
        
        # 1. –ë–µ–∑ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
        results['no_scaling'] = {
            'X_mean': np.mean(X, axis=0),
            'X_std': np.std(X, axis=0)
        }
        
        # 2. StandardScaler
        standard_scaler = StandardScaler()
        X_standard = standard_scaler.fit_transform(X)
        results['standard_scaler'] = {
            'X_mean': np.mean(X_standard, axis=0),
            'X_std': np.std(X_standard, axis=0),
            'scaler': standard_scaler
        }
        
        # 3. RobustScaler
        robust_scaler = RobustScaler()
        X_robust = robust_scaler.fit_transform(X)
        results['robust_scaler'] = {
            'X_mean': np.mean(X_robust, axis=0),
            'X_std': np.std(X_robust, axis=0),
            'scaler': robust_scaler
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∫–∞–ª–µ—Ä—ã
        self.scalers['standard'] = standard_scaler
        self.scalers['robust'] = robust_scaler
        
        return results

# ============================================================
# –ö–õ–ê–°–° –î–õ–Ø –°–ï–ì–ú–ï–ù–¢–ê–¶–ò–ò
# ============================================================

class TimeSeriesSegmenter:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤"""
    
    def __init__(self):
        self.kmeans_model = None
        self.segments = {}
        self.segment_models = {}
    
    def kmeans_segmentation(self, X, n_clusters=3):
        """
        –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Ä—è–¥–æ–≤ —Å –ø–æ–º–æ—â—å—é KMeans
        """
        
        kmeans = KMeans(
            n_clusters=n_clusters,
            random_state=42,
            n_init=10
        )
        
        clusters = kmeans.fit_predict(X)
        self.kmeans_model = kmeans
        
        # –°–æ–∑–¥–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã
        segments = {}
        for cluster_id in range(n_clusters):
            segment_mask = clusters == cluster_id
            segment_indices = np.where(segment_mask)[0]
            
            if len(segment_indices) > 0:
                segments[cluster_id] = {
                    'indices': segment_indices,
                    'size': len(segment_indices),
                    'percentage': len(segment_indices) / len(X) * 100,
                    'features_mean': X[segment_mask].mean(axis=0) if len(X[segment_mask]) > 0 else None
                }
        
        self.segments['kmeans'] = segments
        
        return clusters, segments

    def seasonal_segmentation(self, dates, target_col):
        """
        –°–µ–∑–æ–Ω–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è (–∑–∏–º–∞/–ª–µ—Ç–æ –∏ —Ç.–¥.)
        """
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ dates –Ω–µ None –∏ –Ω–µ –ø—É—Å—Ç–æ–π
            if dates is None or len(dates) == 0:
                st.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–µ–∑–æ–Ω–Ω–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏")
                return {}
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º dates –≤ datetime –µ—Å–ª–∏ —ç—Ç–æ –µ—â–µ –Ω–µ —Å–¥–µ–ª–∞–Ω–æ
            if not isinstance(dates, pd.Series):
                dates = pd.Series(dates)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —É–∂–µ datetime
            if not pd.api.types.is_datetime64_any_dtype(dates):
                try:
                    dates = pd.to_datetime(dates, errors='coerce')
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–∞—Ç—ã: {str(e)}")
                    return {}
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
            if dates.isna().any():
                st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å {dates.isna().sum()} –¥–∞—Ç. –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–µ–∑–æ–Ω—ã
            seasons = {
                'winter': [12, 1, 2],   # –ó–∏–º–∞
                'spring': [3, 4, 5],     # –í–µ—Å–Ω–∞
                'summer': [6, 7, 8],     # –õ–µ—Ç–æ
                'autumn': [9, 10, 11]    # –û—Å–µ–Ω—å
            }
            
            # –°–æ–∑–¥–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã –ø–æ —Å–µ–∑–æ–Ω–∞–º
            seasonal_segments = {}
            
            for season_name, months in seasons.items():
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º dt.month –¥–ª—è Series —Å datetime
                    mask = dates.dt.month.isin(months)
                    
                    indices = np.where(mask)[0]
                    
                    if len(indices) > 0:
                        # –ü–æ–ª—É—á–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
                        if isinstance(target_col, pd.Series):
                            target_mean = target_col.iloc[indices].mean()
                        elif hasattr(target_col, '__getitem__'):
                            target_mean = np.mean(target_col[indices])
                        else:
                            target_mean = 0
                        
                        seasonal_segments[season_name] = {
                            'indices': indices.tolist(),
                            'size': len(indices),
                            'percentage': len(indices) / len(dates) * 100,
                            'months': months,
                            'target_mean': target_mean
                        }
                except Exception as e:
                    st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–µ–∑–æ–Ω–∞ {season_name}: {str(e)}")
                    continue
            
            self.segments['seasonal'] = seasonal_segments
            
            return seasonal_segments
            
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ —Å–µ–∑–æ–Ω–Ω–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: {str(e)}")
            return {}
    
    def regime_segmentation(self, values, n_regimes=2, method='percentile'):
        """
        –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ —Ä–µ–∂–∏–º–∞–º (–≤—ã—Å–æ–∫–∏–π/–Ω–∏–∑–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –∏ —Ç.–¥.)
        """
        
        if method == 'percentile':
            # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è–º
            percentiles = np.linspace(0, 100, n_regimes + 1)
            thresholds = np.percentile(values, percentiles[1:-1])
            
            regimes = np.digitize(values, thresholds)
        
        elif method == 'kmeans':
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º KMeans –¥–ª—è –∑–Ω–∞—á–µ–Ω–∏–π
            kmeans = KMeans(n_clusters=n_regimes, random_state=42)
            values_2d = values.reshape(-1, 1)
            regimes = kmeans.fit_predict(values_2d)
            thresholds = kmeans.cluster_centers_.flatten()
        
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –º–µ—Ç–æ–¥: {method}")
        
        # –°–æ–∑–¥–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã —Ä–µ–∂–∏–º–æ–≤
        regime_segments = {}
        for regime_id in range(n_regimes):
            mask = regimes == regime_id
            indices = np.where(mask)[0]
            
            if len(indices) > 0:
                regime_segments[regime_id] = {
                    'indices': indices,
                    'size': len(indices),
                    'percentage': len(indices) / len(values) * 100,
                    'value_mean': np.mean(values[indices]) if len(indices) > 0 else 0,
                    'value_std': np.std(values[indices]) if len(indices) > 0 else 0
                }
        
        self.segments['regime'] = regime_segments
        
        return regimes, regime_segments
    
    def train_segment_models(self, X, y, segments, segment_type='kmeans', base_model=None):
        """
        –û–±—É—á–µ–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
        """
        
        if base_model is None:
            from sklearn.linear_model import Ridge
            base_model = Ridge(alpha=1.0, random_state=42)
        
        segment_models = {}
        
        for segment_name, segment_info in segments.items():
            indices = segment_info['indices']
            
            if len(indices) < 10:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Å–µ–≥–º–µ–Ω—Ç–∞
                st.warning(f"–°–µ–≥–º–µ–Ω—Ç {segment_name} —Å–ª–∏—à–∫–æ–º –º–∞–ª ({len(indices)} samples)")
                continue
            
            # –í—ã–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞
            X_segment = X.iloc[indices] if hasattr(X, 'iloc') else X[indices]
            y_segment = y.iloc[indices] if hasattr(y, 'iloc') else y[indices]
            
            if len(X_segment) == 0 or len(y_segment) == 0:
                continue
            
            # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞
            model = base_model.__class__(**base_model.get_params())
            
            try:
                model.fit(X_segment, y_segment)
                segment_models[segment_name] = {
                    'model': model,
                    'indices': indices,
                    'size': len(indices),
                    'X_segment': X_segment,
                    'y_segment': y_segment
                }
            except Exception as e:
                st.warning(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞ {segment_name}: {str(e)}")
        
        self.segment_models[segment_type] = segment_models
        
        return segment_models
    
    def predict_with_segment_models(self, X_test, segment_models, segment_type='kmeans'):
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–µ–π —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        
        Parameters:
        -----------
        X_test : —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        segment_models : –æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        segment_type : —Ç–∏–ø —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        """
        
        if segment_type not in segment_models or not segment_models[segment_type]:
            return None, {}
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        y_pred = np.zeros(len(X_test)) * np.nan
        segment_predictions = {}
        
        # –ï—Å–ª–∏ —É –Ω–∞—Å –µ—Å—Ç—å KMeans –º–æ–¥–µ–ª—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if segment_type == 'kmeans' and hasattr(self, 'kmeans_model') and self.kmeans_model is not None:
            # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –∫–ª–∞—Å—Ç–µ—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            test_clusters = self.kmeans_model.predict(X_test)
            
            # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ (–∫–ª–∞—Å—Ç–µ—Ä–∞)
            for segment_name, segment_info in segment_models[segment_type].items():
                model = segment_info['model']
                cluster_id = int(segment_name)
                
                # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å—ã —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç —ç—Ç–æ–º—É –∫–ª–∞—Å—Ç–µ—Ä—É
                test_indices = np.where(test_clusters == cluster_id)[0]
                
                if len(test_indices) > 0:
                    try:
                        # –í—ã–±–∏—Ä–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç—Ç–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞
                        if hasattr(X_test, 'iloc'):
                            X_test_segment = X_test.iloc[test_indices]
                        else:
                            X_test_segment = X_test[test_indices]
                        
                        if len(X_test_segment) > 0:
                            segment_pred = model.predict(X_test_segment)
                            y_pred[test_indices] = segment_pred
                            segment_predictions[segment_name] = segment_pred
                    except Exception as e:
                        st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞ {segment_name}: {str(e)}")
        
        # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π –ø–æ–¥—Ö–æ–¥
        elif segment_type in ['seasonal', 'regime']:
            # –î–ª—è —Å–µ–∑–æ–Ω–Ω–æ–π –∏ —Ä–µ–∂–∏–º–Ω–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
            # –∏ —É—Å—Ä–µ–¥–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            all_predictions = []
            
            for segment_name, segment_info in segment_models[segment_type].items():
                model = segment_info['model']
                try:
                    segment_pred = model.predict(X_test)
                    all_predictions.append(segment_pred)
                    segment_predictions[segment_name] = segment_pred
                except Exception as e:
                    st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞ {segment_name}: {str(e)}")
            
            if all_predictions:
                # –£—Å—Ä–µ–¥–Ω—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
                y_pred = np.mean(all_predictions, axis=0)
        
        else:
            # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—É—é –º–æ–¥–µ–ª—å
            for segment_name, segment_info in segment_models[segment_type].items():
                model = segment_info['model']
                try:
                    y_pred = model.predict(X_test)
                    segment_predictions[segment_name] = y_pred
                    break  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—É—é –º–æ–¥–µ–ª—å
                except Exception as e:
                    st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞ {segment_name}: {str(e)}")
        
        # –ï—Å–ª–∏ –æ—Å—Ç–∞–ª–∏—Å—å NaN, –∑–∞–ø–æ–ª–Ω—è–µ–º —Å—Ä–µ–¥–Ω–∏–º –ø–æ –Ω–µ-NaN –∑–Ω–∞—á–µ–Ω–∏—è–º
        nan_mask = np.isnan(y_pred)
        if np.any(nan_mask):
            non_nan_values = y_pred[~nan_mask]
            if len(non_nan_values) > 0:
                mean_val = np.mean(non_nan_values)
                y_pred[nan_mask] = mean_val
            else:
                # –ï—Å–ª–∏ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è NaN, –∑–∞–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏
                y_pred[nan_mask] = 0
        
        return y_pred, segment_predictions

# ============================================================
# –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° –≠–¢–ê–ü–ê 8
# ============================================================

def show_advanced_techniques_interface():
    """–û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –≠—Ç–∞–ø–∞ 8: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏"""
    
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–æ–≤
    if 'df_features' not in st.session_state or 'feature_info' not in st.session_state:
        st.error("‚ùå –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≠—Ç–∞–ø—ã 1-2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö")
        return
    
    st.info("""
    **–¶–µ–ª—å –≠—Ç–∞–ø–∞ 8:**
    
    1. **–ê–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ:**
       - –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ (–ø–æ MASE)
       - Stacking —Å –ª–∏–Ω–µ–π–Ω–æ–π –º–µ—Ç–∞-–º–æ–¥–µ–ª—å—é
       - AutoGluon WeightedEnsemble
    
    2. **–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤:**
       - Isolation Forest –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
       - RobustScaler –≤–º–µ—Å—Ç–æ StandardScaler
       - Winsorization (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ 5%/95% –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—è–º–∏)
    
    3. **–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è:**
       - –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Ä—è–¥–æ–≤ (KMeans –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º)
       - –û—Ç–¥–µ–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ —Å–µ–∑–æ–Ω–∞–º (–∑–∏–º–∞/–ª–µ—Ç–æ)
       - –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ —Ä–µ–∂–∏–º–∞–º
    """)
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    with st.spinner("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
        result = prepare_data_for_advanced_techniques()
        
        if result[0] is None:
            return
        
        X_train, y_train, X_test, y_test, feature_cols = result
    
    st.success(f"""
    ‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã:
    - –û–±—É—á–∞—é—â–∏–µ: {X_train.shape[0]} –∑–∞–ø–∏—Å–µ–π, {X_train.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    - –¢–µ—Å—Ç–æ–≤—ã–µ: {X_test.shape[0]} –∑–∞–ø–∏—Å–µ–π
    """)
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞—Ç—ã –¥–ª—è —Å–µ–∑–æ–Ω–Ω–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
    if 'df_features' in st.session_state and 'feature_info' in st.session_state:
        feature_info = st.session_state.feature_info
        df_features = st.session_state.df_features
        
        date_col = feature_info['original_features'][0]
        
        # –ë–µ—Ä–µ–º –¥–∞—Ç—ã –∏–∑ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        train_data = st.session_state.split_data['train']
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–∞—Ç–æ–π
        if date_col in train_data.columns:
            dates = train_data[date_col]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö
            if not pd.api.types.is_datetime64_any_dtype(dates):
                try:
                    dates = pd.to_datetime(dates, errors='coerce')
                    st.success(f"‚úÖ –î–∞—Ç—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω—ã –≤ datetime")
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –¥–∞—Ç—ã: {str(e)}")
                    dates = None
        else:
            st.warning(f"‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ —Å –¥–∞—Ç–æ–π '{date_col}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
            dates = None
    else:
        dates = None
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑—ã –ª—É—á—à–∏—Ö –º–æ–¥–µ–ª–µ–π –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–æ–≤
    model_predictions = extract_best_models_from_previous_stages()
    
    if model_predictions:
        st.info(f"‚úÖ –ù–∞–π–¥–µ–Ω—ã –ø—Ä–æ–≥–Ω–æ–∑—ã {len(model_predictions)} –º–æ–¥–µ–ª–µ–π –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–æ–≤")
        st.write("**–ú–æ–¥–µ–ª–∏ –¥–ª—è –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è:**")
        for model_name in model_predictions.keys():
            st.write(f"- {model_name}")
    else:
        st.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω—ã –ø—Ä–æ–≥–Ω–æ–∑—ã –º–æ–¥–µ–ª–µ–π –¥–ª—è –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è")
    
    # –°–æ–∑–¥–∞–µ–º –≤–∫–ª–∞–¥–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–µ—Ö–Ω–∏–∫
    tab1, tab2, tab3 = st.tabs(["üéØ –ê–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ", "‚ö†Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤", "üìä –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è"])
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—ä–µ–∫—Ç—ã —Ç–µ—Ö–Ω–∏–∫
    ensemble_techniques = AdvancedEnsembleTechniques()
    outlier_handler = OutlierHandler()
    segmenter = TimeSeriesSegmenter()
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    comparison_results = {}
    
    # ============================================================
    # –í–ö–õ–ê–î–ö–ê 1: –ê–ù–°–ê–ú–ë–õ–ò–†–û–í–ê–ù–ò–ï
    # ============================================================
    
    with tab1:
        st.subheader("üéØ –ê–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
        
        col1, col2 = st.columns(2)
        
        with col1:
            include_weighted = st.checkbox("–í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ", value=True)
            if include_weighted:
                weight_method = st.selectbox(
                    "–ú–µ—Ç–æ–¥ —Ä–∞—Å—á–µ—Ç–∞ –≤–µ—Å–æ–≤:",
                    options=['mase', 'mae', 'rmse', 'equal'],
                    index=0,
                    help="–ú–µ—Ç–æ–¥ —Ä–∞—Å—á–µ—Ç–∞ –≤–µ—Å–æ–≤ –¥–ª—è –∞–Ω—Å–∞–º–±–ª—è"
                )
        
        with col2:
            include_stacking = st.checkbox("Stacking –∞–Ω—Å–∞–º–±–ª—å", value=STACKING_AVAILABLE and X_train is not None)
            include_autogluon = st.checkbox("AutoGluon –∞–Ω—Å–∞–º–±–ª—å", value=AUTOGLUON_AVAILABLE)
        
        st.markdown("---")
        
        # –ö–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
        if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ", key="ensemble_button"):
            
            with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ..."):
                
                # 1. –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ
                if include_weighted and model_predictions:
                    st.subheader("1. –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ")
                    
                    try:
                        # –ù—É–∂–Ω—ã —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤–µ—Å–æ–≤
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —á–∞—Å—Ç—å —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è "–≤–∞–ª–∏–¥–∞—Ü–∏–∏"
                        if len(y_test) > 0 and any(p is not None for p in model_predictions.values()):
                            # –ù–∞—Ö–æ–¥–∏–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
                            min_len = min(len(y_test), 
                                         *[len(p) for p in model_predictions.values() if p is not None])
                            
                            if min_len > 10:
                                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–µ 30% –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤–µ—Å–æ–≤
                                val_size = int(min_len * 0.3)
                                
                                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤–µ—Å–æ–≤
                                y_val = y_test[:val_size]
                                predictions_val = {}
                                
                                for name, pred in model_predictions.items():
                                    if pred is not None and len(pred) >= val_size:
                                        predictions_val[name] = pred[:val_size]
                                
                                if predictions_val:
                                    weighted_pred, weights = ensemble_techniques.weighted_average_ensemble(
                                        predictions_val, y_val, method=weight_method
                                    )
                                    
                                    if weighted_pred is not None:
                                        # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤–µ—Å—ã –∫–æ –≤—Å–µ–º –¥–∞–Ω–Ω—ã–º
                                        full_pred = None
                                        for name, pred in model_predictions.items():
                                            if pred is not None:
                                                weight = weights.get(name, 0)
                                                if full_pred is None:
                                                    full_pred = pred * weight
                                                else:
                                                    min_len_full = min(len(full_pred), len(pred))
                                                    if min_len_full > 0:
                                                        full_pred[:min_len_full] += pred[:min_len_full] * weight
                                        
                                        if full_pred is not None:
                                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                                            comparison_results['Weighted Average'] = {
                                                'predictions': full_pred,
                                                'weights': weights,
                                                'method': weight_method
                                            }
                                            
                                            st.success(f"‚úÖ –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ")
                                            st.write("**–í–µ—Å–∞ –º–æ–¥–µ–ª–µ–π:**")
                                            for name, weight in weights.items():
                                                st.write(f"- {name}: {weight:.3f}")
                                        else:
                                            st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤–∑–≤–µ—à–µ–Ω–Ω—ã–π –∞–Ω—Å–∞–º–±–ª—å")
                                    else:
                                        st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –≤–µ—Å–∞")
                                else:
                                    st.warning("–ù–µ—Ç –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤–µ—Å–æ–≤")
                            else:
                                st.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤–µ—Å–æ–≤")
                        else:
                            st.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∑–≤–µ—à–µ–Ω–Ω–æ–≥–æ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è")
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∑–≤–µ—à–µ–Ω–Ω–æ–≥–æ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏—è: {str(e)}")
                
                # 2. Stacking –∞–Ω—Å–∞–º–±–ª—å
                if include_stacking and X_train is not None and X_test is not None:
                    st.subheader("2. Stacking –∞–Ω—Å–∞–º–±–ª—å")
                    
                    # –ù—É–∂–Ω—ã –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è stacking
                    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—ã–µ –±–∞–∑–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                    from sklearn.linear_model import Ridge, Lasso
                    from sklearn.ensemble import RandomForestRegressor
                    
                    base_models = {
                        'Ridge': Ridge(alpha=1.0, random_state=42),
                        'Lasso': Lasso(alpha=0.1, random_state=42, max_iter=10000),
                        'RandomForest': RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)
                    }
                    
                    try:
                        stacking_pred = ensemble_techniques.stacking_ensemble(
                            X_train, y_train, X_test, base_models=base_models
                        )
                        
                        if stacking_pred is not None:
                            comparison_results['Stacking'] = {
                                'predictions': stacking_pred,
                                'base_models': list(base_models.keys())
                            }
                            st.success(f"‚úÖ Stacking –∞–Ω—Å–∞–º–±–ª—å —Å–æ–∑–¥–∞–Ω —Å {len(base_models)} –±–∞–∑–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏")
                        else:
                            st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å stacking –∞–Ω—Å–∞–º–±–ª—å")
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ stacking –∞–Ω—Å–∞–º–±–ª—è: {str(e)}")
                
                # 3. AutoGluon –∞–Ω—Å–∞–º–±–ª—å
                if include_autogluon:
                    st.subheader("3. AutoGluon WeightedEnsemble")
                    
                    try:
                        autogluon_pred = ensemble_techniques.autogluon_weighted_ensemble(
                            X_train, y_train, X_test, y_test, time_limit=60
                        )
                        
                        if autogluon_pred is not None:
                            comparison_results['AutoGluon Ensemble'] = {
                                'predictions': autogluon_pred,
                                'time_limit': 60
                            }
                            st.success("‚úÖ AutoGluon –∞–Ω—Å–∞–º–±–ª—å —Å–æ–∑–¥–∞–Ω")
                        else:
                            st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å AutoGluon –∞–Ω—Å–∞–º–±–ª—å")
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ AutoGluon –∞–Ω—Å–∞–º–±–ª—è: {str(e)}")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª–µ–π
                if comparison_results:
                    st.markdown("---")
                    st.subheader("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª–µ–π")
                    
                    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
                    metrics_data = []
                    for ensemble_name, ensemble_info in comparison_results.items():
                        pred = ensemble_info.get('predictions')
                        
                        if pred is not None and len(pred) > 0 and len(y_test) > 0:
                            min_len = min(len(pred), len(y_test))
                            if min_len > 0:
                                y_pred_trimmed = pred[:min_len]
                                y_true_trimmed = y_test[:min_len]
                                
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN
                                if np.isnan(y_pred_trimmed).any() or np.isnan(y_true_trimmed).any():
                                    # –£–¥–∞–ª—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è
                                    mask = ~np.isnan(y_pred_trimmed) & ~np.isnan(y_true_trimmed)
                                    if np.sum(mask) > 0:
                                        y_pred_clean = y_pred_trimmed[mask]
                                        y_true_clean = y_true_trimmed[mask]
                                        mae = mean_absolute_error(y_true_clean, y_pred_clean)
                                        rmse = np.sqrt(mean_squared_error(y_true_clean, y_pred_clean))
                                    else:
                                        mae = np.nan
                                        rmse = np.nan
                                else:
                                    mae = mean_absolute_error(y_true_trimmed, y_pred_trimmed)
                                    rmse = np.sqrt(mean_squared_error(y_true_trimmed, y_pred_trimmed))
                                
                                metrics_data.append({
                                    '–ê–Ω—Å–∞–º–±–ª—å': ensemble_name,
                                    'MAE': mae,
                                    'RMSE': rmse,
                                    '–î–ª–∏–Ω–∞': min_len
                                })
                    
                    if metrics_data:
                        metrics_df = pd.DataFrame(metrics_data)
                        
                        # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN
                        metrics_df = metrics_df.dropna()
                        
                        if not metrics_df.empty:
                            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ MAE
                            metrics_df = metrics_df.sort_values('MAE')
                            metrics_df['–†–∞–Ω–≥'] = range(1, len(metrics_df) + 1)
                            
                            st.dataframe(metrics_df, width='stretch')
                            
                            # –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                            fig = go.Figure()
                            
                            fig.add_trace(go.Bar(
                                x=metrics_df['–ê–Ω—Å–∞–º–±–ª—å'],
                                y=metrics_df['MAE'],
                                name='MAE',
                                marker_color='lightblue',
                                text=metrics_df['MAE'].round(4),
                                textposition='auto'
                            ))
                            
                            fig.update_layout(
                                title='–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª–µ–π –ø–æ MAE',
                                xaxis_title='–ê–Ω—Å–∞–º–±–ª—å',
                                yaxis_title='MAE',
                                height=400,
                                template='plotly_white'
                            )
                            
                            st.plotly_chart(fig, use_container_width=True)
                            
                            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª—É—á—à–∏–π –∞–Ω—Å–∞–º–±–ª—å
                            best_ensemble = metrics_df.iloc[0]
                            st.success(f"""
                            üèÜ **–õ—É—á—à–∏–π –∞–Ω—Å–∞–º–±–ª—å:** {best_ensemble['–ê–Ω—Å–∞–º–±–ª—å']}
                            - **MAE:** {best_ensemble['MAE']:.4f}
                            - **RMSE:** {best_ensemble['RMSE']:.4f}
                            - **–†–∞–Ω–≥:** {best_ensemble['–†–∞–Ω–≥']}
                            """)
                            
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à–∏–π –∞–Ω—Å–∞–º–±–ª—å
                            st.session_state.best_ensemble = {
                                'name': best_ensemble['–ê–Ω—Å–∞–º–±–ª—å'],
                                'predictions': comparison_results[best_ensemble['–ê–Ω—Å–∞–º–±–ª—å']]['predictions'],
                                'metrics': {
                                    'MAE': best_ensemble['MAE'],
                                    'RMSE': best_ensemble['RMSE']
                                }
                            }
                        else:
                            st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—á–∏—Å–ª–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π (–≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è NaN)")
                    else:
                        st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—á–∏—Å–ª–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∞–Ω—Å–∞–º–±–ª–µ–π")
                else:
                    st.warning("–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
    
    # ============================================================
    # –í–ö–õ–ê–î–ö–ê 2: –û–ë–†–ê–ë–û–¢–ö–ê –í–´–ë–†–û–°–û–í
    # ============================================================
    
    with tab2:
        st.subheader("‚ö†Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤")
        
        col1, col2 = st.columns(2)
        
        with col1:
            include_isolation = st.checkbox("Isolation Forest", value=True)
            if include_isolation:
                contamination = st.slider(
                    "Contamination (–¥–æ–ª—è –≤—ã–±—Ä–æ—Å–æ–≤):",
                    min_value=0.01,
                    max_value=0.5,
                    value=0.1,
                    step=0.01,
                    help="–û–∂–∏–¥–∞–µ–º–∞—è –¥–æ–ª—è –≤—ã–±—Ä–æ—Å–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö"
                )
        
        with col2:
            include_robust = st.checkbox("RobustScaler", value=True)
            include_winsor = st.checkbox("Winsorization", value=True)
            if include_winsor:
                lower_limit = st.slider("–ù–∏–∂–Ω–∏–π –ª–∏–º–∏—Ç (%)", 0, 10, 5, 1) / 100
                upper_limit = st.slider("–í–µ—Ä—Ö–Ω–∏–π –ª–∏–º–∏—Ç (%)", 90, 100, 95, 1) / 100
        
        st.markdown("---")
        
        if st.button("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –≤—ã–±—Ä–æ—Å—ã", key="outlier_button"):
            
            with st.spinner("–ê–Ω–∞–ª–∏–∑ –≤—ã–±—Ä–æ—Å–æ–≤..."):
                
                # 1. –ê–Ω–∞–ª–∏–∑ –≤—ã–±—Ä–æ—Å–æ–≤
                st.subheader("1. –ê–Ω–∞–ª–∏–∑ –≤—ã–±—Ä–æ—Å–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö")
                
                # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                fig_outliers = make_subplots(
                    rows=2, cols=3,
                    subplot_titles=['–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π', 
                                   '–ë–æ–∫—Å–ø–ª–æ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤', 
                                   '–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞',
                                   '–î–∏–∞–≥—Ä–∞–º–º–∞ —Ä–∞—Å—Å–µ—è–Ω–∏—è',
                                   '–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤',
                                   'Q-Q plot'],
                    specs=[[{'type': 'histogram'}, {'type': 'box'}, {'type': 'heatmap'}],
                           [{'type': 'scatter'}, {'type': 'histogram'}, {'type': 'scatter'}]],
                    vertical_spacing=0.1,
                    horizontal_spacing=0.1
                )
                
                # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
                fig_outliers.add_trace(
                    go.Histogram(
                        x=y_train,
                        name='–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è',
                        nbinsx=50,
                        marker_color='lightblue',
                        opacity=0.7
                    ),
                    row=1, col=1
                )
                
                # –ë–æ–∫—Å–ø–ª–æ—Ç –¥–ª—è —Ç–æ–ø-5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                top_features = feature_cols[:5] if len(feature_cols) >= 5 else feature_cols
                for i, feature in enumerate(top_features):
                    fig_outliers.add_trace(
                        go.Box(
                            y=X_train[feature].values,
                            name=feature,
                            marker_color=px.colors.qualitative.Set1[i % len(px.colors.qualitative.Set1)],
                            showlegend=False
                        ),
                        row=1, col=2
                    )
                
                fig_outliers.update_layout(
                    height=600,
                    title_text="–ê–Ω–∞–ª–∏–∑ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏ –≤—ã–±—Ä–æ—Å–æ–≤",
                    title_x=0.5,
                    showlegend=False,
                    template='plotly_white'
                )
                
                st.plotly_chart(fig_outliers, use_container_width=True)
                
                # 2. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã–±—Ä–æ—Å–æ–≤
                st.subheader("2. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                
                # Isolation Forest
                if include_isolation and X_train is not None:
                    outlier_mask = outlier_handler.isolation_forest_detection(
                        X_train, contamination=contamination
                    )
                    
                    st.info(f"""
                    **Isolation Forest:**
                    - –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –≤—ã–±—Ä–æ—Å–æ–≤: {np.sum(outlier_mask)} ({np.mean(outlier_mask)*100:.1f}%)
                    - Contamination: {contamination}
                    - –ß–∏—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ: {np.sum(~outlier_mask)} –∑–∞–ø–∏—Å–µ–π
                    """)
                
                # RobustScaler
                if include_robust and X_train is not None:
                    scaling_results = outlier_handler.compare_scaling_methods(X_train, y_train)
                    
                    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
                    fig_scaling = go.Figure()
                    
                    methods = ['no_scaling', 'standard_scaler', 'robust_scaler']
                    method_names = ['–ë–µ–∑ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è', 'StandardScaler', 'RobustScaler']
                    
                    for i, (method, method_name) in enumerate(zip(methods, method_names)):
                        if method in scaling_results:
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –ø—Ä–∏–∑–Ω–∞–∫ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                            if i == 0:
                                data = X_train.iloc[:, 0] if hasattr(X_train, 'iloc') else X_train[:, 0]
                            else:
                                # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
                                scaler = scaling_results[method]['scaler']
                                data_scaled = scaler.transform(X_train)
                                data = data_scaled[:, 0]
                            
                            fig_scaling.add_trace(go.Box(
                                y=data,
                                name=method_name,
                                marker_color=px.colors.qualitative.Set1[i]
                            ))
                    
                    fig_scaling.update_layout(
                        title='–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è',
                        yaxis_title='–ó–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞ (–º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ)',
                        height=400,
                        template='plotly_white'
                    )
                    
                    st.plotly_chart(fig_scaling, use_container_width=True)
                    
                    st.info("""
                    **RobustScaler vs StandardScaler:**
                    - **RobustScaler:** –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–µ–¥–∏–∞–Ω—É –∏ –º–µ–∂–∫–≤–∞—Ä—Ç–∏–ª—å–Ω—ã–π —Ä–∞–∑–º–∞—Ö, —É—Å—Ç–æ–π—á–∏–≤ –∫ –≤—ã–±—Ä–æ—Å–∞–º
                    - **StandardScaler:** –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—Ä–µ–¥–Ω–µ–µ –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ, —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –≤—ã–±—Ä–æ—Å–∞–º
                    - **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –î–ª—è –¥–∞–Ω–Ω—ã—Ö —Å –≤—ã–±—Ä–æ—Å–∞–º–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ RobustScaler
                    """)
                
                # Winsorization
                if include_winsor and X_train is not None:
                    X_winsorized = outlier_handler.winsorization(
                        X_train, limits=(lower_limit, upper_limit)
                    )
                    
                    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–æ –∏ –ø–æ—Å–ª–µ
                    fig_winsor = go.Figure()
                    
                    # –î–æ winsorization
                    fig_winsor.add_trace(go.Histogram(
                        x=X_train.iloc[:, 0] if hasattr(X_train, 'iloc') else X_train[:, 0],
                        name='–î–æ winsorization',
                        opacity=0.7,
                        marker_color='red'
                    ))
                    
                    # –ü–æ—Å–ª–µ winsorization
                    fig_winsor.add_trace(go.Histogram(
                        x=X_winsorized.iloc[:, 0] if hasattr(X_winsorized, 'iloc') else X_winsorized[:, 0],
                        name='–ü–æ—Å–ª–µ winsorization',
                        opacity=0.7,
                        marker_color='blue'
                    ))
                    
                    fig_winsor.update_layout(
                        title=f'Winsorization: –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ {lower_limit*100}%/{upper_limit*100}%',
                        xaxis_title='–ó–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞',
                        yaxis_title='–ß–∞—Å—Ç–æ—Ç–∞',
                        barmode='overlay',
                        height=400,
                        template='plotly_white'
                    )
                    
                    st.plotly_chart(fig_winsor, use_container_width=True)
                    
                    st.info(f"""
                    **Winsorization:**
                    - **–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:** {lower_limit*100:.1f}% (–Ω–∏–∂–Ω–∏–π), {upper_limit*100:.1f}% (–≤–µ—Ä—Ö–Ω–∏–π)
                    - **–≠—Ñ—Ñ–µ–∫—Ç:** –ö—Ä–∞–π–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∑–∞–º–µ–Ω—è—é—Ç—Å—è –Ω–∞ –∑–Ω–∞—á–µ–Ω–∏—è –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª–µ–π
                    - **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ:** –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏, —É–º–µ–Ω—å—à–∞–µ—Ç –≤–ª–∏—è–Ω–∏–µ –≤—ã–±—Ä–æ—Å–æ–≤
                    """)
                
                st.success("‚úÖ –ê–Ω–∞–ª–∏–∑ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω—ã")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±—Ä–æ—Å–æ–≤
                st.session_state.outlier_handler = outlier_handler
    
    # ============================================================
    # –í–ö–õ–ê–î–ö–ê 3: –°–ï–ì–ú–ï–ù–¢–ê–¶–ò–Ø
    # ============================================================
    
    with tab3:
        st.subheader("üìä –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        if 'segmentation_state' not in st.session_state:
            st.session_state.segmentation_state = {
                'results': {},
                'segmenter': TimeSeriesSegmenter(),
                'last_updated': None
            }
        
        col1, col2 = st.columns(2)
        
        with col1:
            include_kmeans = st.checkbox("KMeans –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è", value=True)
            if include_kmeans:
                n_clusters = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤", 2, 10, 3, 1)
        
        with col2:
            include_seasonal = st.checkbox("–°–µ–∑–æ–Ω–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è", value=dates is not None)
            include_regime = st.checkbox("–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ —Ä–µ–∂–∏–º–∞–º", value=True)
            if include_regime:
                n_regimes = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∂–∏–º–æ–≤", 2, 5, 2, 1)
                regime_method = st.selectbox("–ú–µ—Ç–æ–¥ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏", ['percentile', 'kmeans'], index=0)
        
        st.markdown("---")
        
        # –ö–Ω–æ–ø–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        if st.button("üéØ –í—ã–ø–æ–ª–Ω–∏—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é", key="segmentation_button"):
            
            with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è..."):
                
                segmentation_results = {}
                
                # 1. KMeans –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
                if include_kmeans and X_train is not None:
                    st.subheader("1. KMeans –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º")
                    
                    clusters, segments = st.session_state.segmentation_state['segmenter'].kmeans_segmentation(
                        X_train, n_clusters=n_clusters
                    )
                    
                    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
                    if len(feature_cols) >= 2:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º PCA –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ 2D
                        from sklearn.decomposition import PCA
                        
                        pca = PCA(n_components=2, random_state=42)
                        X_pca = pca.fit_transform(X_train)
                        
                        fig_clusters = go.Figure()
                        
                        for cluster_id in range(n_clusters):
                            mask = clusters == cluster_id
                            if np.any(mask):
                                fig_clusters.add_trace(go.Scatter(
                                    x=X_pca[mask, 0],
                                    y=X_pca[mask, 1],
                                    mode='markers',
                                    name=f'–ö–ª–∞—Å—Ç–µ—Ä {cluster_id}',
                                    marker=dict(
                                        size=8,
                                        opacity=0.7,
                                        color=px.colors.qualitative.Set1[cluster_id % len(px.colors.qualitative.Set1)]
                                    )
                                ))
                        
                        fig_clusters.update_layout(
                            title='KMeans –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è (PCA –ø—Ä–æ–µ–∫—Ü–∏—è)',
                            xaxis_title='–ì–ª–∞–≤–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1',
                            yaxis_title='–ì–ª–∞–≤–Ω–∞—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2',
                            height=500,
                            template='plotly_white'
                        )
                        
                        st.plotly_chart(fig_clusters, use_container_width=True)
                    
                    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–µ–≥–º–µ–Ω—Ç–∞—Ö
                    st.write("**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤:**")
                    kmeans_stats = []
                    for cluster_id, segment_info in segments.items():
                        kmeans_stats.append({
                            '–ö–ª–∞—Å—Ç–µ—Ä': cluster_id,
                            '–†–∞–∑–º–µ—Ä': segment_info['size'],
                            '–ü—Ä–æ—Ü–µ–Ω—Ç': f"{segment_info['percentage']:.1f}%",
                            '–°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤': f"{segment_info['features_mean'].mean():.4f}" if segment_info['features_mean'] is not None else 'N/A'
                        })
                    
                    if kmeans_stats:
                        st.dataframe(pd.DataFrame(kmeans_stats), width='stretch')
                    
                    segmentation_results['kmeans'] = {
                        'clusters': clusters,
                        'segments': segments,
                        'n_clusters': n_clusters
                    }
                
                # 2. –°–µ–∑–æ–Ω–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è
                if include_seasonal and dates is not None:
                    st.subheader("2. –°–µ–∑–æ–Ω–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è")
                    
                    try:
                        seasonal_segments = st.session_state.segmentation_state['segmenter'].seasonal_segmentation(
                            dates, y_train
                        )
                        
                        if seasonal_segments:
                            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ–∑–æ–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                            fig_seasons = go.Figure()
                            
                            seasons = list(seasonal_segments.keys())
                            season_means = []
                            season_sizes = []
                            
                            for season_name, segment_info in seasonal_segments.items():
                                if 'target_mean' in segment_info and segment_info['target_mean'] is not None:
                                    season_means.append(segment_info['target_mean'])
                                    season_sizes.append(segment_info['size'])
                                    
                                    fig_seasons.add_trace(go.Bar(
                                        x=[season_name],
                                        y=[segment_info['target_mean']],
                                        name=season_name,
                                        text=[f"{segment_info['percentage']:.1f}% ({segment_info['size']} –∑–∞–ø.)"],
                                        textposition='auto',
                                        marker_color=px.colors.qualitative.Set1[seasons.index(season_name) % len(px.colors.qualitative.Set1)],
                                        hovertemplate=(
                                            f"–°–µ–∑–æ–Ω: {season_name}<br>" +
                                            f"–°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {segment_info['target_mean']:.4f}<br>" +
                                            f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π: {segment_info['size']}<br>" +
                                            f"–ü—Ä–æ—Ü–µ–Ω—Ç –æ—Ç –æ–±—â–µ–≥–æ: {segment_info['percentage']:.1f}%<br>" +
                                            f"–ú–µ—Å—è—Ü—ã: {segment_info['months']}"
                                        )
                                    ))
                            
                            fig_seasons.update_layout(
                                title='–°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –ø–æ —Å–µ–∑–æ–Ω–∞–º',
                                xaxis_title='–°–µ–∑–æ–Ω',
                                yaxis_title='–°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ',
                                height=400,
                                template='plotly_white'
                            )
                            
                            st.plotly_chart(fig_seasons, use_container_width=True)
                            
                            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–µ–∑–æ–Ω–∞—Ö
                            st.write("**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–µ–∑–æ–Ω–æ–≤:**")
                            seasonal_stats = []
                            for season_name, segment_info in seasonal_segments.items():
                                seasonal_stats.append({
                                    '–°–µ–∑–æ–Ω': season_name,
                                    '–†–∞–∑–º–µ—Ä': segment_info['size'],
                                    '–ü—Ä–æ—Ü–µ–Ω—Ç': f"{segment_info['percentage']:.1f}%",
                                    '–°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ': f"{segment_info.get('target_mean', 0):.4f}",
                                    '–ú–µ—Å—è—Ü—ã': segment_info['months']
                                })
                            
                            if seasonal_stats:
                                st.dataframe(pd.DataFrame(seasonal_stats), width='stretch')
                            
                            segmentation_results['seasonal'] = seasonal_segments
                        else:
                            st.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Å–µ–∑–æ–Ω–Ω—É—é —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é. –í–æ–∑–º–æ–∂–Ω–æ, –ø—Ä–æ–±–ª–µ–º–∞ —Å —Ñ–æ—Ä–º–∞—Ç–æ–º –¥–∞—Ç.")
                            
                    except Exception as e:
                        st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ —Å–µ–∑–æ–Ω–Ω–æ–π —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: {str(e)}")
                
                # 3. –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ —Ä–µ–∂–∏–º–∞–º
                if include_regime and y_train is not None:
                    st.subheader("3. –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ —Ä–µ–∂–∏–º–∞–º (–∑–Ω–∞—á–µ–Ω–∏—è–º)")
                    
                    regimes, regime_segments = st.session_state.segmentation_state['segmenter'].regime_segmentation(
                        y_train.values, n_regimes=n_regimes, method=regime_method
                    )
                    
                    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∂–∏–º–æ–≤
                    fig_regimes = go.Figure()
                    
                    time_index = list(range(len(y_train)))
                    
                    for regime_id in range(n_regimes):
                        mask = regimes == regime_id
                        if np.any(mask):
                            fig_regimes.add_trace(go.Scatter(
                                x=np.array(time_index)[mask],
                                y=y_train.values[mask],
                                mode='markers',
                                name=f'–†–µ–∂–∏–º {regime_id}',
                                marker=dict(
                                    size=6,
                                    opacity=0.7,
                                    color=px.colors.qualitative.Set1[regime_id % len(px.colors.qualitative.Set1)]
                                )
                            ))
                    
                    fig_regimes.update_layout(
                        title=f'–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ —Ä–µ–∂–∏–º–∞–º ({n_regimes} —Ä–µ–∂–∏–º–∞)',
                        xaxis_title='–í—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω–¥–µ–∫—Å',
                        yaxis_title='–ó–Ω–∞—á–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π',
                        height=400,
                        template='plotly_white'
                    )
                    
                    st.plotly_chart(fig_regimes, use_container_width=True)
                    
                    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–µ–∂–∏–º–∞—Ö
                    st.write("**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–µ–∂–∏–º–æ–≤:**")
                    regime_stats = []
                    for regime_id, segment_info in regime_segments.items():
                        regime_stats.append({
                            '–†–µ–∂–∏–º': regime_id,
                            '–†–∞–∑–º–µ—Ä': segment_info['size'],
                            '–ü—Ä–æ—Ü–µ–Ω—Ç': f"{segment_info['percentage']:.1f}%",
                            '–°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ': f"{segment_info['value_mean']:.4f}",
                            '–°—Ç–¥. –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ': f"{segment_info['value_std']:.4f}"
                        })
                    
                    if regime_stats:
                        st.dataframe(pd.DataFrame(regime_stats), width='stretch')
                    
                    segmentation_results['regime'] = {
                        'regimes': regimes,
                        'segments': regime_segments,
                        'n_regimes': n_regimes,
                        'method': regime_method
                    }
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤ session_state
                if segmentation_results:
                    st.session_state.segmentation_state['results'] = segmentation_results
                    st.session_state.segmentation_state['last_updated'] = time.time()
                    st.session_state.segmentation_state['X_train'] = X_train
                    st.session_state.segmentation_state['y_train'] = y_train
                    st.session_state.segmentation_state['X_test'] = X_test
                    st.session_state.segmentation_state['y_test'] = y_test
                    
                    st.success(f"‚úÖ –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∞. –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(segmentation_results)} —Ç–∏–ø–æ–≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏.")
                else:
                    st.warning("‚ö†Ô∏è –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è.")
        
        # –†–∞–∑–¥–µ–ª –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ö
        st.markdown("---")
        st.subheader("üéØ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏
        if st.session_state.segmentation_state['results']:
            available_segmentations = list(st.session_state.segmentation_state['results'].keys())
            
            if available_segmentations:
                # –í—ã–±–æ—Ä —Ç–∏–ø–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
                segment_type_to_use = st.selectbox(
                    "–¢–∏–ø —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π:",
                    options=available_segmentations,
                    index=0,
                    key="segment_type_select"
                )
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
                col1, col2 = st.columns(2)
                with col1:
                    use_ridge = st.checkbox("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Ridge —Ä–µ–≥—Ä–µ—Å—Å–∏—é", value=True)
                with col2:
                    if use_ridge:
                        alpha_value = st.slider("Alpha (—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è)", 0.1, 10.0, 1.0, 0.1)
                
                # –ö–Ω–æ–ø–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
                if st.button("üèãÔ∏è –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤", key="train_segment_models"):
                    
                    with st.spinner("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤..."):
                        
                        # –ü–æ–ª—É—á–∞–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                        segmentation_results = st.session_state.segmentation_state['results']
                        segmenter = st.session_state.segmentation_state['segmenter']
                        
                        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                        X_train_local = st.session_state.segmentation_state.get('X_train', X_train)
                        y_train_local = st.session_state.segmentation_state.get('y_train', y_train)
                        X_test_local = st.session_state.segmentation_state.get('X_test', X_test)
                        y_test_local = st.session_state.segmentation_state.get('y_test', y_test)
                        
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞
                        if segment_type_to_use == 'kmeans':
                            segments = segmentation_results['kmeans']['segments']
                        elif segment_type_to_use == 'seasonal':
                            segments = segmentation_results['seasonal']
                        elif segment_type_to_use == 'regime':
                            segments = segmentation_results['regime']['segments']
                        else:
                            st.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: {segment_type_to_use}")
                            segments = {}
                        
                        # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å
                        if use_ridge:
                            from sklearn.linear_model import Ridge
                            base_model = Ridge(alpha=alpha_value, random_state=42)
                        else:
                            from sklearn.linear_model import LinearRegression
                            base_model = LinearRegression()
                        
                        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                        segment_models = segmenter.train_segment_models(
                            X_train_local, y_train_local, segments, 
                            segment_type=segment_type_to_use,
                            base_model=base_model
                        )
                        
                        if segment_models:
                            st.success(f"‚úÖ –û–±—É—á–µ–Ω–æ {len(segment_models)} –º–æ–¥–µ–ª–µ–π –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
                            
                            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª–∏ –≤ session_state
                            if 'segment_models' not in st.session_state:
                                st.session_state.segment_models = {}
                            
                            st.session_state.segment_models[segment_type_to_use] = {
                                'models': segment_models,
                                'segment_type': segment_type_to_use,
                                'base_model': type(base_model).__name__,
                                'timestamp': time.time()
                            }
                            
                            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª—è—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                            st.write("**–î–µ—Ç–∞–ª–∏ –º–æ–¥–µ–ª–µ–π —Å–µ–≥–º–µ–Ω—Ç–æ–≤:**")
                            
                            model_stats = []
                            for segment_name, model_info in segment_models.items():
                                model = model_info['model']
                                
                                # –í—ã—á–∏—Å–ª—è–µ–º R¬≤ –Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
                                X_seg = model_info['X_segment']
                                y_seg = model_info['y_segment']
                                r2_score = model.score(X_seg, y_seg) if len(X_seg) > 0 else 0
                                
                                model_stats.append({
                                    '–°–µ–≥–º–µ–Ω—Ç': segment_name,
                                    '–†–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏': model_info['size'],
                                    '–¢–∏–ø –º–æ–¥–µ–ª–∏': type(model).__name__,
                                    'R¬≤ –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏': f"{r2_score:.4f}",
                                    '–ü–∞—Ä–∞–º–µ—Ç—Ä—ã': str(model.get_params())[:50] + '...'
                                })
                            
                            if model_stats:
                                stats_df = pd.DataFrame(model_stats)
                                st.dataframe(stats_df, width='stretch')
                                
                                # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π
                                fig_quality = go.Figure()
                                
                                fig_quality.add_trace(go.Bar(
                                    x=stats_df['–°–µ–≥–º–µ–Ω—Ç'],
                                    y=stats_df['R¬≤ –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏'].astype(float),
                                    name='R¬≤ –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏',
                                    marker_color='lightblue',
                                    text=stats_df['R¬≤ –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏'],
                                    textposition='auto'
                                ))
                                
                                fig_quality.update_layout(
                                    title='–ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º (R¬≤)',
                                    xaxis_title='–°–µ–≥–º–µ–Ω—Ç',
                                    yaxis_title='R¬≤ –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏',
                                    height=400,
                                    template='plotly_white'
                                )
                                
                                st.plotly_chart(fig_quality, use_container_width=True)
                                
                                # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                                st.subheader("üìä –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
                                
                                y_pred, segment_preds = segmenter.predict_with_segment_models(
                                    X_test_local, 
                                    segmenter.segment_models, 
                                    segment_type_to_use
                                )
                                
                                if y_pred is not None:
                                    # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ç NaN
                                    y_test_clean = y_test_local.copy()
                                    if isinstance(y_test_clean, pd.Series):
                                        y_test_clean = y_test_clean.values
                                    
                                    # –£–¥–∞–ª—è–µ–º NaN –∏–∑ y_test_clean –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ y_pred
                                    valid_mask = ~np.isnan(y_test_clean) & ~np.isnan(y_pred)
                                    
                                    if np.any(valid_mask):
                                        y_test_clean = y_test_clean[valid_mask]
                                        y_pred_clean = y_pred[valid_mask]
                                        
                                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –æ—Å—Ç–∞–ª–∏—Å—å –¥–∞–Ω–Ω—ã–µ
                                        if len(y_test_clean) > 0 and len(y_pred_clean) > 0:
                                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è NaN –≤ –ø—Ä–æ–≥–Ω–æ–∑–∞—Ö
                                            if np.isnan(y_pred_clean).any():
                                                # –ó–∞–º–µ–Ω—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è NaN –Ω–∞ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                                                mean_val = np.nanmean(y_pred_clean)
                                                if np.isnan(mean_val):
                                                    mean_val = 0
                                                y_pred_clean = np.nan_to_num(y_pred_clean, nan=mean_val)
                                            
                                            # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
                                            mae = mean_absolute_error(y_test_clean, y_pred_clean)
                                            rmse = np.sqrt(mean_squared_error(y_test_clean, y_pred_clean))
                                            
                                            st.info(f"""
                                            **–ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:**
                                            - **MAE:** {mae:.4f}
                                            - **RMSE:** {rmse:.4f}
                                            - **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–ª–∏–¥–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤:** {len(y_test_clean)} –∏–∑ {len(y_test_local)}
                                            """)
                                            
                                            # –ì—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
                                            fig_predictions = go.Figure()
                                            
                                            fig_predictions.add_trace(go.Scatter(
                                                x=list(range(len(y_test_clean))),
                                                y=y_test_clean,
                                                mode='lines',
                                                name='–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è',
                                                line=dict(color='blue', width=2)
                                            ))
                                            
                                            fig_predictions.add_trace(go.Scatter(
                                                x=list(range(len(y_pred_clean))),
                                                y=y_pred_clean,
                                                mode='lines',
                                                name='–ü—Ä–æ–≥–Ω–æ–∑—ã',
                                                line=dict(color='red', width=2, dash='dash')
                                            ))
                                            
                                            fig_predictions.update_layout(
                                                title='–ü—Ä–æ–≥–Ω–æ–∑—ã –º–æ–¥–µ–ª–µ–π —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö',
                                                xaxis_title='–í—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω–¥–µ–∫—Å',
                                                yaxis_title='–ó–Ω–∞—á–µ–Ω–∏–µ',
                                                height=400,
                                                template='plotly_white'
                                            )
                                            
                                            st.plotly_chart(fig_predictions, use_container_width=True)
                                        else:
                                            st.warning("‚ö†Ô∏è –ü–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –æ—Ç NaN –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫.")
                                    else:
                                        st.error("‚ùå –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ (–≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è NaN).")
                                else:
                                    st.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑—ã –æ—Ç –º–æ–¥–µ–ª–µ–π —Å–µ–≥–º–µ–Ω—Ç–æ–≤.")
                        else:
                            st.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤.")
            else:
                st.info("‚ÑπÔ∏è –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é.")
        else:
            st.info("‚ÑπÔ∏è –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ù–∞–∂–º–∏—Ç–µ '–í—ã–ø–æ–ª–Ω–∏—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é' –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã.")
    
    # –ó–∞–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞–∑–¥–µ–ª
    st.markdown("---")
    st.subheader("üéØ –ò—Ç–æ–≥–∏ –≠—Ç–∞–ø–∞ 8")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if 'best_ensemble' in st.session_state:
            st.success("‚úÖ –ê–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ")
            best_ensemble = st.session_state.best_ensemble
            st.write(f"**–õ—É—á—à–∏–π –∞–Ω—Å–∞–º–±–ª—å:** {best_ensemble['name']}")
            st.write(f"**MAE:** {best_ensemble['metrics']['MAE']:.4f}")
        else:
            st.info("–ê–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ: –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ")
    
    with col2:
        if 'outlier_handler' in st.session_state:
            st.success("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
            outlier_handler = st.session_state.outlier_handler
            if 'isolation_forest' in outlier_handler.outlier_stats:
                stats = outlier_handler.outlier_stats['isolation_forest']
                st.write(f"**–í—ã–±—Ä–æ—Å–æ–≤:** {stats['n_outliers']}")
                st.write(f"**–ü—Ä–æ—Ü–µ–Ω—Ç:** {stats['outlier_percentage']:.1f}%")
        else:
            st.info("–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤: –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
    
    with col3:
        if 'segment_models' in st.session_state:
            st.success("‚úÖ –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
            segment_models = st.session_state.segment_models
            segment_types = list(segment_models.keys())
            st.write(f"**–¢–∏–ø—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏:** {', '.join(segment_types)}")
            for seg_type, seg_info in segment_models.items():
                st.write(f"**{seg_type}:** {len(seg_info['models'])} –º–æ–¥–µ–ª–µ–π")
        elif 'segmentation_state' in st.session_state and st.session_state.segmentation_state['results']:
            st.success("‚úÖ –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
            results = st.session_state.segmentation_state['results']
            st.write(f"**–¢–∏–ø—ã —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏:** {', '.join(results.keys())}")
        else:
            st.info("–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è: –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞")
    
    st.markdown("---")
    st.success("""
    **‚úÖ –≠—Ç–∞–ø 8: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω!**
    
    **–ß—Ç–æ –±—ã–ª–æ —Å–¥–µ–ª–∞–Ω–æ:**
    1. **–ê–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ:** –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ, Stacking, AutoGluon –∞–Ω—Å–∞–º–±–ª–∏
    2. **–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤:** Isolation Forest, RobustScaler, Winsorization
    3. **–°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è:** KMeans –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è, —Å–µ–∑–æ–Ω–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è, —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ —Ä–µ–∂–∏–º–∞–º
    
    **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞:**
    - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ª—É—á—à–∏–π –∞–Ω—Å–∞–º–±–ª—å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞–±–∏–ª—å–Ω—ã—Ö –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
    - –ü—Ä–∏–º–µ–Ω—è–π—Ç–µ RobustScaler –¥–ª—è –¥–∞–Ω–Ω—ã—Ö —Å –≤—ã–±—Ä–æ—Å–∞–º–∏
    - –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ä–µ–∂–∏–º–∞–º–∏
    
    **–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:**
    - –î–µ–ø–ª–æ–π –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω
    - –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤
    - –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
    """)

# ============================================================
# –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –ó–ê–ü–£–°–ö–ê –≠–¢–ê–ü–ê
# ============================================================

def run_stage_8():
    """–ó–∞–ø—É—Å–∫ –≠—Ç–∞–ø–∞ 8"""
    show_advanced_techniques_interface()

if __name__ == "__main__":
    run_stage_8()