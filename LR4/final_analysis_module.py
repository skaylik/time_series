# final_analysis_module.py - –≠—Ç–∞–ø 9: –§–∏–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

import streamlit as st
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt

# ============================================================
# –ö–õ–ê–°–° –î–õ–Ø –§–ò–ù–ê–õ–¨–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê
# ============================================================

class FinalAnalysis:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
    
    def __init__(self):
        self.analysis_results = {}
        self.recommendations = {}
        self.comparison_results = {}
    
    def collect_all_results(self):
        """–°–±–æ—Ä –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–æ–≤"""
        
        results_summary = {
            'data_preparation': {},
            'feature_engineering': {},
            'models_trained': {},
            'ensemble_results': {},
            'segmentation_results': {},
            'outlier_handling': {},
            'evaluation_results': {}
        }
        
        # 1. –°–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö (–≠—Ç–∞–ø 1-2)
        if 'df_features' in st.session_state:
            df_features = st.session_state.df_features
            results_summary['data_preparation'] = {
                'original_shape': df_features.shape,
                'features_count': len(df_features.columns),
                'missing_values': df_features.isnull().sum().sum()
            }
        
        # 2. –°–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ feature engineering (–≠—Ç–∞–ø 3)
        if 'feature_engineering_results' in st.session_state:
            feat_eng = st.session_state.feature_engineering_results
            results_summary['feature_engineering'] = {
                'created_features': feat_eng.get('created_features', []),
                'total_features': feat_eng.get('total_features', 0),
                'feature_importance': feat_eng.get('feature_importance', {})
            }
        
        # 3. –°–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π (–≠—Ç–∞–ø 4)
        if 'models_results' in st.session_state:
            models_results = st.session_state.models_results
            results_summary['models_trained'] = {
                'models_count': len(models_results),
                'best_model': models_results.get('best_model', {}),
                'all_models': list(models_results.keys())
            }
        
        # 4. –°–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è (–≠—Ç–∞–ø 8)
        if 'best_ensemble' in st.session_state:
            best_ensemble = st.session_state.best_ensemble
            results_summary['ensemble_results'] = {
                'best_ensemble_name': best_ensemble.get('name', 'N/A'),
                'best_ensemble_mae': best_ensemble.get('metrics', {}).get('MAE', 'N/A'),
                'best_ensemble_rmse': best_ensemble.get('metrics', {}).get('RMSE', 'N/A')
            }
        
        # 5. –°–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ (–≠—Ç–∞–ø 8)
        if 'segmentation_state' in st.session_state:
            seg_state = st.session_state.segmentation_state
            results_summary['segmentation_results'] = {
                'segmentation_types': list(seg_state.get('results', {}).keys()),
                'segment_models_trained': 'segment_models' in st.session_state
            }
        
        # 6. –°–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—ã–±—Ä–æ—Å–æ–≤ (–≠—Ç–∞–ø 8)
        if 'outlier_handler' in st.session_state:
            outlier_handler = st.session_state.outlier_handler
            results_summary['outlier_handling'] = {
                'methods_applied': list(outlier_handler.outlier_stats.keys()) if hasattr(outlier_handler, 'outlier_stats') else []
            }
        
        # 7. –°–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ü–µ–Ω–∫–∏ (–≠—Ç–∞–ø 7)
        if 'evaluation_results' in st.session_state:
            eval_results = st.session_state.evaluation_results
            results_summary['evaluation_results'] = {
                'ranked_models': eval_results.get('ranked_df', pd.DataFrame()),
                'best_model_name': eval_results.get('best_model', 'N/A'),
                'best_model_mae': eval_results.get('best_mae', 'N/A')
            }
        
        self.analysis_results = results_summary
        return results_summary
    
    def analyze_model_performance(self):
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π"""
        
        performance_analysis = {
            'model_ranking': {},
            'performance_comparison': {},
            'strengths_weaknesses': {}
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ü–µ–Ω–∫–∏
        if 'evaluation_results' in st.session_state:
            eval_results = st.session_state.evaluation_results
            ranked_df = eval_results.get('ranked_df')
            
            if ranked_df is not None and not ranked_df.empty:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ MAE
                if 'MAE' in ranked_df.columns:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º MAE –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç
                    ranked_df['MAE_numeric'] = pd.to_numeric(ranked_df['MAE'], errors='coerce')
                    ranked_df = ranked_df.dropna(subset=['MAE_numeric'])
                    ranked_df = ranked_df.sort_values('MAE_numeric')
                    
                    performance_analysis['model_ranking'] = ranked_df.to_dict('records')
                    
                    # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–Ω–∏—Ü—ã –≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                    if len(ranked_df) > 1:
                        best_mae = ranked_df['MAE_numeric'].iloc[0]
                        worst_mae = ranked_df['MAE_numeric'].iloc[-1]
                        mae_range = worst_mae - best_mae
                        performance_analysis['performance_comparison'] = {
                            'best_mae': float(best_mae),
                            'worst_mae': float(worst_mae),
                            'mae_range': float(mae_range),
                            'relative_improvement': float((mae_range / worst_mae) * 100)
                        }
        
        # –ê–Ω–∞–ª–∏–∑ —Å–∏–ª—å–Ω—ã—Ö –∏ —Å–ª–∞–±—ã—Ö —Å—Ç–æ—Ä–æ–Ω
        if 'models_results' in st.session_state:
            models_results = st.session_state.models_results
            
            strengths = []
            weaknesses = []
            
            for model_name, model_info in models_results.items():
                if isinstance(model_info, dict):
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏
                    model_type = model_info.get('type', 'unknown')
                    
                    # –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
                    if 'linear' in model_type.lower():
                        strengths.append(f"{model_name}: –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å, –±—ã—Å—Ç—Ä–∞—è –æ–±—É—á–µ–Ω–∏–µ")
                    elif 'tree' in model_type.lower() or 'forest' in model_type.lower():
                        strengths.append(f"{model_name}: –†–∞–±–æ—Ç–∞ —Å –Ω–µ–ª–∏–Ω–µ–π–Ω—ã–º–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è–º–∏")
                    elif 'neural' in model_type.lower():
                        strengths.append(f"{model_name}: –°–ª–æ–∂–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –±–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ")
                    
                    # –°–ª–∞–±—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã
                    if 'linear' in model_type.lower():
                        weaknesses.append(f"{model_name}: –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ –≤—ã–±—Ä–æ—Å–∞–º, –ª–∏–Ω–µ–π–Ω—ã–µ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–µ–Ω–∏—è")
                    elif 'tree' in model_type.lower():
                        weaknesses.append(f"{model_name}: –°–∫–ª–æ–Ω–Ω–æ—Å—Ç—å –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é")
            
            performance_analysis['strengths_weaknesses'] = {
                'strengths': strengths,
                'weaknesses': weaknesses
            }
        
        return performance_analysis
    
    def analyze_feature_importance(self):
        """–ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        
        feature_importance_analysis = {
            'top_features': [],
            'feature_categories': {},
            'recommendations': []
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ feature importance
        if 'feature_engineering_results' in st.session_state:
            feat_eng = st.session_state.feature_engineering_results
            feature_importance = feat_eng.get('feature_importance', {})
            
            if feature_importance:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
                sorted_features = sorted(feature_importance.items(), 
                                       key=lambda x: abs(x[1]), 
                                       reverse=True)
                
                # –ë–µ—Ä–µ–º —Ç–æ–ø-10 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                top_features = sorted_features[:10]
                feature_importance_analysis['top_features'] = [
                    {'feature': feat, 'importance': float(imp)} 
                    for feat, imp in top_features
                ]
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                temporal_features = []
                lag_features = []
                statistical_features = []
                
                for feature, _ in sorted_features:
                    feature_lower = feature.lower()
                    if any(term in feature_lower for term in ['lag', 'shift', 'diff']):
                        lag_features.append(feature)
                    elif any(term in feature_lower for term in ['mean', 'std', 'min', 'max', 'rolling']):
                        statistical_features.append(feature)
                    elif any(term in feature_lower for term in ['year', 'month', 'day', 'hour', 'week', 'season']):
                        temporal_features.append(feature)
                
                feature_importance_analysis['feature_categories'] = {
                    'temporal': temporal_features[:5],
                    'lag': lag_features[:5],
                    'statistical': statistical_features[:5]
                }
                
                # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                recommendations = []
                
                if len(lag_features) > 0:
                    recommendations.append("–õ–∞–≥-–ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–º–µ—é—Ç –≤—ã—Å–æ–∫—É—é –≤–∞–∂–Ω–æ—Å—Ç—å - –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —Å–∏–ª—å–Ω—ã")
                
                if len(statistical_features) > 0:
                    recommendations.append("–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤–∞–∂–Ω—ã - —Ä—è–¥—ã –∏–º–µ—é—Ç —Å–ª–æ–∂–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É")
                
                if len(temporal_features) > 0:
                    recommendations.append("–í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∑–Ω–∞—á–∏–º—ã - –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å–µ–∑–æ–Ω–Ω—ã–µ/—Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã")
                
                feature_importance_analysis['recommendations'] = recommendations
        
        return feature_importance_analysis
    
    def analyze_autogluon_vs_custom(self):
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ AutoGluon —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏"""
        
        comparison = {
            'autogluon_available': False,
            'autogluon_results': {},
            'custom_models_results': {},
            'comparison_summary': {}
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ AutoGluon —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if 'autogluon_results' in st.session_state:
            autogluon_res = st.session_state.autogluon_results
            comparison['autogluon_available'] = True
            comparison['autogluon_results'] = autogluon_res
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ AutoGluon
            autogluon_metrics = autogluon_res.get('metrics', {})
            autogluon_mae = autogluon_metrics.get('MAE', None)
            autogluon_rmse = autogluon_metrics.get('RMSE', None)
        
        # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—Å—Ç–æ–º–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        custom_models_metrics = []
        
        # –ò–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ü–µ–Ω–∫–∏
        if 'evaluation_results' in st.session_state:
            eval_results = st.session_state.evaluation_results
            predictions = eval_results.get('predictions', {})
            
            for model_name, pred in predictions.items():
                if pred is not None:
                    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫
                    result = prepare_data_for_advanced_techniques()
                    if result[0] is not None:
                        _, _, _, y_test, _ = result
                        
                        if len(pred) == len(y_test):
                            try:
                                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —á–∏—Å–ª–∞ –∏ —É–±–∏—Ä–∞–µ–º NaN
                                y_pred_clean = pd.to_numeric(pred, errors='coerce')
                                y_test_clean = pd.to_numeric(y_test, errors='coerce')
                                
                                # –£–±–∏—Ä–∞–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è
                                mask = ~np.isnan(y_pred_clean) & ~np.isnan(y_test_clean)
                                if np.sum(mask) > 0:
                                    y_pred_valid = y_pred_clean[mask]
                                    y_test_valid = y_test_clean[mask]
                                    
                                    mae = mean_absolute_error(y_test_valid, y_pred_valid)
                                    rmse = np.sqrt(mean_squared_error(y_test_valid, y_pred_valid))
                                    
                                    custom_models_metrics.append({
                                        'model': model_name,
                                        'mae': float(mae),
                                        'rmse': float(rmse)
                                    })
                            except:
                                pass
        
        comparison['custom_models_results'] = custom_models_metrics
        
        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º AutoGluon —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
        if comparison['autogluon_available'] and custom_models_metrics:
            # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à—É—é –∫–∞—Å—Ç–æ–º–Ω—É—é –º–æ–¥–µ–ª—å
            best_custom = min(custom_models_metrics, key=lambda x: x['mae'])
            
            comparison['comparison_summary'] = {
                'autogluon_mae': autogluon_mae,
                'best_custom_mae': best_custom['mae'],
                'difference_mae': float(autogluon_mae - best_custom['mae']) if autogluon_mae is not None else None,
                'autogluon_better': autogluon_mae < best_custom['mae'] if autogluon_mae is not None else False
            }
        
        self.comparison_results = comparison
        return comparison
    
    def generate_recommendations(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        
        recommendations = {
            'model_selection': [],
            'feature_engineering': [],
            'data_preprocessing': [],
            'deployment': [],
            'monitoring': []
        }
        
        # 1. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É –º–æ–¥–µ–ª–∏
        if 'best_ensemble' in st.session_state:
            best_ensemble = st.session_state.best_ensemble
            recommendations['model_selection'].append(
                f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–Ω—Å–∞–º–±–ª—å '{best_ensemble['name']}' –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞ (MAE: {best_ensemble['metrics']['MAE']:.4f})"
            )
        elif 'evaluation_results' in st.session_state:
            eval_results = st.session_state.evaluation_results
            best_model = eval_results.get('best_model', 'N/A')
            recommendations['model_selection'].append(
                f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å '{best_model}' –∫–∞–∫ –ª—É—á—à—É—é –æ–¥–∏–Ω–æ—á–Ω—É—é –º–æ–¥–µ–ª—å"
            )
        
        # 2. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ feature engineering
        feat_importance = self.analyze_feature_importance()
        top_features = feat_importance.get('top_features', [])
        
        if len(top_features) > 0:
            top_feature_names = [f['feature'] for f in top_features[:3]]
            recommendations['feature_engineering'].append(
                f"–°—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö: {', '.join(top_feature_names)}"
            )
        
        # 3. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö
        if 'outlier_handler' in st.session_state:
            outlier_handler = st.session_state.outlier_handler
            if hasattr(outlier_handler, 'outlier_stats') and 'isolation_forest' in outlier_handler.outlier_stats:
                stats = outlier_handler.outlier_stats['isolation_forest']
                if stats['outlier_percentage'] > 5:
                    recommendations['data_preprocessing'].append(
                        f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {stats['outlier_percentage']:.1f}% –≤—ã–±—Ä–æ—Å–æ–≤ - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å RobustScaler"
                    )
        
        # 4. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–µ–ø–ª–æ—é
        recommendations['deployment'].append(
            "–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–∞–π–ø–ª–∞–π–Ω –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Ä–∞–∑ –≤ –Ω–µ–¥–µ–ª—é"
        )
        recommendations['deployment'].append(
            "–ù–∞—Å—Ç—Ä–æ–∏—Ç—å A/B —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏–π –º–æ–¥–µ–ª–µ–π"
        )
        
        # 5. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥—É
        recommendations['monitoring'].append(
            "–ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å MAE –∏ RMSE –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"
        )
        recommendations['monitoring'].append(
            "–ù–∞—Å—Ç—Ä–æ–∏—Ç—å –∞–ª–µ—Ä—Ç—ã –ø—Ä–∏ —É—Ö—É–¥—à–µ–Ω–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ 10%"
        )
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ AutoGluon —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
        comparison = self.analyze_autogluon_vs_custom()
        if comparison.get('autogluon_available', False):
            summary = comparison.get('comparison_summary', {})
            if summary.get('autogluon_better', False):
                recommendations['model_selection'].append(
                    "AutoGluon –ø–æ–∫–∞–∑–∞–ª –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã - —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏"
                )
            else:
                recommendations['model_selection'].append(
                    "–ö–∞—Å—Ç–æ–º–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ª—É—á—à–µ AutoGluon - –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ä—É—á–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É"
                )
        
        self.recommendations = recommendations
        return recommendations
    
    def create_performance_report(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        
        report = {
            'executive_summary': {},
            'technical_details': {},
            'business_impact': {},
            'next_steps': {}
        }
        
        # 1. Executive Summary
        best_mae = None
        best_model_name = "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ"
        
        if 'best_ensemble' in st.session_state:
            best_ensemble = st.session_state.best_ensemble
            best_mae = best_ensemble['metrics']['MAE']
            best_model_name = best_ensemble['name']
        elif 'evaluation_results' in st.session_state:
            eval_results = st.session_state.evaluation_results
            best_mae = eval_results.get('best_mae')
            best_model_name = eval_results.get('best_model', 'N/A')
        
        report['executive_summary'] = {
            'best_model': best_model_name,
            'best_mae': float(best_mae) if best_mae is not None else 'N/A',
            'total_models_tested': len(self.analysis_results.get('models_trained', {}).get('all_models', [])),
            'key_achievement': f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ —Ç–æ—á–Ω–æ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è —Å MAE: {best_mae:.4f}" if best_mae else "–¢–æ—á–Ω–æ—Å—Ç—å –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞"
        }
        
        # 2. Technical Details
        report['technical_details'] = {
            'data_characteristics': self.analysis_results.get('data_preparation', {}),
            'features_used': len(self.analysis_results.get('feature_engineering', {}).get('created_features', [])),
            'ensemble_used': 'best_ensemble' in st.session_state,
            'segmentation_applied': len(self.analysis_results.get('segmentation_results', {}).get('segmentation_types', [])) > 0
        }
        
        # 3. Business Impact
        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è - —ç—Ç–æ, –Ω–∞–ø—Ä–∏–º–µ—Ä, –ø—Ä–æ–¥–∞–∂–∏ –∏–ª–∏ —Å–ø—Ä–æ—Å
        if best_mae and isinstance(best_mae, (int, float)):
            accuracy_percentage = max(0, 100 - (best_mae * 100))  # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏
            report['business_impact'] = {
                'forecast_accuracy': f"{accuracy_percentage:.1f}%",
                'potential_savings': "–£–ª—É—á—à–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤ –Ω–∞ 10-20%",
                'risk_reduction': "–°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∏—Å–∫–æ–≤ –Ω–µ—Ö–≤–∞—Ç–∫–∏/–ø–µ—Ä–µ–∏–∑–±—ã—Ç–∫–∞ –Ω–∞ 15-25%"
            }
        else:
            report['business_impact'] = {
                'forecast_accuracy': "–ù–µ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–æ",
                'potential_savings': "–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑",
                'risk_reduction': "–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"
            }
        
        # 4. Next Steps
        report['next_steps'] = {
            'immediate': [
                "–î–µ–ø–ª–æ–π –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –≤ —Ç–µ—Å—Ç–æ–≤–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ",
                "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤"
            ],
            'short_term': [
                "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è",
                "–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö"
            ],
            'long_term': [
                "–í–Ω–µ–¥—Ä–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤",
                "–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–∏—Å—Ç–µ–º–∞–º–∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤"
            ]
        }
        
        return report
    
    def perform_complete_analysis(self):
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        
        # –°–±–æ—Ä –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.collect_all_results()
        
        # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
        performance = self.analyze_model_performance()
        
        # –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_importance = self.analyze_feature_importance()
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ AutoGluon —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
        autogluon_comparison = self.analyze_autogluon_vs_custom()
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        recommendations = self.generate_recommendations()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        report = self.create_performance_report()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        complete_analysis = {
            'performance_analysis': performance,
            'feature_importance_analysis': feature_importance,
            'autogluon_comparison': autogluon_comparison,
            'recommendations': recommendations,
            'final_report': report
        }
        
        st.session_state.final_analysis = complete_analysis
        return complete_analysis

# ============================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ============================================================

def prepare_data_for_advanced_techniques():
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö —Ç–µ—Ö–Ω–∏–∫ (–∫–æ–ø–∏—è –∏–∑ advanced_techniques.py)"""
    
    required_keys = ['df_features', 'feature_info', 'split_data']
    missing_keys = [key for key in required_keys if key not in st.session_state]
    
    if missing_keys:
        return None, None, None, None, None
    
    feature_info = st.session_state.feature_info
    split_data = st.session_state.split_data
    df_features = st.session_state.df_features
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    date_col = feature_info['original_features'][0]
    target_col = feature_info['original_features'][1]
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    train_data = split_data['train'].copy()
    val_data = split_data['val'].copy()
    test_data = split_data['test'].copy()
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º train –∏ val –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    X_train_full = pd.concat([train_data, val_data], axis=0)
    
    # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
    feature_cols = []
    for col in X_train_full.columns:
        if col != date_col and col != target_col:
            if pd.api.types.is_numeric_dtype(X_train_full[col]):
                feature_cols.append(col)
    
    if not feature_cols:
        return None, None, None, None, None
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    X_train = X_train_full[feature_cols].copy()
    y_train = X_train_full[target_col].copy()
    
    X_test = test_data[feature_cols].copy()
    y_test = test_data[target_col].copy()
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
    X_train = X_train.fillna(X_train.median())
    X_test = X_test.fillna(X_train.median())
    y_train = y_train.fillna(y_train.median())
    y_test = y_test.fillna(y_test.median())
    
    return X_train, y_train, X_test, y_test, feature_cols

# ============================================================
# –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° –≠–¢–ê–ü–ê 9
# ============================================================

def show_final_analysis_interface():
    """–û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –≠—Ç–∞–ø–∞ 9: –§–∏–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑"""
    
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–æ–≤
    if 'df_features' not in st.session_state or 'feature_info' not in st.session_state:
        st.error("‚ùå –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≠—Ç–∞–ø—ã 1-2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö")
        return
    
    st.info("""
    **–¶–µ–ª—å –≠—Ç–∞–ø–∞ 9:**
    
    1. **–°–≤–æ–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤**
    2. **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π**
    3. **–ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤**
    4. **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞**
    5. **–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç**
    """)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞
    analysis = FinalAnalysis()
    
    # –ö–Ω–æ–ø–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    if st.button("üöÄ –í—ã–ø–æ–ª–Ω–∏—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑", key="final_analysis_button"):
        
        with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑..."):
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            complete_analysis = analysis.perform_complete_analysis()
            
            # 1. –°–≤–æ–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            st.subheader("1. üìã –°–≤–æ–¥–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric(
                    label="–ú–æ–¥–µ–ª–µ–π –æ–±—É—á–µ–Ω–æ",
                    value=len(analysis.analysis_results.get('models_trained', {}).get('all_models', [])),
                    help="–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"
                )
            
            with col2:
                features_count = len(analysis.analysis_results.get('feature_engineering', {}).get('created_features', []))
                st.metric(
                    label="–ü—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–æ–∑–¥–∞–Ω–æ",
                    value=features_count,
                    help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –≤ feature engineering –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
                )
            
            with col3:
                segmentation_types = analysis.analysis_results.get('segmentation_results', {}).get('segmentation_types', [])
                st.metric(
                    label="–¢–∏–ø–æ–≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏",
                    value=len(segmentation_types),
                    help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–¥–æ–≤ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏"
                )
            
            # 2. –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
            st.subheader("2. üìà –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π")
            
            performance = complete_analysis['performance_analysis']
            
            if 'model_ranking' in performance and performance['model_ranking']:
                # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                ranking_df = pd.DataFrame(performance['model_ranking'])
                
                # –£–±–∏—Ä–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∫–æ–ª–æ–Ω–∫–∏
                if 'MAE_numeric' in ranking_df.columns:
                    ranking_df = ranking_df.drop('MAE_numeric', axis=1)
                
                st.dataframe(ranking_df, width='stretch')
                
                # –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
                if len(ranking_df) > 0 and 'MAE' in ranking_df.columns and 'model' in ranking_df.columns:
                    fig_comparison = go.Figure()
                    
                    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º MAE –≤ —á–∏—Å–ª–∞
                    ranking_df['MAE_numeric'] = pd.to_numeric(ranking_df['MAE'], errors='coerce')
                    ranking_df = ranking_df.dropna(subset=['MAE_numeric'])
                    
                    if not ranking_df.empty:
                        fig_comparison.add_trace(go.Bar(
                            x=ranking_df['model'],
                            y=ranking_df['MAE_numeric'],
                            name='MAE',
                            marker_color='lightblue',
                            text=ranking_df['MAE_numeric'].round(4),
                            textposition='auto'
                        ))
                        
                        fig_comparison.update_layout(
                            title='–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ MAE',
                            xaxis_title='–ú–æ–¥–µ–ª—å',
                            yaxis_title='MAE',
                            height=400,
                            template='plotly_white'
                        )
                        
                        st.plotly_chart(fig_comparison, use_container_width=True)
            
            # 3. –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            st.subheader("3. üîç –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            
            feature_importance = complete_analysis['feature_importance_analysis']
            
            if feature_importance.get('top_features'):
                # –ì—Ä–∞—Ñ–∏–∫ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                features_df = pd.DataFrame(feature_importance['top_features'])
                
                fig_features = go.Figure()
                
                fig_features.add_trace(go.Bar(
                    x=features_df['importance'],
                    y=features_df['feature'],
                    orientation='h',
                    name='–í–∞–∂–Ω–æ—Å—Ç—å',
                    marker_color='lightgreen'
                ))
                
                fig_features.update_layout(
                    title='–¢–æ–ø-10 —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤',
                    xaxis_title='–í–∞–∂–Ω–æ—Å—Ç—å',
                    yaxis_title='–ü—Ä–∏–∑–Ω–∞–∫',
                    height=500,
                    template='plotly_white'
                )
                
                st.plotly_chart(fig_features, use_container_width=True)
                
                # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                st.write("**–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:**")
                
                categories = feature_importance.get('feature_categories', {})
                for category, features in categories.items():
                    if features:
                        st.write(f"- **{category.capitalize()}:** {', '.join(features[:3])}")
            
            # 4. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ AutoGluon —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏
            st.subheader("4. ü§ñ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ AutoGluon —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏")
            
            autogluon_comparison = complete_analysis['autogluon_comparison']
            
            if autogluon_comparison.get('autogluon_available', False):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("**AutoGluon —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:**")
                    autogluon_res = autogluon_comparison.get('autogluon_results', {})
                    if 'metrics' in autogluon_res:
                        metrics = autogluon_res['metrics']
                        st.write(f"- MAE: {metrics.get('MAE', 'N/A')}")
                        st.write(f"- RMSE: {metrics.get('RMSE', 'N/A')}")
                
                with col2:
                    st.write("**–õ—É—á—à–∏–µ –∫–∞—Å—Ç–æ–º–Ω—ã–µ –º–æ–¥–µ–ª–∏:**")
                    custom_models = autogluon_comparison.get('custom_models_results', [])
                    if custom_models:
                        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ MAE
                        custom_models_sorted = sorted(custom_models, key=lambda x: x['mae'])
                        for i, model in enumerate(custom_models_sorted[:3]):
                            st.write(f"{i+1}. {model['model']}: MAE={model['mae']:.4f}")
                
                # –°–≤–æ–¥–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                summary = autogluon_comparison.get('comparison_summary', {})
                if summary:
                    st.write("**–°–≤–æ–¥–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:**")
                    
                    if summary.get('autogluon_better'):
                        st.success(f"‚úÖ AutoGluon –ª—É—á—à–µ –Ω–∞ {(summary.get('difference_mae', 0) * -1):.4f} MAE")
                    else:
                        st.success(f"‚úÖ –ö–∞—Å—Ç–æ–º–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ª—É—á—à–µ –Ω–∞ {summary.get('difference_mae', 0):.4f} MAE")
            else:
                st.info("‚ÑπÔ∏è AutoGluon –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è –≤ –∞–Ω–∞–ª–∏–∑–µ")
            
            # 5. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            st.subheader("5. üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞")
            
            recommendations = complete_analysis['recommendations']
            
            tabs = st.tabs(["–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏", "Feature Engineering", "–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞", "–î–µ–ø–ª–æ–π", "–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"])
            
            with tabs[0]:
                st.write("**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É –º–æ–¥–µ–ª–∏:**")
                for rec in recommendations.get('model_selection', []):
                    st.write(f"‚Ä¢ {rec}")
            
            with tabs[1]:
                st.write("**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ feature engineering:**")
                for rec in recommendations.get('feature_engineering', []):
                    st.write(f"‚Ä¢ {rec}")
            
            with tabs[2]:
                st.write("**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö:**")
                for rec in recommendations.get('data_preprocessing', []):
                    st.write(f"‚Ä¢ {rec}")
            
            with tabs[3]:
                st.write("**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–µ–ø–ª–æ—é:**")
                for rec in recommendations.get('deployment', []):
                    st.write(f"‚Ä¢ {rec}")
            
            with tabs[4]:
                st.write("**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥—É:**")
                for rec in recommendations.get('monitoring', []):
                    st.write(f"‚Ä¢ {rec}")
            
            # 6. –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
            st.subheader("6. üìÑ –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç")
            
            report = complete_analysis['final_report']
            
            with st.expander("üìã Executive Summary", expanded=True):
                exec_summary = report.get('executive_summary', {})
                st.write(f"**–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å:** {exec_summary.get('best_model', 'N/A')}")
                st.write(f"**–õ—É—á—à–∏–π MAE:** {exec_summary.get('best_mae', 'N/A')}")
                st.write(f"**–ú–æ–¥–µ–ª–µ–π –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ:** {exec_summary.get('total_models_tested', 0)}")
                st.write(f"**–ö–ª—é—á–µ–≤–æ–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ:** {exec_summary.get('key_achievement', 'N/A')}")
            
            with st.expander("üîß Technical Details"):
                tech_details = report.get('technical_details', {})
                st.write(f"**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –∞–Ω—Å–∞–º–±–ª—å:** {'–î–∞' if tech_details.get('ensemble_used') else '–ù–µ—Ç'}")
                st.write(f"**–ü—Ä–∏–º–µ–Ω–µ–Ω–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è:** {'–î–∞' if tech_details.get('segmentation_applied') else '–ù–µ—Ç'}")
                st.write(f"**–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:** {tech_details.get('features_used', 0)}")
            
            with st.expander("üíº Business Impact"):
                business_impact = report.get('business_impact', {})
                st.write(f"**–¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–æ–≤:** {business_impact.get('forecast_accuracy', 'N/A')}")
                st.write(f"**–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è —ç–∫–æ–Ω–æ–º–∏—è:** {business_impact.get('potential_savings', 'N/A')}")
                st.write(f"**–°–Ω–∏–∂–µ–Ω–∏–µ —Ä–∏—Å–∫–æ–≤:** {business_impact.get('risk_reduction', 'N/A')}")
            
            with st.expander("üöÄ Next Steps"):
                next_steps = report.get('next_steps', {})
                
                st.write("**–ù–µ–º–µ–¥–ª–µ–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:**")
                for step in next_steps.get('immediate', []):
                    st.write(f"‚Ä¢ {step}")
                
                st.write("**–ö—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ –ø–ª–∞–Ω—ã:**")
                for step in next_steps.get('short_term', []):
                    st.write(f"‚Ä¢ {step}")
                
                st.write("**–î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –ø–ª–∞–Ω—ã:**")
                for step in next_steps.get('long_term', []):
                    st.write(f"‚Ä¢ {step}")
            
            # –ö–Ω–æ–ø–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –æ—Ç—á–µ—Ç–∞
            st.download_button(
                label="üì• –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á–µ—Ç –≤ JSON",
                data=pd.Series(complete_analysis).to_json(indent=2, orient='index'),
                file_name="final_analysis_report.json",
                mime="application/json"
            )
            
            st.success("‚úÖ –§–∏–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    
    # –ò—Ç–æ–≥–æ–≤—ã–π —Ä–∞–∑–¥–µ–ª
    st.markdown("---")
    st.subheader("üéØ –ò—Ç–æ–≥–∏ –ø—Ä–æ–µ–∫—Ç–∞")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**–ß—Ç–æ –±—ã–ª–æ —Å–¥–µ–ª–∞–Ω–æ:**")
        st.write("‚Ä¢ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö")
        st.write("‚Ä¢ Feature engineering –∏ –æ—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        st.write("‚Ä¢ –û–±—É—á–µ–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π")
        st.write("‚Ä¢ –ê–Ω—Å–∞–º–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è")
        st.write("‚Ä¢ –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤ –∏ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è")
        st.write("‚Ä¢ –î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞")
        st.write("‚Ä¢ –§–∏–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
    
    with col2:
        st.write("**–ö–ª—é—á–µ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:**")
        st.write("‚Ä¢ –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å/–∞–Ω—Å–∞–º–±–ª—å")
        st.write("‚Ä¢ –í—ã—è–≤–ª–µ–Ω—ã –≤–∞–∂–Ω–µ–π—à–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏")
        st.write("‚Ä¢ –†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω—ã —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞")
        st.write("‚Ä¢ –°–æ–∑–¥–∞–Ω –ø–ª–∞–Ω –¥–∞–ª—å–Ω–µ–π—à–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π")
        st.write("‚Ä¢ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç")
    
    st.markdown("---")
    st.success("""
    **üèÜ –ü—Ä–æ–µ–∫—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!**
    
    **–î–∞–ª—å–Ω–µ–π—à–∏–µ —à–∞–≥–∏:**
    1. **–î–µ–ø–ª–æ–π** –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –≤ –ø—Ä–æ–¥–∞–∫—à–µ–Ω
    2. **–ù–∞—Å—Ç—Ä–æ–π–∫–∞** –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –∞–ª–µ—Ä—Ç–æ–≤
    3. **–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ** —Ä–µ–≥—É–ª—è—Ä–Ω–æ–≥–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
    4. **–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ** —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö insights
    
    **–°–ø–∞—Å–∏–±–æ –∑–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã! üéâ**
    """)

# ============================================================
# –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –ó–ê–ü–£–°–ö–ê –≠–¢–ê–ü–ê
# ============================================================

def show_final_analysis():
    """–ó–∞–ø—É—Å–∫ –≠—Ç–∞–ø–∞ 9"""
    show_final_analysis_interface()

if __name__ == "__main__":
    show_final_analysis()