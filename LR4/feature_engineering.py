# feature_engineering.py - –ú–æ–¥—É–ª—å –∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–≠—Ç–∞–ø 1)

import pandas as pd
import numpy as np
from datetime import datetime
from scipy import stats
from scipy.special import boxcox, inv_boxcox
from typing import List, Tuple, Dict, Optional
import warnings
warnings.filterwarnings('ignore')

# –ò–º–ø–æ—Ä—Ç –¥–ª—è Streamlit –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
import streamlit as st
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# ============================================================
# –û–°–ù–û–í–ù–ê–Ø –õ–û–ì–ò–ö–ê –ò–ù–ñ–ò–ù–ò–†–ò–ù–ì–ê –ü–†–ò–ó–ù–ê–ö–û–í
# ============================================================

class TimeSeriesFeatureEngineer:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
    """
    
    def __init__(self, date_col: str, target_col: str):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∞
        
        Parameters:
        -----------
        date_col : str
            –ù–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ —Å –¥–∞—Ç–æ–π/–≤—Ä–µ–º–µ–Ω–µ–º
        target_col : str
            –ù–∞–∑–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        """
        self.date_col = date_col
        self.target_col = target_col
        self.lambda_boxcox = None
        
    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        
        Parameters:
        -----------
        df : pd.DataFrame
            –ò—Å—Ö–æ–¥–Ω—ã–π DataFrame
            
        Returns:
        --------
        pd.DataFrame
            DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        """
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é DataFrame
        df_features = df.copy()
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞—Ç—É —Å—Ä–∞–∑—É, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫
        df_features = self._ensure_datetime(df_features)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
        df_features = df_features.sort_values(self.date_col)
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö —Å–¥–≤–∏–≥–æ–≤
        df_features = df_features.reset_index(drop=True)
        
        # 1. –õ–∞–≥–∏
        df_features = self._create_lags(df_features)
        
        # 2. –°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞
        df_features = self._create_rolling_features(df_features)
        
        # 3. –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
        df_features = self._create_exponential_smoothing(df_features)
        
        # 4. –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        df_features = self._create_time_features(df_features)
        
        # 5. –°–µ–∑–æ–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–§—É—Ä—å–µ)
        df_features = self._create_fourier_features(df_features)
        
        # –£–î–ê–õ–Ø–ï–ú –°–¢–†–û–ö–£ –°–ë–†–û–°–ê –ò–ù–î–ï–ö–°–ê - –û–ù–ê –£–ù–ò–ß–¢–û–ñ–ê–ï–¢ –ü–†–ò–ó–ù–ê–ö–ò!
        # df_features = df_features.reset_index(drop=True)
        
        # –ü–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤—ã–≤–µ–¥–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        print(f"–°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df_features.columns)}")
        print(f"–ò–º–µ–Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {df_features.columns.tolist()}")

        return df_features
    
    def _ensure_datetime(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–∞ —Å –¥–∞—Ç–æ–π –≤ datetime —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–æ–Ω
        """
        df_copy = df.copy()
        
        if not pd.api.types.is_datetime64_any_dtype(df_copy[self.date_col]):
            try:
                # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Å —É—á–µ—Ç–æ–º –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–æ–Ω
                df_copy[self.date_col] = pd.to_datetime(df_copy[self.date_col], utc=True)
            except Exception as e:
                # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è —Å utc=True, –ø—Ä–æ–±—É–µ–º –±–µ–∑
                df_copy[self.date_col] = pd.to_datetime(df_copy[self.date_col])
        
        # –£–±–∏—Ä–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –∑–æ–Ω—É –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
        if hasattr(df_copy[self.date_col].dt, 'tz') and df_copy[self.date_col].dt.tz is not None:
            df_copy[self.date_col] = df_copy[self.date_col].dt.tz_convert(None)
        
        return df_copy
    
    def _create_lags(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –ª–∞–≥–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        lags = [1, 2, 3, 7, 14, 30]
        
        for lag in lags:
            col_name = f'{self.target_col}_lag_{lag}'
            if col_name not in df.columns:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —Å—Ç–æ–ª–±—Ü–∞
                df[col_name] = df[self.target_col].shift(lag)
        
        return df
    
    def _create_rolling_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å–∫–æ–ª—å–∑—è—â–∏—Ö –æ–∫–æ–Ω
        """
        windows = [7, 14, 30]
        
        for window in windows:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º
            mean_col = f'{self.target_col}_rolling_mean_{window}'
            std_col = f'{self.target_col}_rolling_std_{window}'
            min_col = f'{self.target_col}_rolling_min_{window}'
            max_col = f'{self.target_col}_rolling_max_{window}'
            median_col = f'{self.target_col}_rolling_median_{window}'
            range_col = f'{self.target_col}_rolling_range_{window}'
            cv_col = f'{self.target_col}_rolling_cv_{window}'
            
            if mean_col not in df.columns:
                df[mean_col] = df[self.target_col].rolling(
                    window=window, min_periods=1
                ).mean()
            
            if std_col not in df.columns:
                df[std_col] = df[self.target_col].rolling(
                    window=window, min_periods=1
                ).std()
            
            if min_col not in df.columns:
                df[min_col] = df[self.target_col].rolling(
                    window=window, min_periods=1
                ).min()
            
            if max_col not in df.columns:
                df[max_col] = df[self.target_col].rolling(
                    window=window, min_periods=1
                ).max()
            
            if median_col not in df.columns:
                df[median_col] = df[self.target_col].rolling(
                    window=window, min_periods=1
                ).median()
            
            if range_col not in df.columns:
                # –°–æ–∑–¥–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–æ–∑–¥–∞–Ω—ã min –∏ max
                if max_col in df.columns and min_col in df.columns:
                    df[range_col] = df[max_col] - df[min_col]
            
            if cv_col not in df.columns:
                # –°–æ–∑–¥–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–æ–∑–¥–∞–Ω—ã std –∏ mean
                if std_col in df.columns and mean_col in df.columns:
                    df[cv_col] = df[std_col] / df[mean_col]
                    # –ó–∞–º–µ–Ω—è–µ–º –±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ NaN
                    df[cv_col] = df[cv_col].replace(
                        [np.inf, -np.inf], np.nan
                    )
        
        return df
    
    def _create_exponential_smoothing(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
        """
        alphas = [0.3, 0.5, 0.7]
        
        for alpha in alphas:
            col_name = f'{self.target_col}_exp_smooth_{alpha}'
            if col_name not in df.columns:
                df[col_name] = 0.0
                
                if len(df) > 0:
                    df.loc[0, col_name] = df.loc[0, self.target_col]
                
                for i in range(1, len(df)):
                    df.loc[i, col_name] = (
                        alpha * df.loc[i, self.target_col] + 
                        (1 - alpha) * df.loc[i-1, col_name]
                    )
        
        return df
    
    def _create_time_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –¥–∞—Ç–∞ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        if not pd.api.types.is_datetime64_any_dtype(df[self.date_col]):
            df[self.date_col] = pd.to_datetime(df[self.date_col])
        
        # –ë–∞–∑–æ–≤—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ - —Å–æ–∑–¥–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
        time_features = {
            'day_of_week': df[self.date_col].dt.dayofweek,  # 0-–ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫, 6-–≤–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ
            'day_of_month': df[self.date_col].dt.day,
            'month': df[self.date_col].dt.month,
            'quarter': df[self.date_col].dt.quarter,
            'week_of_year': df[self.date_col].dt.isocalendar().week,
            'year': df[self.date_col].dt.year,
            'is_weekend': df[self.date_col].dt.dayofweek.apply(lambda x: 1 if x >= 5 else 0),
            'is_holiday': 0,  # –ü—Ä–∏–∑–Ω–∞–∫ –ø—Ä–∞–∑–¥–Ω–∏–∫–∞ (–∑–∞–≥–ª—É—à–∫–∞)
        }
        
        for col_name, values in time_features.items():
            if col_name not in df.columns:
                df[col_name] = values
        
        # –¶–∏–∫–ª–∏—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        cyclic_features = {
            'month_sin': np.sin(2 * np.pi * df['month'] / 12),
            'month_cos': np.cos(2 * np.pi * df['month'] / 12),
            'day_of_week_sin': np.sin(2 * np.pi * df['day_of_week'] / 7),
            'day_of_week_cos': np.cos(2 * np.pi * df['day_of_week'] / 7),
        }
        
        for col_name, values in cyclic_features.items():
            if col_name not in df.columns:
                df[col_name] = values
        
        return df
    
    def _create_fourier_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ–∑–æ–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –§—É—Ä—å–µ
        """
        seasons = [7, 30]  # –Ω–µ–¥–µ–ª—å–Ω–∞—è –∏ –º–µ—Å—è—á–Ω–∞—è —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å
        t = np.arange(len(df))
        
        for season in seasons:
            fourier_cols = {
                f'fourier_sin_{season}': np.sin(2 * np.pi * t / season),
                f'fourier_cos_{season}': np.cos(2 * np.pi * t / season),
                f'fourier_sin_{season}_2': np.sin(4 * np.pi * t / season),
                f'fourier_cos_{season}_2': np.cos(4 * np.pi * t / season),
            }
            
            for col_name, values in fourier_cols.items():
                if col_name not in df.columns:
                    df[col_name] = values
        
        return df
    
    def apply_target_transformations(self, df: pd.DataFrame, 
                                     apply_log: bool = True, 
                                     apply_boxcox: bool = True) -> Tuple[pd.DataFrame, Dict]:
        """
        –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π –∫ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        """
        df_transformed = df.copy()
        transformation_params = {}
        
        # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
        if apply_log and (df_transformed[self.target_col] > 0).all():
            log_col = f'{self.target_col}_log'
            if log_col not in df_transformed.columns:
                df_transformed[log_col] = np.log(df_transformed[self.target_col])
                transformation_params['log_applied'] = True
                transformation_params['log_col'] = log_col
            else:
                transformation_params['log_applied'] = False
        else:
            transformation_params['log_applied'] = False
            
        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ë–æ–∫—Å–∞-–ö–æ–∫—Å–∞
        if apply_boxcox and (df_transformed[self.target_col] > 0).all():
            y_positive = df_transformed[self.target_col][df_transformed[self.target_col] > 0]
            if len(y_positive) > 0:
                # –î–æ–±–∞–≤–ª—è–µ–º –º–∞–ª–µ–Ω—å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –Ω—É–ª–µ–π
                y_for_boxcox = df_transformed[self.target_col] + 1e-10
                self.lambda_boxcox = stats.boxcox_normmax(y_for_boxcox)
                transformation_params['lambda_boxcox'] = self.lambda_boxcox
                
                boxcox_col = f'{self.target_col}_boxcox'
                if boxcox_col not in df_transformed.columns:
                    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: stats.boxcox —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º lmbda –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ª—å–∫–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                    df_transformed[boxcox_col] = stats.boxcox(
                        y_for_boxcox, 
                        lmbda=self.lambda_boxcox
                    )
                    transformation_params['boxcox_applied'] = True
                    transformation_params['boxcox_col'] = boxcox_col
                else:
                    transformation_params['boxcox_applied'] = False
            else:
                transformation_params['boxcox_applied'] = False
        else:
            transformation_params['boxcox_applied'] = False
        
        return df_transformed, transformation_params
    
    def inverse_target_transformations(self, predictions: np.ndarray,
                                       transformation_type: str = 'boxcox') -> np.ndarray:
        """
        –û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        """
        if transformation_type == 'boxcox' and self.lambda_boxcox is not None:
            return inv_boxcox(predictions, self.lambda_boxcox)
        elif transformation_type == 'log':
            return np.exp(predictions)
        else:
            return predictions
    
    def get_feature_categories(self) -> Dict[str, List[str]]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        """
        return {
            '–ò—Å—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏': [self.date_col, self.target_col],
            '–õ–∞–≥–∏': [f'{self.target_col}_lag_{lag}' for lag in [1, 2, 3, 7, 14, 30]],
            '–°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞ (mean)': [f'{self.target_col}_rolling_mean_{window}' for window in [7, 14, 30]],
            '–°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞ (std)': [f'{self.target_col}_rolling_std_{window}' for window in [7, 14, 30]],
            '–°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞ (min)': [f'{self.target_col}_rolling_min_{window}' for window in [7, 14, 30]],
            '–°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞ (max)': [f'{self.target_col}_rolling_max_{window}' for window in [7, 14, 30]],
            '–°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞ (median)': [f'{self.target_col}_rolling_median_{window}' for window in [7, 14, 30]],
            '–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ': [f'{self.target_col}_exp_smooth_{alpha}' for alpha in [0.3, 0.5, 0.7]],
            '–í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏': ['day_of_week', 'day_of_month', 'month', 'quarter', 
                                   'week_of_year', 'year', 'is_weekend', 'is_holiday'],
            '–¶–∏–∫–ª–∏—á–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏': ['month_sin', 'month_cos', 'day_of_week_sin', 'day_of_week_cos'],
            '–§—É—Ä—å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã': [f'fourier_sin_{season}' for season in [7, 30]] + 
                              [f'fourier_cos_{season}' for season in [7, 30]] +
                              [f'fourier_sin_{season}_2' for season in [7, 30]] +
                              [f'fourier_cos_{season}_2' for season in [7, 30]]
        }


# ============================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ============================================================

def create_time_series_features(df: pd.DataFrame, 
                                date_col: str, 
                                target_col: str,
                                apply_transformations: bool = False,
                                include_fourier: bool = True) -> Tuple[pd.DataFrame, Dict]:
    """
    –ë—ã—Å—Ç—Ä–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞
    """
    print(f"üõ†Ô∏è –ù–∞—á–∏–Ω–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    print(f"   - –†–∞–∑–º–µ—Ä –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {df.shape}")
    print(f"   - –î–∞—Ç–∞: {date_col}, –¶–µ–ª—å: {target_col}")
    
    feature_engineer = TimeSeriesFeatureEngineer(date_col, target_col)
    df_features = feature_engineer.create_features(df)
    
    # –ï—Å–ª–∏ –Ω–µ –≤–∫–ª—é—á–∞—Ç—å –§—É—Ä—å–µ, —É–¥–∞–ª—è–µ–º —ç—Ç–∏ –∫–æ–ª–æ–Ω–∫–∏
    if not include_fourier:
        fourier_cols = [col for col in df_features.columns if 'fourier' in col]
        df_features = df_features.drop(columns=fourier_cols)
    
    transformation_info = {}
    if apply_transformations:
        df_features, transformation_info = feature_engineer.apply_target_transformations(df_features)
    
    feature_categories = feature_engineer.get_feature_categories()
    
    # –ò—Å–∫–ª—é—á–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–∑ created_features
    created_features = []
    for col in df_features.columns:
        if col not in [date_col, target_col]:
            created_features.append(col)
    
    feature_info = {
        'original_features': [date_col, target_col],
        'created_features': created_features,
        'total_features': len(df_features.columns),
        'feature_categories': feature_categories,
        'transformation_info': transformation_info,
        'engineer': feature_engineer
    }
    
    # –í–û–¢ –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï - –í–û–ó–í–†–ê–©–ê–ï–ú –î–ê–ù–ù–´–ï!
    return df_features, feature_info


def analyze_feature_importance(df_features: pd.DataFrame, 
                               target_col: str,
                               date_col: str,
                               top_n: int = 20) -> pd.DataFrame:
    """
    –ê–Ω–∞–ª–∏–∑ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
    """
    numeric_cols = df_features.select_dtypes(include=[np.number]).columns.tolist()
    feature_cols = [col for col in numeric_cols if col != target_col and col != date_col]
    
    correlations = []
    for col in feature_cols:
        valid_idx = df_features[col].notna() & df_features[target_col].notna()
        if valid_idx.sum() > 0:
            corr = np.corrcoef(df_features.loc[valid_idx, col], 
                               df_features.loc[valid_idx, target_col])[0, 1]
            correlations.append((col, corr))
    
    if correlations:
        corr_df = pd.DataFrame(correlations, columns=['–ü—Ä–∏–∑–Ω–∞–∫', '–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è'])
        corr_df['–ê–±—Å_–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è'] = corr_df['–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è'].abs()
        corr_df = corr_df.sort_values('–ê–±—Å_–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è', ascending=False)
        
        return corr_df.head(top_n)
    else:
        return pd.DataFrame(columns=['–ü—Ä–∏–∑–Ω–∞–∫', '–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è', '–ê–±—Å_–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è'])


# ============================================================
# –ò–ù–¢–ï–†–§–ï–ô–° –î–õ–Ø STREAMLIT
# ============================================================

def show_feature_engineering_ui(df, date_col, target_col):
    """
    –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ Streamlit
    """
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ session_state
    if 'df_features' in st.session_state and 'feature_info' in st.session_state:
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        return st.session_state.df_features, st.session_state.feature_info
    
    # –ï—Å–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –µ—â–µ –Ω–µ —Å–æ–∑–¥–∞–Ω—ã, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∏—Ö —Å–æ–∑–¥–∞–Ω–∏—è
    st.markdown("### ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    
    col1, col2 = st.columns(2)
    with col1:
        apply_transformations = st.checkbox("–ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∫ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π", value=True)
        st.caption("–õ–æ–≥–∞—Ä–∏—Ñ–º (–µ—Å–ª–∏ y > 0) –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ë–æ–∫—Å–∞-–ö–æ–∫—Å–∞")
    
    with col2:
        include_fourier = st.checkbox("–î–æ–±–∞–≤–∏—Ç—å –§—É—Ä—å–µ-–ø—Ä–∏–∑–Ω–∞–∫–∏", value=True)
        st.caption("–°–µ–∑–æ–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–Ω–µ–¥–µ–ª—å–Ω–∞—è –∏ –º–µ—Å—è—á–Ω–∞—è)")
    
    # –ö–Ω–æ–ø–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    if st.button("üöÄ –°–æ–∑–¥–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏", type="primary", use_container_width=True):
        with st.spinner("–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤..."):
            try:
                # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
                df_features, feature_info = create_time_series_features(
                    df, 
                    date_col, 
                    target_col,
                    apply_transformations=apply_transformations,
                    include_fourier=include_fourier
                )
                
                st.success(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(feature_info['created_features'])} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤!")
                
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                return df_features, feature_info
                
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {str(e)}")
                return None
    
    # –ï—Å–ª–∏ –∫–Ω–æ–ø–∫–∞ –Ω–µ –Ω–∞–∂–∞—Ç–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None
    return None


def _display_feature_engineering_results(df_features, feature_info, date_col, target_col):
    """
    –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥–∞
    """
    # 1. –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    st.subheader("üìä –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
    
    info_col1, info_col2, info_col3, info_col4 = st.columns(4)
    
    with info_col1:
        st.metric("–ò—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", len(feature_info['original_features']))
    
    with info_col2:
        st.metric("–°–æ–∑–¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", len(feature_info['created_features']))
    
    with info_col3:
        st.metric("–í—Å–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", feature_info['total_features'])
    
    with info_col4:
        st.metric("–ó–∞–ø–∏—Å–µ–π", len(df_features))
    
    # 2. –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    st.subheader("üóÇÔ∏è –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    
    category_stats = []
    for category, features in feature_info['feature_categories'].items():
        # –°—á–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        existing_features = [f for f in features if f in df_features.columns]
        if existing_features:
            category_stats.append({
                '–ö–∞—Ç–µ–≥–æ—Ä–∏—è': category,
                '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤': len(existing_features),
                '–ü—Ä–∏–º–µ—Ä—ã': ', '.join(existing_features[:3]) + ('...' if len(existing_features) > 3 else '')
            })
    
    if category_stats:
        st.dataframe(pd.DataFrame(category_stats), width='stretch')
    
    # 3. –ü—Ä–æ—Å–º–æ—Ç—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    st.subheader("üëÅÔ∏è –ü—Ä–æ—Å–º–æ—Ç—Ä —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    
    if category_stats:
        selected_category = st.selectbox(
            "–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—é –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞",
            options=[cat['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'] for cat in category_stats],
            key="category_selector"
        )
        
        if selected_category:
            # –ù–∞—Ö–æ–¥–∏–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            features_to_show = []
            for cat in category_stats:
                if cat['–ö–∞—Ç–µ–≥–æ—Ä–∏—è'] == selected_category:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ —Å—Ç—Ä–æ–∫–∏ –ø—Ä–∏–º–µ—Ä–æ–≤
                    example_str = cat['–ü—Ä–∏–º–µ—Ä—ã']
                    if '...' in example_str:
                        features_to_show = example_str.replace('...', '').split(', ')
                    else:
                        features_to_show = example_str.split(', ')
                    break
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤
            features_to_show = [f.strip() for f in features_to_show]
            features_to_show = list(set(features_to_show))  # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            cols_to_show = []
            seen_columns = set()
            
            # –°–Ω–∞—á–∞–ª–∞ –¥–æ–±–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
            for col in [date_col, target_col]:
                if col in df_features.columns and col not in seen_columns:
                    cols_to_show.append(col)
                    seen_columns.add(col)
            
            # –ó–∞—Ç–µ–º –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            for feature in features_to_show:
                if feature in df_features.columns and feature not in seen_columns:
                    cols_to_show.append(feature)
                    seen_columns.add(feature)
            
            if cols_to_show:
                st.dataframe(df_features[cols_to_show].head(10), width='stretch')
    
    # 4. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    st.subheader("üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    
    available_features = feature_info['created_features']
    # –í—ã–±–∏—Ä–∞–µ–º –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    interesting_features = []
    for feat in available_features:
        if any(keyword in feat for keyword in ['lag', 'rolling', 'exp_smooth']):
            interesting_features.append(feat)
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    interesting_features = interesting_features[:6]
    
    if interesting_features:
        num_features = len(interesting_features)
        rows = (num_features + 1) // 2
        
        fig = make_subplots(
            rows=rows, cols=2,
            subplot_titles=interesting_features,
            vertical_spacing=0.1,
            horizontal_spacing=0.1
        )
        
        for i, feat in enumerate(interesting_features):
            row = i // 2 + 1
            col = i % 2 + 1
            fig.add_trace(
                go.Scatter(
                    x=df_features[date_col], 
                    y=df_features[feat], 
                    mode='lines',
                    name=feat,
                    line=dict(width=1)
                ),
                row=row, col=col
            )
        
        fig.update_layout(
            height=300 * rows, 
            showlegend=False,
            title_text="–ü—Ä–∏–º–µ—Ä—ã —Å–æ–∑–¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"
        )
        st.plotly_chart(fig, width='stretch')
    
    # 5. –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
    st.subheader("üîó –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π")
    
    try:
        corr_df = analyze_feature_importance(df_features, target_col, date_col, top_n=15)
        
        if not corr_df.empty:
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
            fig_corr = go.Figure()
            corr_df_sorted = corr_df.sort_values('–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è', ascending=True)
            colors = ['red' if x < 0 else 'green' for x in corr_df_sorted['–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è']]
            
            fig_corr.add_trace(go.Bar(
                x=corr_df_sorted['–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è'],
                y=corr_df_sorted['–ü—Ä–∏–∑–Ω–∞–∫'],
                orientation='h',
                marker_color=colors,
                text=corr_df_sorted['–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è'].round(3),
                textposition='auto'
            ))
            
            fig_corr.update_layout(
                title="–¢–æ–ø-15 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π",
                height=500,
                xaxis_title="–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è",
                yaxis_title="–ü—Ä–∏–∑–Ω–∞–∫"
            )
            st.plotly_chart(fig_corr, width='stretch')
            
            # –¢–∞–±–ª–∏—Ü–∞ —Å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è–º–∏
            st.dataframe(corr_df, width='stretch')
        else:
            st.info("–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—á–∏—Å–ª–∏—Ç—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏. –í–æ–∑–º–æ–∂–Ω–æ, –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.")
            
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏: {str(e)}")
    
    # 6. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è—Ö
    if feature_info['transformation_info']:
        trans_info = feature_info['transformation_info']
        
        if trans_info.get('log_applied') or trans_info.get('boxcox_applied'):
            st.subheader("üîÑ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è—Ö")
            
            if trans_info.get('log_applied'):
                st.success(f"‚úÖ –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–æ: {trans_info.get('log_col', 'N/A')}")
            
            if trans_info.get('boxcox_applied'):
                st.success(f"‚úÖ –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ë–æ–∫—Å–∞-–ö–æ–∫—Å–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–æ: Œª={trans_info.get('lambda_boxcox', 'N/A'):.4f}")
    
    # –ù–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–∏—á–µ–≥–æ, —Ç.–∫. —ç—Ç–æ –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è