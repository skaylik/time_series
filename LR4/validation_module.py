# validation_module.py - –ú–æ–¥—É–ª—å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ —Ä–∞–∑–±–∏–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö (–≠—Ç–∞–ø 2)

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import Tuple, Dict, List, Optional
import warnings
warnings.filterwarnings('ignore')

# –ò–º–ø–æ—Ä—Ç –¥–ª—è Streamlit –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
import streamlit as st
import plotly.graph_objects as go

# –ò–º–ø–æ—Ä—Ç –¥–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏
from sklearn.model_selection import TimeSeriesSplit

# ============================================================
# –ö–õ–ê–°–°–´ –î–õ–Ø –í–ê–õ–ò–î–ê–¶–ò–ò
# ============================================================

class PurgedWalkForward:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ Purged Walk-Forward –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å gap
    """
    
    def __init__(self, n_splits: int = 5, gap: int = 7, max_train_size: int = 365):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Purged Walk-Forward
        
        Parameters:
        -----------
        n_splits : int
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤
        gap : int
            –†–∞–∑—Ä—ã–≤ –º–µ–∂–¥—É –æ–±—É—á–∞—é—â–µ–π –∏ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∞–º–∏
        max_train_size : int
            –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏
        """
        self.n_splits = n_splits
        self.gap = gap
        self.max_train_size = max_train_size
        self.folds_info = []
    
    def split(self, X: pd.DataFrame) -> List[Tuple]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞–∑–±–∏–µ–Ω–∏–π
        
        Parameters:
        -----------
        X : pd.DataFrame
            –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            
        Returns:
        --------
        List[Tuple]
            –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (train_indices, test_indices)
        """
        n_samples = len(X)
        indices = np.arange(n_samples)
        
        # –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –æ–∫–Ω–∞
        test_size = (n_samples - self.max_train_size) // (self.n_splits + 1)
        
        folds = []
        self.folds_info = []
        
        for i in range(self.n_splits):
            # –í—ã—á–∏—Å–ª—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã
            train_end = n_samples - test_size * (self.n_splits - i) - self.gap
            test_start = train_end + self.gap
            test_end = test_start + test_size
            
            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –≥—Ä–∞–Ω–∏—Ü—ã
            train_start = max(0, train_end - self.max_train_size)
            
            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
            train_idx = indices[train_start:train_end]
            test_idx = indices[test_start:test_end]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∏–Ω–¥–µ–∫—Å—ã –Ω–µ –ø—É—Å—Ç—ã–µ
            if len(train_idx) > 0 and len(test_idx) > 0:
                folds.append((train_idx, test_idx))
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–æ–ª–¥–µ
                fold_info = {
                    'fold': i + 1,
                    'train_size': len(train_idx),
                    'test_size': len(test_idx),
                    'train_start': train_start,
                    'train_end': train_end,
                    'test_start': test_start,
                    'test_end': test_end,
                    'gap': self.gap
                }
                self.folds_info.append(fold_info)
        
        return folds

class TimeSeriesValidator:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
    """
    
    def __init__(self):
        self.split_data = None
        self.split_stats = None
        self.tscv_folds = None
        self.purged_folds = None
        
    def chronological_split(self, df: pd.DataFrame, date_col: str, 
                           target_col: str, split_ratios: Dict) -> Dict:
        """
        –•—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        
        Parameters:
        -----------
        df : pd.DataFrame
            –ò—Å—Ö–æ–¥–Ω—ã–π DataFrame
        date_col : str
            –ö–æ–ª–æ–Ω–∫–∞ —Å –¥–∞—Ç–æ–π
        target_col : str
            –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
        split_ratios : Dict
            –°–ª–æ–≤–∞—Ä—å —Å —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è–º–∏ —Ä–∞–∑–±–∏–µ–Ω–∏—è
            
        Returns:
        --------
        Dict
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–∞–∑–±–∏—Ç—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
        df_sorted = df.sort_values(date_col).copy()
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã —Ä–∞–∑–±–∏–µ–Ω–∏—è
        total_len = len(df_sorted)
        train_end = int(total_len * split_ratios['train'])
        val_end = train_end + int(total_len * split_ratios['val'])
        
        # –†–∞–∑–±–∏–≤–∞–µ–º
        train_data = df_sorted.iloc[:train_end]
        val_data = df_sorted.iloc[train_end:val_end]
        test_data = df_sorted.iloc[val_end:]
        
        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = {
            'train': {
                'size': len(train_data),
                'start': train_data[date_col].min(),
                'end': train_data[date_col].max(),
                'target_mean': train_data[target_col].mean()
            },
            'val': {
                'size': len(val_data),
                'start': val_data[date_col].min(),
                'end': val_data[date_col].max(),
                'target_mean': val_data[target_col].mean()
            },
            'test': {
                'size': len(test_data),
                'start': test_data[date_col].min(),
                'end': test_data[date_col].max(),
                'target_mean': test_data[target_col].mean()
            }
        }
        
        return {
            'train': train_data,
            'val': val_data,
            'test': test_data,
            'stats': stats
        }
    
    def time_series_cross_validation(self, df: pd.DataFrame, date_col: str,
                                    n_splits: int = 5, max_train_size: int = 365) -> Dict:
        """
        TimeSeriesSplit –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
        
        Parameters:
        -----------
        df : pd.DataFrame
            –ò—Å—Ö–æ–¥–Ω—ã–π DataFrame
        date_col : str
            –ö–æ–ª–æ–Ω–∫–∞ —Å –¥–∞—Ç–æ–π
        n_splits : int
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤
        max_train_size : int
            –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏
            
        Returns:
        --------
        Dict
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ñ–æ–ª–¥–∞—Ö
        """
        df_sorted = df.sort_values(date_col).reset_index(drop=True)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º TimeSeriesSplit –∏–∑ sklearn —Å max_train_size
        tscv = TimeSeriesSplit(
            n_splits=n_splits,
            max_train_size=max_train_size
        )
        
        folds = []
        for fold_idx, (train_idx, test_idx) in enumerate(tscv.split(df_sorted)):
            train_data = df_sorted.iloc[train_idx]
            test_data = df_sorted.iloc[test_idx]
            
            folds.append({
                'fold': fold_idx + 1,
                'train_size': len(train_data),
                'test_size': len(test_data),
                'train_start': train_data[date_col].min(),
                'train_end': train_data[date_col].max(),
                'test_start': test_data[date_col].min(),
                'test_end': test_data[date_col].max(),
                'train_indices': train_idx.tolist(),
                'test_indices': test_idx.tolist()
            })
        
        return {
            'folds': folds,
            'n_splits': n_splits,
            'max_train_size': max_train_size,
            'total_samples': len(df_sorted)
        }
    
    def purged_walk_forward_validation(self, df: pd.DataFrame, date_col: str,
                                      n_splits: int = 5, gap: int = 7, 
                                      max_train_size: int = 365) -> Dict:
        """
        Purged Walk-Forward –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å gap
        
        Parameters:
        -----------
        df : pd.DataFrame
            –ò—Å—Ö–æ–¥–Ω—ã–π DataFrame
        date_col : str
            –ö–æ–ª–æ–Ω–∫–∞ —Å –¥–∞—Ç–æ–π
        n_splits : int
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤
        gap : int
            –†–∞–∑—Ä—ã–≤ –º–µ–∂–¥—É –æ–±—É—á–∞—é—â–µ–π –∏ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∞–º–∏
        max_train_size : int
            –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏
            
        Returns:
        --------
        Dict
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ñ–æ–ª–¥–∞—Ö
        """
        df_sorted = df.sort_values(date_col).reset_index(drop=True)
        
        # –°–æ–∑–¥–∞–µ–º Purged Walk-Forward –≤–∞–ª–∏–¥–∞—Ç–æ—Ä
        pwf = PurgedWalkForward(
            n_splits=n_splits,
            gap=gap,
            max_train_size=max_train_size
        )
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–±–∏–µ–Ω–∏—è
        splits = pwf.split(df_sorted)
        
        folds = []
        for i, (train_idx, test_idx) in enumerate(splits):
            train_data = df_sorted.iloc[train_idx]
            test_data = df_sorted.iloc[test_idx]
            
            folds.append({
                'fold': i + 1,
                'train_size': len(train_data),
                'test_size': len(test_data),
                'train_start': train_data[date_col].min(),
                'train_end': train_data[date_col].max(),
                'test_start': test_data[date_col].min(),
                'test_end': test_data[date_col].max(),
                'gap': gap,
                'train_indices': train_idx.tolist(),
                'test_indices': test_idx.tolist()
            })
        
        return {
            'folds': folds,
            'n_splits': n_splits,
            'gap': gap,
            'max_train_size': max_train_size,
            'total_samples': len(df_sorted)
        }

# ============================================================
# –§–£–ù–ö–¶–ò–ò –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ò
# ============================================================

def plot_validation_splits(chronological_stats: Dict, 
                          tscv_folds: Optional[Dict] = None,
                          purged_folds: Optional[Dict] = None,
                          date_col: str = 'date'):
    """
    –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ —Ä–∞–∑–±–∏–µ–Ω–∏–π
    """
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–≥—É—Ä—É —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫–∞–º–∏
    fig = go.Figure()
    
    # 1. –•—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ
    colors = ['#2E86AB', '#A23B72', '#F18F01']
    y_positions = [2, 1, 0]  # –ü–æ–∑–∏—Ü–∏–∏ –Ω–∞ –æ—Å–∏ Y
    
    for idx, (split_name, color) in enumerate(zip(['train', 'val', 'test'], colors)):
        stats = chronological_stats[split_name]
        y_pos = y_positions[idx]
        
        fig.add_trace(go.Scatter(
            x=[stats['start'], stats['end']],
            y=[f"–•—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ: {split_name}", f"–•—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ: {split_name}"],
            mode='lines+markers',
            name=f"{split_name} ({stats['size']} –∑–∞–ø–∏—Å–µ–π)",
            line=dict(color=color, width=8),
            marker=dict(size=10),
            legendgroup="chronological",
            showlegend=True
        ))
    
    # 2. TimeSeriesSplit —Ñ–æ–ª–¥—ã
    if tscv_folds:
        for fold in tscv_folds['folds']:
            y_offset = 0.2 * (fold['fold'] - 1)  # –°–º–µ—â–µ–Ω–∏–µ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ñ–æ–ª–¥–æ–≤
            
            fig.add_trace(go.Scatter(
                x=[fold['train_start'], fold['train_end']],
                y=[f"TimeSeriesSplit: Fold {fold['fold']} train", f"TimeSeriesSplit: Fold {fold['fold']} train"],
                mode='lines',
                name=f"TS Fold {fold['fold']} train",
                line=dict(color='lightblue', width=4, dash='dash'),
                legendgroup="tscv",
                showlegend=True if fold['fold'] == 1 else False
            ))
            
            fig.add_trace(go.Scatter(
                x=[fold['test_start'], fold['test_end']],
                y=[f"TimeSeriesSplit: Fold {fold['fold']} test", f"TimeSeriesSplit: Fold {fold['fold']} test"],
                mode='lines',
                name=f"TS Fold {fold['fold']} test",
                line=dict(color='orange', width=4, dash='dash'),
                legendgroup="tscv",
                showlegend=True if fold['fold'] == 1 else False
            ))
    
    # 3. Purged Walk-Forward —Ñ–æ–ª–¥—ã
    if purged_folds:
        for fold in purged_folds['folds']:
            y_offset = 0.2 * (fold['fold'] - 1) + 1  # –°–º–µ—â–µ–Ω–∏–µ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ñ–æ–ª–¥–æ–≤
            
            fig.add_trace(go.Scatter(
                x=[fold['train_start'], fold['train_end']],
                y=[f"PurgedWF: Fold {fold['fold']} train", f"PurgedWF: Fold {fold['fold']} train"],
                mode='lines',
                name=f"Purged Fold {fold['fold']} train",
                line=dict(color='green', width=4, dash='dot'),
                legendgroup="purged",
                showlegend=True if fold['fold'] == 1 else False
            ))
            
            fig.add_trace(go.Scatter(
                x=[fold['test_start'], fold['test_end']],
                y=[f"PurgedWF: Fold {fold['fold']} test", f"PurgedWF: Fold {fold['fold']} test"],
                mode='lines',
                name=f"Purged Fold {fold['fold']} test",
                line=dict(color='red', width=4, dash='dot'),
                legendgroup="purged",
                showlegend=True if fold['fold'] == 1 else False
            ))
    
    fig.update_layout(
        title="–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏",
        xaxis_title="–î–∞—Ç–∞",
        yaxis_title="–¢–∏–ø —Ä–∞–∑–±–∏–µ–Ω–∏—è",
        height=500,
        showlegend=True,
        legend=dict(
            yanchor="top",
            y=0.99,
            xanchor="left",
            x=0.01
        )
    )
    
    return fig

def show_folds_table(folds_data: Dict, title: str):
    """
    –ü–æ–∫–∞–∑–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ñ–æ–ª–¥–∞—Ö
    """
    st.subheader(title)
    
    table_data = []
    for fold in folds_data['folds']:
        table_data.append({
            '–§–æ–ª–¥': fold['fold'],
            'Train —Ä–∞–∑–º–µ—Ä': fold['train_size'],
            'Test —Ä–∞–∑–º–µ—Ä': fold['test_size'],
            'Train –Ω–∞—á–∞–ª–æ': fold['train_start'].strftime('%Y-%m-%d'),
            'Train –∫–æ–Ω–µ—Ü': fold['train_end'].strftime('%Y-%m-%d'),
            'Test –Ω–∞—á–∞–ª–æ': fold['test_start'].strftime('%Y-%m-%d'),
            'Test –∫–æ–Ω–µ—Ü': fold['test_end'].strftime('%Y-%m-%d'),
            'Gap': fold.get('gap', 0)
        })
    
    if table_data:
        st.dataframe(pd.DataFrame(table_data), width='stretch')

# ============================================================
# –ò–ù–¢–ï–†–§–ï–ô–° –î–õ–Ø STREAMLIT
# ============================================================

def show_validation_interface(df: pd.DataFrame, date_col: str, target_col: str):
    """
    –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö
    """
    print(f"üìä –ù–∞—á–∞–ª–æ –≤–∞–ª–∏–¥–∞—Ü–∏–∏...")
    print(f"   - df_features –≤ session_state: {'df_features' in st.session_state}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    if 'df_features' not in st.session_state:
        st.error("‚ùå –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≠—Ç–∞–ø 1: –ò–Ω–∂–∏–Ω–∏—Ä–∏–Ω–≥ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤!")
        return
    
    df_features = st.session_state.df_features
    
    st.info("""
    ### üìã –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –≠—Ç–∞–ø–∞ 2:
    1. **–•—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ**: train (60%), val (20%), test (20%)
    2. **TimeSeriesSplit**: n_splits=5, max_train_size=365
    3. **Purged Walk-Forward**: gap –º–µ–∂–¥—É train –∏ test, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —É—Ç–µ—á–∫–∏
    """)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–æ—Ä–º—É –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏
    with st.form(key='validation_form'):
        # 1. –•–†–û–ù–û–õ–û–ì–ò–ß–ï–°–ö–û–ï –†–ê–ó–ë–ò–ï–ù–ò–ï
        st.subheader("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            train_size = st.slider("Train —Ä–∞–∑–º–µ—Ä (%)", 50, 80, 60, 5) / 100
            st.caption(f"–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {train_size*100:.0f}%")
        
        with col2:
            val_size = st.slider("Validation —Ä–∞–∑–º–µ—Ä (%)", 10, 40, 20, 5) / 100
            st.caption(f"–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞: {val_size*100:.0f}%")
        
        with col3:
            test_size = st.slider("Test —Ä–∞–∑–º–µ—Ä (%)", 10, 40, 20, 5) / 100
            st.caption(f"–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {test_size*100:.0f}%")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É–º–º—ã
        total = train_size + val_size + test_size
        if abs(total - 1.0) > 0.01:
            st.warning(f"–°—É–º–º–∞ –¥–æ–ª–µ–π –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ä–∞–≤–Ω–∞ 100%. –¢–µ–∫—É—â–∞—è —Å—É–º–º–∞: {total*100:.0f}%")
        
        st.markdown("---")
        
        # 2. TIMESERIESSPLIT –ù–ê–°–¢–†–û–ô–ö–ò
        st.subheader("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ TimeSeriesSplit")
        
        col4, col5 = st.columns(2)
        
        with col4:
            n_splits = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤ (n_splits)", 2, 10, 5, 1)
        
        with col5:
            max_train_size = st.slider("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä train (max_train_size)", 100, 1000, 365, 10)
        
        st.markdown("---")
        
        # 3. PURGED WALK-FORWARD –ù–ê–°–¢–†–û–ô–ö–ò
        st.subheader("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Purged Walk-Forward")
        
        col6, col7 = st.columns(2)
        
        with col6:
            gap_size = st.slider("–†–∞–∑–º–µ—Ä gap", 1, 30, 7, 1)
            st.caption("–†–∞–∑—Ä—ã–≤ –º–µ–∂–¥—É train –∏ test –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —É—Ç–µ—á–∫–∏")
        
        with col7:
            pwf_max_train = st.slider("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä train (Purged)", 100, 1000, 365, 10)
        
        # –ö–Ω–æ–ø–∫–∞ –∑–∞–ø—É—Å–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤–Ω—É—Ç—Ä–∏ —Ñ–æ—Ä–º—ã
        submit_button = st.form_submit_button(
            "üöÄ –í—ã–ø–æ–ª–Ω–∏—Ç—å –≤—Å–µ —Ç–∏–ø—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏", 
            type="primary", 
            use_container_width=True
        )
    
    # –ï—Å–ª–∏ —Ñ–æ—Ä–º–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞, –≤—ã–ø–æ–ª–Ω—è–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é
    if submit_button:
        with st.spinner("–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏..."):
            try:
                # –°–æ–∑–¥–∞–µ–º –≤–∞–ª–∏–¥–∞—Ç–æ—Ä
                validator = TimeSeriesValidator()
                
                # 1. –•—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ
                split_result = validator.chronological_split(
                    df=df_features,
                    date_col=date_col,
                    target_col=target_col,
                    split_ratios={
                        'train': train_size,
                        'val': val_size,
                        'test': test_size
                    }
                )
                
                # 2. TimeSeriesSplit –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è
                tscv_result = validator.time_series_cross_validation(
                    df=split_result['train'],  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ train –¥–∞–Ω–Ω—ã–µ
                    date_col=date_col,
                    n_splits=n_splits,
                    max_train_size=max_train_size
                )
                
                # 3. Purged Walk-Forward –≤–∞–ª–∏–¥–∞—Ü–∏—è
                purged_result = validator.purged_walk_forward_validation(
                    df=split_result['train'],  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ train –¥–∞–Ω–Ω—ã–µ
                    date_col=date_col,
                    n_splits=n_splits,
                    gap=gap_size,
                    max_train_size=pwf_max_train
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ session state
                st.session_state.split_data = split_result
                st.session_state.tscv_folds = tscv_result
                st.session_state.purged_folds = purged_result
                
                st.success("‚úÖ –í—Å–µ —Ç–∏–ø—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã!")
                
            except Exception as e:
                st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {str(e)}")
                print(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
    if 'split_data' in st.session_state:
        split_result = st.session_state.split_data
        
        st.markdown("---")
        st.success("‚úÖ –≠—Ç–∞–ø 2: –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω!")
        
        # 1. –û–ë–©–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø
        st.subheader("üìä –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–∞–∑–±–∏–µ–Ω–∏—è—Ö")
        
        info_cols = st.columns(4)
        
        with info_cols[0]:
            st.metric("–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π", len(df_features))
        
        with info_cols[1]:
            train_size = split_result['stats']['train']['size']
            st.metric("Train –∑–∞–ø–∏—Å–µ–π", train_size)
        
        with info_cols[2]:
            val_size = split_result['stats']['val']['size']
            st.metric("Val –∑–∞–ø–∏—Å–µ–π", val_size)
        
        with info_cols[3]:
            test_size = split_result['stats']['test']['size']
            st.metric("Test –∑–∞–ø–∏—Å–µ–π", test_size)
        
        st.markdown("---")
        
        # 2. –•–†–û–ù–û–õ–û–ì–ò–ß–ï–°–ö–û–ï –†–ê–ó–ë–ò–ï–ù–ò–ï
        st.subheader("üìÖ –•—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ (60/20/20)")
        
        stats_cols = st.columns(3)
        colors = ['#2E86AB', '#A23B72', '#F18F01']
        
        for idx, (split_name, color) in enumerate(zip(['train', 'val', 'test'], colors)):
            with stats_cols[idx]:
                stats = split_result['stats'][split_name]
                st.metric(
                    label=f"{split_name.upper()} –≤—ã–±–æ—Ä–∫–∞",
                    value=f"{stats['size']:,} –∑–∞–ø–∏—Å–µ–π",
                    delta=f"{stats['size']/len(df_features)*100:.1f}%"
                )
        
        # –¢–∞–±–ª–∏—Ü–∞ —Å –¥–µ—Ç–∞–ª—è–º–∏ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è
        chronological_table = []
        for split_name in ['train', 'val', 'test']:
            stats = split_result['stats'][split_name]
            chronological_table.append({
                '–í—ã–±–æ—Ä–∫–∞': split_name.upper(),
                '–ó–∞–ø–∏—Å–µ–π': stats['size'],
                '–ü—Ä–æ—Ü–µ–Ω—Ç': f"{stats['size']/len(df_features)*100:.1f}%",
                '–ù–∞—á–∞–ª–æ': stats['start'].strftime('%Y-%m-%d'),
                '–ö–æ–Ω–µ—Ü': stats['end'].strftime('%Y-%m-%d'),
                '–°—Ä–µ–¥–Ω–µ–µ —Ü–µ–ª–µ–≤–æ–π': f"{stats['target_mean']:.4f}"
            })
        
        st.dataframe(pd.DataFrame(chronological_table), width='stretch')
        
        st.markdown("---")
        
        # 3. TIMESERIESSPLIT –†–ï–ó–£–õ–¨–¢–ê–¢–´
        if 'tscv_folds' in st.session_state:
            tscv_result = st.session_state.tscv_folds
            
            st.subheader(f"üîÑ TimeSeriesSplit (n_splits={tscv_result['n_splits']}, max_train_size={tscv_result['max_train_size']})")
            
            # –¢–∞–±–ª–∏—Ü–∞ —Å —Ñ–æ–ª–¥–∞–º–∏
            show_folds_table(tscv_result, "–î–µ—Ç–∞–ª–∏ —Ñ–æ–ª–¥–æ–≤ TimeSeriesSplit")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ñ–æ–ª–¥–∞–º
            fold_stats = []
            for fold in tscv_result['folds']:
                fold_stats.append({
                    '–§–æ–ª–¥': fold['fold'],
                    'Train —Ä–∞–∑–º–µ—Ä': fold['train_size'],
                    'Test —Ä–∞–∑–º–µ—Ä': fold['test_size'],
                    'Test/Train': f"{(fold['test_size']/fold['train_size'])*100:.1f}%"
                })
            
            st.dataframe(pd.DataFrame(fold_stats), width='stretch')
        
        st.markdown("---")
        
        # 4. PURGED WALK-FORWARD –†–ï–ó–£–õ–¨–¢–ê–¢–´
        if 'purged_folds' in st.session_state:
            purged_result = st.session_state.purged_folds
            
            st.subheader(f"üö∂ Purged Walk-Forward (n_splits={purged_result['n_splits']}, gap={purged_result['gap']}, max_train_size={purged_result['max_train_size']})")
            
            # –¢–∞–±–ª–∏—Ü–∞ —Å —Ñ–æ–ª–¥–∞–º–∏
            show_folds_table(purged_result, "–î–µ—Ç–∞–ª–∏ —Ñ–æ–ª–¥–æ–≤ Purged Walk-Forward")
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ gap
            st.info(f"""
            **Purged Walk-Forward —Å gap={purged_result['gap']}:**
            - Gap –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç —É—Ç–µ—á–∫—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –±—É–¥—É—â–µ–≥–æ
            - –ú–µ–∂–¥—É –∫–æ–Ω—Ü–æ–º train –∏ –Ω–∞—á–∞–ª–æ–º test –µ—Å—Ç—å —Ä–∞–∑—Ä—ã–≤ –≤ {purged_result['gap']} –¥–Ω–µ–π
            - –≠—Ç–æ –æ—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω–æ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ —Å –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–µ–π
            """)
        
        st.markdown("---")
        
        # 5. –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –í–°–ï–• –†–ê–ó–ë–ò–ï–ù–ò–ô
        st.subheader("üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏")
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        tscv_folds = st.session_state.get('tscv_folds')
        purged_folds = st.session_state.get('purged_folds')
        
        # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
        fig = plot_validation_splits(
            chronological_stats=split_result['stats'],
            tscv_folds=tscv_folds,
            purged_folds=purged_folds,
            date_col=date_col
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # 6. –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ó–ê–í–ï–†–®–ï–ù–ò–ò –≠–¢–ê–ü–ê
        st.markdown("---")
        st.success("""
        ### ‚úÖ –≠—Ç–∞–ø 2 —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!
        
        **–ß—Ç–æ —Å–¥–µ–ª–∞–Ω–æ:**
        1. ‚úÖ –•—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ: train/val/test (60/20/20)
        2. ‚úÖ TimeSeriesSplit: 5 —Ñ–æ–ª–¥–æ–≤ –¥–ª—è –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å max_train_size=365
        3. ‚úÖ Purged Walk-Forward: –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å gap –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        
        **–î–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã –¥–ª—è –≠—Ç–∞–ø–∞ 3: –ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ.**
        """)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–ª–µ–¥—É—é—â–∏—Ö —à–∞–≥–∞—Ö
        st.info("""
        **–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:** –ü–µ—Ä–µ–π–¥–∏—Ç–µ –∫ –≠—Ç–∞–ø—É 3 –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è.
        –î–ª—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ –±—É—Å—Ç–∏–Ω–≥–∞ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è Optuna, –¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π - GridSearchCV,
        –∞ —Ç–∞–∫–∂–µ –ø–æ–ª–Ω–∞—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è —Å AutoGluon.
        """)