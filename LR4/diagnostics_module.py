# diagnostics_module.py - –≠—Ç–∞–ø 6: –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–µ–π (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)

import pandas as pd
import numpy as np
import time
import warnings
warnings.filterwarnings('ignore')

import streamlit as st
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
import seaborn as sns

# –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã
from statsmodels.tsa.stattools import acf, adfuller, kpss
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from scipy import stats

# –ò–º–ø–æ—Ä—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ NaN
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

# –ò–º–ø–æ—Ä—Ç –¥–ª—è SHAP
try:
    import shap
    SHAP_AVAILABLE = True
except ImportError:
    SHAP_AVAILABLE = False

# –ò–º–ø–æ—Ä—Ç –¥–ª—è PDP
try:
    from sklearn.inspection import PartialDependenceDisplay
    PDP_AVAILABLE = True
except ImportError:
    PDP_AVAILABLE = False

# ============================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø –†–ê–ë–û–¢–´ –° –î–ê–ù–ù–´–ú–ò –ò–ó 5 –≠–¢–ê–ü–ê
# ============================================================

def extract_model_from_integrated_results():
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –∏–∑ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ 5 —ç—Ç–∞–ø–∞"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫–ª—é—á–∏, –ø–æ–¥ –∫–æ—Ç–æ—Ä—ã–º–∏ –º–æ–≥—É—Ç –±—ã—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã 5 —ç—Ç–∞–ø–∞
    integrated_results = None
    
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º integrated_results (–æ—Å–Ω–æ–≤–Ω–æ–π –∫–ª—é—á –∏–∑ 5 —ç—Ç–∞–ø–∞)
    if 'integrated_results' in st.session_state:
        integrated_results = st.session_state.integrated_results
    # –ó–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä—è–µ–º advanced_modeling_data (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∫–ª—é—á –∏–∑ 5 —ç—Ç–∞–ø–∞)
    elif 'advanced_modeling_data' in st.session_state:
        integrated_results = st.session_state.advanced_modeling_data
    # –ò –ø—Ä–æ–≤–µ—Ä—è–µ–º model_comparison_results (–µ—â–µ –æ–¥–∏–Ω –≤–æ–∑–º–æ–∂–Ω—ã–π –∫–ª—é—á)
    elif 'model_comparison_results' in st.session_state:
        integrated_results = st.session_state.model_comparison_results
    
    if integrated_results is None:
        st.error("‚ùå –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≠—Ç–∞–ø 5: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–æ–≤")
        return None, None, None
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –∏–∑ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
        
        integrated_df = None
        integrated_df_display = None
        
        # –ï—Å–ª–∏ integrated_results - —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–∞–º–∏
        if isinstance(integrated_results, dict):
            integrated_df = integrated_results.get('integrated_df')
            integrated_df_display = integrated_results.get('integrated_df_display')
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ —ç—Ç–∏—Ö –∫–ª—é—á–∞—Ö, –∏—â–µ–º –≤ –¥—Ä—É–≥–∏—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∫–ª—é—á–∞—Ö
            if integrated_df is None and 'comparison_df' in integrated_results:
                integrated_df = integrated_results.get('comparison_df')
            if integrated_df_display is None and 'comparison_df_display' in integrated_results:
                integrated_df_display = integrated_results.get('comparison_df_display')
        
        # –ï—Å–ª–∏ integrated_results - —ç—Ç–æ DataFrame –Ω–∞–ø—Ä—è–º—É—é
        elif isinstance(integrated_results, pd.DataFrame):
            integrated_df = integrated_results
            integrated_df_display = integrated_results
        
        if integrated_df is None or integrated_df.empty:
            st.error("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –º–æ–¥–µ–ª—è—Ö –≤ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö")
            return None, None, None
        
        # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –ø–æ MAE
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å—Ç–æ–ª–±—Ü–æ–≤ —Å MAE
        mae_column = None
        for possible_col in ['MAE', 'Val MAE', 'val_mae', 'CV MAE', '–°—Ä–µ–¥–Ω–∏–π MAE']:
            if possible_col in integrated_df.columns:
                mae_column = possible_col
                break
        
        if mae_column is None:
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ MAE –≤ –Ω–∞–∑–≤–∞–Ω–∏—è—Ö, –∏—â–µ–º —Å—Ç–æ–ª–±–µ—Ü, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π "MAE" –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
            for col in integrated_df.columns:
                if 'mae' in col.lower() or 'MAE' in col:
                    mae_column = col
                    break
        
        if mae_column:
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º MAE –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç
            integrated_df['MAE_numeric'] = pd.to_numeric(integrated_df[mae_column], errors='coerce')
            best_idx = integrated_df['MAE_numeric'].idxmin()
            best_row = integrated_df.loc[best_idx]
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏
            model_type = best_row.get('–¢–∏–ø', 'N/A')
            if pd.isna(model_type) or model_type == 'N/A':
                # –ü—Ä–æ–±—É–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
                model_name = best_row.get('–ù–∞–∑–≤–∞–Ω–∏–µ', '')
                if '–≠—Ç–∞–ø 3' in str(model_name) or any(x in str(model_name).lower() for x in ['ridge', 'lasso', 'random', 'forest', 'xgboost']):
                    model_type = 'ML –º–æ–¥–µ–ª—å (–≠—Ç–∞–ø 3)'
                elif '–≠—Ç–∞–ø 4' in str(model_name) or any(x in str(model_name).lower() for x in ['recursive', 'direct', 'dirrec', 'multi']):
                    model_type = '–°—Ç—Ä–∞—Ç–µ–≥–∏—è (–≠—Ç–∞–ø 4)'
            
            best_model_info = {
                '–¢–∏–ø': model_type,
                '–ù–∞–∑–≤–∞–Ω–∏–µ': best_row.get('–ù–∞–∑–≤–∞–Ω–∏–µ', best_row.get('–ú–µ—Ç–æ–¥', 'Unknown')),
                'MAE': best_row['MAE_numeric'],
                '–ü–æ–¥—Ö–æ–¥': best_row.get('–ü–æ–¥—Ö–æ–¥', 'N/A')
            }
            
            return best_model_info, integrated_results, integrated_df
            
        else:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –º–µ—Ç—Ä–∏–∫—É MAE –≤ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö")
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            st.write("–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã:", list(integrated_df.columns))
            return None, None, None
            
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏: {str(e)}")
        import traceback
        st.write(traceback.format_exc())
        return None, None, None

def prepare_data_for_diagnostics(feature_info, split_data):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –∏–∑ –≠—Ç–∞–ø–æ–≤ 1 –∏ 2"""
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –≠—Ç–∞–ø–æ–≤ 1 –∏ 2
        date_col = feature_info['original_features'][0]
        target_col = feature_info['original_features'][1]
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º split_data –∏–∑ –≠—Ç–∞–ø–∞ 2
        train_data = split_data['train'].copy()
        val_data = split_data['val'].copy()
        test_data = split_data['test'].copy()
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º train –∏ val –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (–∫–∞–∫ –≤ –≠—Ç–∞–ø–µ 3)
        X_train_full = pd.concat([train_data, val_data], axis=0)
        
        # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏: –≤—Å–µ —á–∏—Å–ª–æ–≤—ã–µ –∫—Ä–æ–º–µ –¥–∞—Ç—ã –∏ —Ü–µ–ª–∏
        feature_cols = []
        for col in X_train_full.columns:
            if col != date_col and col != target_col:
                if pd.api.types.is_numeric_dtype(X_train_full[col]):
                    feature_cols.append(col)
        
        if not feature_cols:
            st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏")
            return None, None, None, None, None
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        X_train = X_train_full[feature_cols].copy()
        y_train = X_train_full[target_col].copy()
        
        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        X_test = test_data[feature_cols].copy()
        y_test = test_data[target_col].copy()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        # 1. –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–º–∏ —Ü–µ–ª–µ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        train_mask = y_train.notna()
        test_mask = y_test.notna()
        
        X_train = X_train[train_mask]
        y_train = y_train[train_mask]
        
        X_test = X_test[test_mask]
        y_test = y_test[test_mask]
        
        # 2. –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
        # –î–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ - –º–µ–¥–∏–∞–Ω–æ–π
        imputer = SimpleImputer(strategy='median')
        X_train_imputed = imputer.fit_transform(X_train)
        X_test_imputed = imputer.transform(X_test)
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ DataFrame
        X_train = pd.DataFrame(X_train_imputed, columns=feature_cols, index=X_train.index)
        X_test = pd.DataFrame(X_test_imputed, columns=feature_cols, index=X_test.index)
        
        # 3. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
        if X_train.isna().any().any():
            st.warning(f"–í —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ—Å—Ç–∞–ª–∏—Å—å NaN –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö: {X_train.columns[X_train.isna().any()].tolist()}")
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –Ω—É–ª—è–º–∏
            X_train = X_train.fillna(0)
        
        if X_test.isna().any().any():
            st.warning(f"–í —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ—Å—Ç–∞–ª–∏—Å—å NaN –∑–Ω–∞—á–µ–Ω–∏—è –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö: {X_test.columns[X_test.isna().any()].tolist()}")
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –Ω—É–ª—è–º–∏
            X_test = X_test.fillna(0)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
        if len(X_train) == 0 or len(X_test) == 0:
            st.error("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏")
            return None, None, None, None, None
        
        st.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã. –†–∞–∑–º–µ—Ä—ã: X_train={X_train.shape}, X_test={X_test.shape}")
        
        return X_train, y_train, X_test, y_test, feature_cols
        
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏: {str(e)}")
        import traceback
        st.code(traceback.format_exc())
        return None, None, None, None, None

def get_model_object(best_model_info, integrated_results):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ 5 —ç—Ç–∞–ø–∞"""
    
    if best_model_info is None:
        return None, None
    
    model_type = best_model_info['–¢–∏–ø']
    model_name = best_model_info['–ù–∞–∑–≤–∞–Ω–∏–µ']
    
    # –î–ª—è ML –º–æ–¥–µ–ª–µ–π –∏–∑ –≠—Ç–∞–ø–∞ 3
    if '–≠—Ç–∞–ø 3' in model_type:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥–∞–Ω–Ω—ã–µ –∏–∑ –≠—Ç–∞–ø–∞ 3
        if 'modeling_results' not in st.session_state:
            st.warning(f"‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –≠—Ç–∞–ø–∞ 3 –¥–ª—è –º–æ–¥–µ–ª–∏ {model_name}")
            return None, 'standard'
        
        modeling_results = st.session_state.modeling_results
        
        try:
            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –º–æ–¥–µ–ª—å –≤ optimizer
            optimizer = modeling_results.get('optimizer')
            if optimizer and hasattr(optimizer, 'best_models'):
                # –ò—â–µ–º –º–æ–¥–µ–ª—å –ø–æ –∏–º–µ–Ω–∏
                for key, model in optimizer.best_models.items():
                    if key in model_name or model_name in key:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É –º–æ–¥–µ–ª–∏ pipeline
                        if hasattr(model, 'steps') and len(model.steps) > 1:
                            st.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –º–æ–¥–µ–ª—å —Å pipeline: {model_name}")
                        return model, 'standard'
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏, —Å–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞
            st.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –¥–∞–Ω–Ω—ã—Ö –≠—Ç–∞–ø–∞ 3. –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –∑–∞–º–µ–Ω—É.")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
            model_name_lower = model_name.lower()
            if 'ridge' in model_name_lower:
                from sklearn.linear_model import Ridge
                return Ridge(alpha=1.0), 'standard'
            elif 'lasso' in model_name_lower:
                from sklearn.linear_model import Lasso
                return Lasso(alpha=0.1, max_iter=10000), 'standard'
            elif 'random' in model_name_lower or 'forest' in model_name_lower:
                from sklearn.ensemble import RandomForestRegressor
                return RandomForestRegressor(n_estimators=50, random_state=42), 'standard'
            elif 'xgboost' in model_name_lower or 'lightgbm' in model_name_lower:
                try:
                    from xgboost import XGBRegressor
                    # XGBoost –º–æ–∂–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å NaN
                    return XGBRegressor(n_estimators=50, random_state=42, enable_categorical=False), 'standard'
                except:
                    pass
            elif 'autogluon' in model_name_lower:
                return None, 'autogluon'
            
            # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è
            from sklearn.linear_model import LinearRegression
            return LinearRegression(), 'standard'
            
        except Exception as e:
            st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏ {model_name}: {str(e)}")
            return None, 'standard'
    
    # –î–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –∏–∑ –≠—Ç–∞–ø–∞ 4 - –ø–æ–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É
    elif '–≠—Ç–∞–ø 4' in model_type:
        st.info(f"""
        ‚ö†Ô∏è **–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è (–≠—Ç–∞–ø 4)**
        
        –ú–æ–¥–µ–ª—å **{model_name}** - —ç—Ç–æ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è multi-step –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è.
        –ü–æ–ª–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –¥–ª—è —Ç–∞–∫–∏—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Ç—Ä–µ–±—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏.
        
        **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –í—ã–±–µ—Ä–∏—Ç–µ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ ML –º–æ–¥–µ–ª—å –∏–∑ –≠—Ç–∞–ø–∞ 3.
        """)
        return None, 'strategy'
    
    else:
        st.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –º–æ–¥–µ–ª–∏: {model_type}")
        return None, 'unknown'

# ============================================================
# –ö–õ–ê–°–° –î–õ–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ò –ú–û–î–ï–õ–ï–ô (–û–ë–ù–û–í–õ–ï–ù–ù–´–ô)
# ============================================================

class ModelDiagnosticsEnhanced:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –º–æ–¥–µ–ª–µ–π —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –∏–∑ 5 —ç—Ç–∞–ø–∞"""
    
    def __init__(self, model, X_train, y_train, X_test, y_test, 
                 model_name="–ú–æ–¥–µ–ª—å", model_type="standard"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        
        Parameters:
        -----------
        model : object or None
            –û–±—ä–µ–∫—Ç –º–æ–¥–µ–ª–∏ –∏–ª–∏ None –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
        X_train : pd.DataFrame
            –û–±—É—á–∞—é—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        y_train : pd.Series
            –û–±—É—á–∞—é—â–∞—è —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
        X_test : pd.DataFrame
            –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        y_test : pd.Series
            –¢–µ—Å—Ç–æ–≤–∞—è —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
        model_name : str
            –ò–º—è –º–æ–¥–µ–ª–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        model_type : str
            –¢–∏–ø –º–æ–¥–µ–ª–∏: 'standard', 'baseline', 'autogluon', 'strategy'
        """
        self.model = model
        self.X_train = X_train
        self.y_train = y_train
        self.X_test = X_test
        self.y_test = y_test
        self.model_name = model_name
        self.model_type = model_type
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ –æ—Å—Ç–∞—Ç–∫–∏
        self.y_train_pred = None
        self.y_test_pred = None
        self.train_residuals = None
        self.test_residuals = None
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤
        self.adf_results = None
        self.kpss_results = None
        self.shap_values = None
        self.feature_importance = None
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        self.model_params = {}
        
    def calculate_predictions_and_residuals(self):
        """–†–∞—Å—á–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∏ –æ—Å—Ç–∞—Ç–∫–æ–≤"""
        
        try:
            # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–≥–Ω–æ–∑
            if self.model is None:
                st.warning(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {self.model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–≥–Ω–æ–∑.")
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
                mean_value = self.y_train.mean() if len(self.y_train) > 0 else 0
                self.y_train_pred = np.full(len(self.y_train), mean_value)
                self.y_test_pred = np.full(len(self.y_test), mean_value)
                
            # –î–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
            elif self.model_type == 'standard':
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º NaN –≤ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ–º
                X_train_clean = self.X_train.copy()
                X_test_clean = self.X_test.copy()
                
                # –ï—Å–ª–∏ –µ—Å—Ç—å NaN, –∑–∞–ø–æ–ª–Ω—è–µ–º –∏—Ö
                if X_train_clean.isna().any().any():
                    imputer = SimpleImputer(strategy='median')
                    X_train_clean = imputer.fit_transform(X_train_clean)
                    X_test_clean = imputer.transform(X_test_clean)
                
                if hasattr(self.model, 'predict'):
                    try:
                        self.y_train_pred = self.model.predict(X_train_clean)
                        self.y_test_pred = self.model.predict(X_test_clean)
                    except Exception as predict_error:
                        st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {predict_error}. –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏.")
                        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –º–æ–¥–µ–ª—å –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
                        from sklearn.linear_model import LinearRegression
                        simple_model = LinearRegression()
                        simple_model.fit(X_train_clean, self.y_train)
                        self.y_train_pred = simple_model.predict(X_train_clean)
                        self.y_test_pred = simple_model.predict(X_test_clean)
                else:
                    raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –∏–º–µ–µ—Ç –º–µ—Ç–æ–¥–∞ predict")
            
            # –î–ª—è AutoGluon –º–æ–¥–µ–ª–µ–π
            elif self.model_type == 'autogluon':
                st.info("‚ö†Ô∏è AutoGluon –º–æ–¥–µ–ª—å - –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è")
                try:
                    # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å - —ç—Ç–æ AutoGluon predictor
                    if hasattr(self.model, 'predict'):
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º NaN –¥–ª—è AutoGluon
                        X_train_clean = self.X_train.fillna(0)
                        X_test_clean = self.X_test.fillna(0)
                        self.y_train_pred = self.model.predict(X_train_clean)
                        self.y_test_pred = self.model.predict(X_test_clean)
                    else:
                        raise ValueError("AutoGluon –º–æ–¥–µ–ª—å –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç predict")
                except Exception as e:
                    st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è AutoGluon: {str(e)}")
                    mean_value = self.y_train.mean() if len(self.y_train) > 0 else 0
                    self.y_train_pred = np.full(len(self.y_train), mean_value)
                    self.y_test_pred = np.full(len(self.y_test), mean_value)
            
            # –î–ª—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–π (–Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º)
            elif self.model_type == 'strategy':
                st.warning("‚ö†Ô∏è –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")
                mean_value = self.y_train.mean() if len(self.y_train) > 0 else 0
                self.y_train_pred = np.full(len(self.y_train), mean_value)
                self.y_test_pred = np.full(len(self.y_test), mean_value)
                return False
            
            else:
                st.error(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –º–æ–¥–µ–ª–∏: {self.model_type}")
                return False
            
            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞—Ç–∫–∏
            self.train_residuals = self.y_train - self.y_train_pred
            self.test_residuals = self.y_test - self.y_test_pred
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ—Å—Ç–∞—Ç–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
            if np.any(np.isnan(self.train_residuals)) or np.any(np.isnan(self.test_residuals)):
                st.warning("‚ö†Ô∏è –í –æ—Å—Ç–∞—Ç–∫–∞—Ö –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã NaN –∑–Ω–∞—á–µ–Ω–∏—è. –ó–∞–º–µ–Ω—è–µ–º –∏—Ö –Ω–∞ 0.")
                self.train_residuals = np.nan_to_num(self.train_residuals, nan=0.0)
                self.test_residuals = np.nan_to_num(self.test_residuals, nan=0.0)
            
            return True
            
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {str(e)}")
            import traceback
            st.code(traceback.format_exc())
            return False
    
    def get_model_parameters(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏"""
        
        if self.model is None:
            return {}
        
        try:
            params = {}
            
            # –î–ª—è sklearn –º–æ–¥–µ–ª–µ–π
            if hasattr(self.model, 'get_params'):
                params = self.model.get_params()
            
            # –î–ª—è AutoGluon
            elif self.model_type == 'autogluon':
                params = {'type': 'AutoGluon model'}
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            self.model_params = params
            
            return params
            
        except Exception as e:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏: {str(e)}")
            return {}
    
    def analyze_residuals(self):
        """–ê–Ω–∞–ª–∏–∑ –æ—Å—Ç–∞—Ç–∫–æ–≤ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞"""
        if self.train_residuals is None:
            if not self.calculate_predictions_and_residuals():
                return None
        
        analysis = {
            'train_mean': float(np.mean(self.train_residuals)),
            'train_std': float(np.std(self.train_residuals)),
            'train_skew': float(stats.skew(self.train_residuals)),
            'train_kurtosis': float(stats.kurtosis(self.train_residuals)),
            'test_mean': float(np.mean(self.test_residuals)),
            'test_std': float(np.std(self.test_residuals)),
            'test_skew': float(stats.skew(self.test_residuals)),
            'test_kurtosis': float(stats.kurtosis(self.test_residuals)),
        }
        
        # –¢–µ—Å—Ç—ã –Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å
        if len(self.train_residuals) <= 5000:
            try:
                analysis['train_shapiro_p'] = float(stats.shapiro(self.train_residuals)[1])
            except:
                analysis['train_shapiro_p'] = np.nan
        else:
            analysis['train_shapiro_p'] = np.nan
            
        if len(self.test_residuals) <= 5000:
            try:
                analysis['test_shapiro_p'] = float(stats.shapiro(self.test_residuals)[1])
            except:
                analysis['test_shapiro_p'] = np.nan
        else:
            analysis['test_shapiro_p'] = np.nan
        
        return analysis
    
    def stationarity_tests(self):
        """–¢–µ—Å—Ç—ã –Ω–∞ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å –æ—Å—Ç–∞—Ç–∫–æ–≤"""
        if self.train_residuals is None:
            return None
        
        results = {}
        
        try:
            # ADF —Ç–µ—Å—Ç (—Ç–µ—Å—Ç –î–∏–∫–∏-–§—É–ª–ª–µ—Ä–∞)
            adf_test = adfuller(self.train_residuals.dropna())
            results['adf'] = {
                'statistic': float(adf_test[0]),
                'p_value': float(adf_test[1]),
                'critical_values': {k: float(v) for k, v in adf_test[4].items()},
                'stationary': adf_test[1] < 0.05
            }
        except Exception as e:
            results['adf'] = {'error': str(e)}
        
        try:
            # KPSS —Ç–µ—Å—Ç
            kpss_test = kpss(self.train_residuals.dropna(), regression='c', nlags='auto')
            results['kpss'] = {
                'statistic': float(kpss_test[0]),
                'p_value': float(kpss_test[1]),
                'critical_values': {k: float(v) for k, v in kpss_test[3].items()},
                'stationary': kpss_test[1] > 0.05
            }
        except Exception as e:
            results['kpss'] = {'error': str(e)}
        
        self.adf_results = results.get('adf')
        self.kpss_results = results.get('kpss')
        
        return results
    
    def calculate_feature_importance(self):
        """–†–∞—Å—á–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        
        if self.model is None or self.model_type == 'strategy':
            self.feature_importance = pd.DataFrame({
                'feature': ['–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'],
                'importance': [0],
                'note': ['–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤']
            })
            return self.feature_importance
        
        try:
            # –î–ª—è –º–æ–¥–µ–ª–µ–π —Å –∞—Ç—Ä–∏–±—É—Ç–æ–º feature_importances_
            if hasattr(self.model, 'feature_importances_'):
                importances = self.model.feature_importances_
                self.feature_importance = pd.DataFrame({
                    'feature': self.X_train.columns,
                    'importance': importances
                }).sort_values('importance', ascending=False)
                
            # –î–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞–º–∏
            elif hasattr(self.model, 'coef_'):
                coef = self.model.coef_
                if len(coef.shape) > 1:
                    coef = coef[0]
                
                self.feature_importance = pd.DataFrame({
                    'feature': self.X_train.columns,
                    'importance': np.abs(coef)
                }).sort_values('importance', ascending=False)
                
            # –î–ª—è SHAP –∞–Ω–∞–ª–∏–∑–∞
            elif SHAP_AVAILABLE and self.model_type != 'autogluon':
                try:
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º NaN –¥–ª—è SHAP
                    X_train_clean = self.X_train.fillna(self.X_train.median())
                    explainer = shap.Explainer(self.model)
                    shap_values = explainer(X_train_clean)
                    
                    shap_values_abs = np.abs(shap_values.values)
                    self.feature_importance = pd.DataFrame({
                        'feature': self.X_train.columns,
                        'importance': shap_values_abs.mean(axis=0)
                    }).sort_values('importance', ascending=False)
                    
                    self.shap_values = shap_values
                    
                except Exception as e:
                    st.warning(f"SHAP –∞–Ω–∞–ª–∏–∑ –Ω–µ —É–¥–∞–ª—Å—è: {str(e)}")
                    self._calculate_correlation_importance()
            
            # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç: –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è
            else:
                self._calculate_correlation_importance()
            
            return self.feature_importance
            
        except Exception as e:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {str(e)}")
            self._calculate_correlation_importance()
            return self.feature_importance
    
    def _calculate_correlation_importance(self):
        """–†–∞—Å—á–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é"""
        try:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º NaN –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
            X_train_clean = self.X_train.fillna(self.X_train.median())
            y_train_clean = self.y_train.fillna(self.y_train.median())
            
            correlations = []
            for col in X_train_clean.columns:
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ NaN
                    mask = X_train_clean[col].notna() & y_train_clean.notna()
                    if mask.sum() > 1:  # –ù—É–∂–Ω–æ –∫–∞–∫ –º–∏–Ω–∏–º—É–º 2 —Ç–æ—á–∫–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
                        corr = np.corrcoef(X_train_clean.loc[mask, col], y_train_clean[mask])[0, 1]
                        correlations.append(abs(corr) if not np.isnan(corr) else 0)
                    else:
                        correlations.append(0)
                except:
                    correlations.append(0)
            
            self.feature_importance = pd.DataFrame({
                'feature': self.X_train.columns,
                'importance': correlations,
                'note': ['–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Å —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π']
            }).sort_values('importance', ascending=False)
            
        except Exception as e:
            self.feature_importance = pd.DataFrame({
                'feature': ['–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å'],
                'importance': [0],
                'note': [f'–û—à–∏–±–∫–∞: {str(e)[:50]}']
            })
    
    def calculate_confidence_intervals(self, alpha=0.05):
        """–†–∞—Å—á–µ—Ç –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤"""
        if self.y_test_pred is None:
            if not self.calculate_predictions_and_residuals():
                return None
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–æ–≤
            residual_std = np.std(self.train_residuals)
            
            # Z-–∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞
            z_value = stats.norm.ppf(1 - alpha/2)
            
            # –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
            lower_bound = self.y_test_pred - z_value * residual_std
            upper_bound = self.y_test_pred + z_value * residual_std
            
            coverage = np.mean((self.y_test >= lower_bound) & (self.y_test <= upper_bound))
            
            return {
                'lower_bound': lower_bound,
                'upper_bound': upper_bound,
                'coverage': float(coverage),
                'expected_coverage': 1 - alpha,
                'residual_std': float(residual_std)
            }
        except Exception as e:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã: {str(e)}")
            return None
    
    def find_error_patterns(self, window_size=7):
        """–ü–æ–∏—Å–∫ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤ –æ—à–∏–±–∫–∞—Ö"""
        if self.test_residuals is None:
            if not self.calculate_predictions_and_residuals():
                return None
        
        try:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º NaN –≤ –æ—Å—Ç–∞—Ç–∫–∞—Ö
            residuals_series = pd.Series(self.test_residuals).fillna(0)
            
            patterns = {
                'max_error': float(residuals_series.abs().max()),
                'max_error_idx': int(residuals_series.abs().idxmax()),
                'mean_abs_error': float(residuals_series.abs().mean()),
            }
            
            # –ê–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –æ—à–∏–±–æ–∫
            if len(residuals_series) > 1:
                patterns['error_autocorrelation'] = float(residuals_series.autocorr())
            else:
                patterns['error_autocorrelation'] = 0.0
            
            # –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ—à–∏–±–æ–∫
            if len(residuals_series) >= window_size:
                rolling_mean = residuals_series.abs().rolling(window=window_size).mean()
                patterns['worst_period_start'] = int(rolling_mean.idxmax())
                patterns['worst_period_value'] = float(rolling_mean.max())
            else:
                patterns['worst_period_start'] = 0
                patterns['worst_period_value'] = 0.0
            
            return patterns
        except Exception as e:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ—à–∏–±–æ–∫: {str(e)}")
            return None

# ============================================================
# –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–ò (–û–ë–ù–û–í–õ–ï–ù–ù–´–ï)
# ============================================================

def plot_residuals_analysis_enhanced(diagnostics):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤ –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏"""
    if diagnostics.train_residuals is None:
        return None
    
    fig = make_subplots(
        rows=2, cols=3,
        subplot_titles=['–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤', 'QQ-plot –æ—Å—Ç–∞—Ç–∫–æ–≤', 
                       '–ê–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –æ—Å—Ç–∞—Ç–∫–æ–≤', '–û—Å—Ç–∞—Ç–∫–∏ vs –ü—Ä–æ–≥–Ω–æ–∑',
                       '–û—Å—Ç–∞—Ç–∫–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–∏', '–ù–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –æ—Å—Ç–∞—Ç–∫–∏'],
        specs=[[{'type': 'histogram'}, {'type': 'scatter'}, {'type': 'bar'}],
               [{'type': 'scatter'}, {'type': 'scatter'}, {'type': 'scatter'}]],
        vertical_spacing=0.1,
        horizontal_spacing=0.1
    )
    
    # 1. –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤
    fig.add_trace(
        go.Histogram(
            x=diagnostics.train_residuals,
            name='–û—Å—Ç–∞—Ç–∫–∏',
            nbinsx=50,
            marker_color='lightblue',
            opacity=0.7
        ),
        row=1, col=1
    )
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    try:
        mu, sigma = diagnostics.train_residuals.mean(), diagnostics.train_residuals.std()
        x_norm = np.linspace(diagnostics.train_residuals.min(), diagnostics.train_residuals.max(), 100)
        y_norm = stats.norm.pdf(x_norm, mu, sigma) * len(diagnostics.train_residuals) * (diagnostics.train_residuals.max() - diagnostics.train_residuals.min()) / 50
        
        fig.add_trace(
            go.Scatter(
                x=x_norm,
                y=y_norm,
                mode='lines',
                name='–ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ',
                line=dict(color='red', width=2),
                showlegend=False
            ),
            row=1, col=1
        )
    except:
        pass
    
    # 2. QQ-plot
    try:
        # –£–±–∏—Ä–∞–µ–º NaN –¥–ª—è QQ-plot
        residuals_clean = diagnostics.train_residuals[~np.isnan(diagnostics.train_residuals)]
        qq = stats.probplot(residuals_clean, dist="norm")
        theoretical_q = qq[0][0]
        sample_q = qq[0][1]
        
        fig.add_trace(
            go.Scatter(
                x=theoretical_q,
                y=sample_q,
                mode='markers',
                name='QQ-plot',
                marker=dict(color='red', size=5, opacity=0.6)
            ),
            row=1, col=2
        )
        
        # –õ–∏–Ω–∏—è –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        min_val = min(theoretical_q.min(), sample_q.min())
        max_val = max(theoretical_q.max(), sample_q.max())
        fig.add_trace(
            go.Scatter(
                x=[min_val, max_val],
                y=[min_val, max_val],
                mode='lines',
                name='–ò–¥–µ–∞–ª—å–Ω–∞—è –ª–∏–Ω–∏—è',
                line=dict(color='black', dash='dash', width=2),
                showlegend=False
            ),
            row=1, col=2
        )
    except:
        pass
    
    # 3. –ê–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –æ—Å—Ç–∞—Ç–∫–æ–≤
    try:
        # –£–±–∏—Ä–∞–µ–º NaN –¥–ª—è ACF
        residuals_clean = diagnostics.train_residuals[~np.isnan(diagnostics.train_residuals)]
        acf_values = acf(residuals_clean, nlags=20, fft=False)
        fig.add_trace(
            go.Bar(
                x=list(range(len(acf_values))),
                y=acf_values,
                name='ACF',
                marker_color='orange',
                opacity=0.7
            ),
            row=1, col=3
        )
        
        # –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
        conf_int = 1.96 / np.sqrt(len(residuals_clean))
        fig.add_trace(
            go.Scatter(
                x=[-1, len(acf_values)],
                y=[conf_int, conf_int],
                mode='lines',
                line=dict(color='gray', dash='dash', width=1),
                showlegend=False
            ),
            row=1, col=3
        )
        fig.add_trace(
            go.Scatter(
                x=[-1, len(acf_values)],
                y=[-conf_int, -conf_int],
                mode='lines',
                line=dict(color='gray', dash='dash', width=1),
                showlegend=False
            ),
            row=1, col=3
        )
    except:
        pass
    
    # 4. –û—Å—Ç–∞—Ç–∫–∏ vs –ü—Ä–æ–≥–Ω–æ–∑
    fig.add_trace(
        go.Scatter(
            x=diagnostics.y_train_pred,
            y=diagnostics.train_residuals,
            mode='markers',
            name='–û—Å—Ç–∞—Ç–∫–∏ vs –ü—Ä–æ–≥–Ω–æ–∑',
            marker=dict(color='green', size=5, opacity=0.6)
        ),
        row=2, col=1
    )
    
    # –ù—É–ª–µ–≤–∞—è –ª–∏–Ω–∏—è
    fig.add_trace(
        go.Scatter(
            x=[diagnostics.y_train_pred.min(), diagnostics.y_train_pred.max()],
            y=[0, 0],
            mode='lines',
            line=dict(color='black', dash='dash', width=2),
            showlegend=False
        ),
        row=2, col=1
    )
    
    # 5. –û—Å—Ç–∞—Ç–∫–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–∏
    fig.add_trace(
        go.Scatter(
            x=list(range(len(diagnostics.train_residuals))),
            y=diagnostics.train_residuals,
            mode='lines',
            name='–û—Å—Ç–∞—Ç–∫–∏ –≤–æ –≤—Ä–µ–º–µ–Ω–∏',
            line=dict(color='blue', width=1)
        ),
        row=2, col=2
    )
    
    # 6. –ù–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –æ—Å—Ç–∞—Ç–∫–∏
    cumulative_residuals = np.cumsum(diagnostics.train_residuals)
    fig.add_trace(
        go.Scatter(
            x=list(range(len(cumulative_residuals))),
            y=cumulative_residuals,
            mode='lines',
            name='–ù–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –æ—Å—Ç–∞—Ç–∫–∏',
            line=dict(color='purple', width=2)
        ),
        row=2, col=3
    )
    
    # –ù—É–ª–µ–≤–∞—è –ª–∏–Ω–∏—è –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã—Ö –æ—Å—Ç–∞—Ç–∫–æ–≤
    fig.add_trace(
        go.Scatter(
            x=[0, len(cumulative_residuals)],
            y=[0, 0],
            mode='lines',
            line=dict(color='black', dash='dash', width=1),
            showlegend=False
        ),
        row=2, col=3
    )
    
    fig.update_layout(
        height=800,
        title_text=f"–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤: {diagnostics.model_name}",
        title_x=0.5,
        showlegend=False,
        template='plotly_white'
    )
    
    return fig

# ============================================================
# –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–° –î–õ–Ø STREAMLIT (–ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô)
# ============================================================

def show_model_diagnostics_interface_enhanced():
    """–û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –≠—Ç–∞–ø–∞ 6: –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–µ–π —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –∏–∑ 5 —ç—Ç–∞–ø–∞"""
    
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —ç—Ç–∞–ø–æ–≤
    if 'df_features' not in st.session_state or 'feature_info' not in st.session_state or 'split_data' not in st.session_state:
        st.error("‚ùå –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –≠—Ç–∞–ø—ã 1-2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫—É –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ")
        return
    
    # –ü–æ–ª—É—á–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –∏–∑ 5 —ç—Ç–∞–ø–∞
    best_model_info, integrated_results, integrated_df = extract_model_from_integrated_results()
    
    if best_model_info is None:
        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏")
        return
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
    feature_info = st.session_state.feature_info
    split_data = st.session_state.split_data
    
    X_train, y_train, X_test, y_test, feature_cols = prepare_data_for_diagnostics(feature_info, split_data)
    
    if X_train is None:
        st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏")
        return
    
    # === –û–¢–õ–ê–î–û–ß–ù–ê–Ø –ö–ù–û–ü–ö–ê –î–õ–Ø –ü–†–û–í–ï–†–ö–ò –î–ê–ù–ù–´–• ===
    if st.checkbox("üîç –ü–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö", value=False):
        st.write("### –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö:")
        
        col1, col2 = st.columns(2)
        with col1:
            st.write("**X_train:**")
            st.write(f"–†–∞–∑–º–µ—Ä: {X_train.shape}")
            st.write(f"–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö: {X_train.dtypes.unique()}")
            st.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ NaN: {X_train.isna().sum().sum()}")
            st.write("–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:")
            st.dataframe(X_train.head())
        
        with col2:
            st.write("**X_test:**")
            st.write(f"–†–∞–∑–º–µ—Ä: {X_test.shape}")
            st.write(f"–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö: {X_test.dtypes.unique()}")
            st.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ NaN: {X_test.isna().sum().sum()}")
            st.write("–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:")
            st.dataframe(X_test.head())
        
        st.write("**y_train:**")
        st.write(f"–†–∞–∑–º–µ—Ä: {y_train.shape}")
        st.write(f"–¢–∏–ø: {y_train.dtype}")
        st.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ NaN: {y_train.isna().sum()}")
        st.write(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: min={y_train.min():.4f}, max={y_train.max():.4f}, mean={y_train.mean():.4f}")
        
        st.write("**y_test:**")
        st.write(f"–†–∞–∑–º–µ—Ä: {y_test.shape}")
        st.write(f"–¢–∏–ø: {y_test.dtype}")
        st.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ NaN: {y_test.isna().sum()}")
        st.write(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: min={y_test.min():.4f}, max={y_test.max():.4f}, mean={y_test.mean():.4f}")
    
    # –ü–æ–ª—É—á–∞–µ–º –æ–±—ä–µ–∫—Ç –º–æ–¥–µ–ª–∏
    model_object, model_type = get_model_object(best_model_info, integrated_results)
    
    st.info(f"""
    **üìã –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –∏–∑ –≠—Ç–∞–ø–∞ 5:**
    
    **–ú–æ–¥–µ–ª—å:** {best_model_info['–ù–∞–∑–≤–∞–Ω–∏–µ']}
    **–¢–∏–ø:** {best_model_info['–¢–∏–ø']}
    **MAE:** {best_model_info['MAE']:.4f}
    **–ü–æ–¥—Ö–æ–¥:** {best_model_info['–ü–æ–¥—Ö–æ–¥']}
    
    **–î–∞–Ω–Ω—ã–µ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏:**
    - –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_train)} –∑–∞–ø–∏—Å–µ–π
    - –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_test)} –∑–∞–ø–∏—Å–µ–π
    - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feature_cols)}
    """)
    
    # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
    diagnostics = ModelDiagnosticsEnhanced(
        model=model_object,
        X_train=X_train,
        y_train=y_train,
        X_test=X_test,
        y_test=y_test,
        model_name=best_model_info['–ù–∞–∑–≤–∞–Ω–∏–µ'],
        model_type=model_type
    )
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º —Ä–∞—Å—á–µ—Ç—ã
    with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ–º –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É –º–æ–¥–µ–ª–∏..."):
        success = diagnostics.calculate_predictions_and_residuals()
        if not success:
            st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏")
            return
        
        residuals_analysis = diagnostics.analyze_residuals()
        stationarity_results = diagnostics.stationarity_tests()
        feature_importance = diagnostics.calculate_feature_importance()
        model_params = diagnostics.get_model_parameters()
    
    st.success("‚úÖ –ë–∞–∑–æ–≤–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
    st.subheader("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏")
    
    col1, col2 = st.columns(2)
    
    with col1:
        include_residuals = st.checkbox("üìà –ê–Ω–∞–ª–∏–∑ –æ—Å—Ç–∞—Ç–∫–æ–≤", value=True)
        include_stationarity = st.checkbox("üìä –¢–µ—Å—Ç—ã –Ω–∞ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å", value=True)
        include_ci = st.checkbox("üéØ –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã", value=True)
    
    with col2:
        if model_type != 'strategy':
            include_feature_importance = st.checkbox("üîù –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", value=True)
            include_error_patterns = st.checkbox("‚ö†Ô∏è –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫", value=True)
        else:
            include_feature_importance = False
            include_error_patterns = False
    
    # –î–ª—è SHAP –∏ PDP
    advanced_options = st.expander("‚ö° –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –æ–ø—Ü–∏–∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏")
    
    with advanced_options:
        col1, col2 = st.columns(2)
        with col1:
            include_shap = st.checkbox("SHAP –∞–Ω–∞–ª–∏–∑", value=False) and SHAP_AVAILABLE and model_type not in ['strategy', 'autogluon']
        with col2:
            include_pdp = st.checkbox("–ß–∞—Å—Ç–∏—á–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (PDP)", value=False) and PDP_AVAILABLE and model_type not in ['strategy', 'autogluon']
    
    st.markdown("---")
    
    # –°–æ–∑–¥–∞–µ–º –≤–∫–ª–∞–¥–∫–∏ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
    tab_names = []
    if include_residuals:
        tab_names.append("üìà –ê–Ω–∞–ª–∏–∑ –æ—Å—Ç–∞—Ç–∫–æ–≤")
    if include_stationarity:
        tab_names.append("üìä –°—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å")
    if include_feature_importance:
        tab_names.append("üîù –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    if include_ci:
        tab_names.append("üéØ –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã")
    if include_error_patterns:
        tab_names.append("‚ö†Ô∏è –ü–∞—Ç—Ç–µ—Ä–Ω—ã –æ—à–∏–±–æ–∫")
    if include_shap:
        tab_names.append("üéØ SHAP –∞–Ω–∞–ª–∏–∑")
    if include_pdp:
        tab_names.append("üìê –ß–∞—Å—Ç–∏—á–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏")
    
    if not tab_names:
        st.warning("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ç–∏–ø –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏")
        return
    
    tabs = st.tabs(tab_names)
    tab_idx = 0
    
    # 1. –ê–Ω–∞–ª–∏–∑ –æ—Å—Ç–∞—Ç–∫–æ–≤
    if include_residuals:
        with tabs[tab_idx]:
            st.subheader("üìà –ê–Ω–∞–ª–∏–∑ –æ—Å—Ç–∞—Ç–∫–æ–≤ –º–æ–¥–µ–ª–∏")
            
            fig_residuals = plot_residuals_analysis_enhanced(diagnostics)
            if fig_residuals:
                st.plotly_chart(fig_residuals, use_container_width=True)
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤
            if residuals_analysis:
                st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤")
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("–°—Ä–µ–¥–Ω–µ–µ", f"{residuals_analysis['train_mean']:.4f}")
                with col2:
                    st.metric("–°—Ç–¥. –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ", f"{residuals_analysis['train_std']:.4f}")
                with col3:
                    st.metric("–°–∫–æ—à–µ–Ω–Ω–æ—Å—Ç—å", f"{residuals_analysis['train_skew']:.4f}")
                with col4:
                    st.metric("–≠–∫—Å—Ü–µ—Å—Å", f"{residuals_analysis['train_kurtosis']:.4f}")
                
                # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
                st.info(f"""
                **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –æ—Å—Ç–∞—Ç–∫–æ–≤ –¥–ª—è {best_model_info['–ù–∞–∑–≤–∞–Ω–∏–µ']}:**
                
                - **–°—Ä–µ–¥–Ω–µ–µ ‚âà 0**: –º–æ–¥–µ–ª—å –Ω–µ –∏–º–µ–µ—Ç —Å–∏—Å—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–∏
                - **–ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ**: p-–∑–Ω–∞—á–µ–Ω–∏–µ —Ç–µ—Å—Ç–∞ –®–∞–ø–∏—Ä–æ-–í–∏–ª–∫–∞: {residuals_analysis.get('train_shapiro_p', 'N/A'):.4f}
                - **–°–∫–æ—à–µ–Ω–Ω–æ—Å—Ç—å ‚âà 0**: –æ—Å—Ç–∞—Ç–∫–∏ —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã
                - **–≠–∫—Å—Ü–µ—Å—Å ‚âà 3**: –æ—Å—Ç–∞—Ç–∫–∏ –∏–º–µ—é—Ç –Ω–æ—Ä–º–∞–ª—å–Ω—É—é –æ—Å—Ç—Ä–æ—Ç—É –ø–∏–∫–∞
                """)
            
            tab_idx += 1
    
    # 2. –¢–µ—Å—Ç—ã –Ω–∞ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å
    if include_stationarity:
        with tabs[tab_idx]:
            st.subheader("üìä –¢–µ—Å—Ç—ã –Ω–∞ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å –æ—Å—Ç–∞—Ç–∫–æ–≤")
            
            if stationarity_results:
                # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
                results_df = pd.DataFrame([
                    {
                        '–¢–µ—Å—Ç': 'ADF',
                        '–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞': stationarity_results['adf'].get('statistic', np.nan),
                        'P-–∑–Ω–∞—á–µ–Ω–∏–µ': stationarity_results['adf'].get('p_value', np.nan),
                        '–°—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å': '–î–∞' if stationarity_results['adf'].get('stationary', False) else '–ù–µ—Ç'
                    },
                    {
                        '–¢–µ—Å—Ç': 'KPSS', 
                        '–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞': stationarity_results['kpss'].get('statistic', np.nan),
                        'P-–∑–Ω–∞—á–µ–Ω–∏–µ': stationarity_results['kpss'].get('p_value', np.nan),
                        '–°—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å': '–î–∞' if stationarity_results['kpss'].get('stationary', False) else '–ù–µ—Ç'
                    }
                ])
                
                st.dataframe(results_df, width='stretch')
                
                # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
                st.info("""
                **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤ –Ω–∞ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å:**
                
                - **ADF —Ç–µ—Å—Ç (Augmented Dickey-Fuller):**
                  - –ù—É–ª–µ–≤–∞—è –≥–∏–ø–æ—Ç–µ–∑–∞: —Ä—è–¥ –Ω–µ—Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–µ–Ω
                  - p < 0.05: –æ—Ç–≤–µ—Ä–≥–∞–µ–º –Ω—É–ª–µ–≤—É—é –≥–∏–ø–æ—Ç–µ–∑—É, —Ä—è–¥ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–µ–Ω
                
                - **KPSS —Ç–µ—Å—Ç (Kwiatkowski-Phillips-Schmidt-Shin):**
                  - –ù—É–ª–µ–≤–∞—è –≥–∏–ø–æ—Ç–µ–∑–∞: —Ä—è–¥ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–µ–Ω
                  - p > 0.05: –Ω–µ –æ—Ç–≤–µ—Ä–≥–∞–µ–º –Ω—É–ª–µ–≤—É—é –≥–∏–ø–æ—Ç–µ–∑—É, —Ä—è–¥ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–µ–Ω
                
                **–î–ª—è —Ö–æ—Ä–æ—à–µ–π –º–æ–¥–µ–ª–∏:** –æ—Å—Ç–∞—Ç–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã (–±–µ–ª—ã–π —à—É–º)
                """)
            
            tab_idx += 1
    
    # 3. –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    if include_feature_importance:
        with tabs[tab_idx]:
            st.subheader("üîù –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            
            if feature_importance is not None and not feature_importance.empty:
                # –ì—Ä–∞—Ñ–∏–∫ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                fig_importance = go.Figure()
                
                # –ë–µ—Ä–µ–º —Ç–æ–ø-15 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                top_n = min(15, len(feature_importance))
                top_features = feature_importance.head(top_n)
                
                fig_importance.add_trace(go.Bar(
                    x=top_features['importance'],
                    y=top_features['feature'],
                    orientation='h',
                    marker_color='teal',
                    text=top_features['importance'].round(4),
                    textposition='auto'
                ))
                
                fig_importance.update_layout(
                    title=f'–¢–æ–ø-{top_n} –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤',
                    xaxis_title='–í–∞–∂–Ω–æ—Å—Ç—å',
                    yaxis_title='–ü—Ä–∏–∑–Ω–∞–∫',
                    height=500,
                    template='plotly_white'
                )
                
                st.plotly_chart(fig_importance, use_container_width=True)
                
                # –¢–∞–±–ª–∏—Ü–∞ —Å –≤–∞–∂–Ω–æ—Å—Ç—å—é –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                st.subheader("–¢–∞–±–ª–∏—Ü–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
                st.dataframe(feature_importance, width='stretch')
            
            else:
                st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –¥–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")
            
            tab_idx += 1
    
    # 4. –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
    if include_ci:
        with tabs[tab_idx]:
            st.subheader("üéØ –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã")
            
            ci_results = diagnostics.calculate_confidence_intervals()
            
            if ci_results:
                # –ì—Ä–∞—Ñ–∏–∫ —Å –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º–∏
                fig_ci = go.Figure()
                
                # –í—Ä–µ–º–µ–Ω–Ω–∞—è –æ—Å—å
                time_index = list(range(len(diagnostics.y_test)))
                
                # –ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
                fig_ci.add_trace(go.Scatter(
                    x=time_index,
                    y=diagnostics.y_test,
                    mode='lines',
                    name='–ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è',
                    line=dict(color='blue', width=2)
                ))
                
                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                fig_ci.add_trace(go.Scatter(
                    x=time_index,
                    y=diagnostics.y_test_pred,
                    mode='lines',
                    name='–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è',
                    line=dict(color='red', width=2, dash='dash')
                ))
                
                # –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
                fig_ci.add_trace(go.Scatter(
                    x=time_index + time_index[::-1],
                    y=np.concatenate([ci_results['upper_bound'], ci_results['lower_bound'][::-1]]),
                    fill='toself',
                    fillcolor='rgba(128, 128, 128, 0.2)',
                    line=dict(color='rgba(128, 128, 128, 0)'),
                    name='95% –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª',
                    showlegend=True
                ))
                
                coverage_text = f"–ü–æ–∫—Ä—ã—Ç–∏–µ: {ci_results['coverage']:.1%} (–æ–∂–∏–¥–∞–µ—Ç—Å—è: {ci_results['expected_coverage']:.1%})"
                
                fig_ci.update_layout(
                    title=f'–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–º–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞–º–∏<br><sup>{coverage_text}</sup>',
                    xaxis_title='–í—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω–¥–µ–∫—Å',
                    yaxis_title='–ó–Ω–∞—á–µ–Ω–∏–µ',
                    height=500,
                    showlegend=True,
                    template='plotly_white'
                )
                
                st.plotly_chart(fig_ci, use_container_width=True)
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–∫—Ä—ã—Ç–∏—è
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("–§–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ", f"{ci_results['coverage']:.1%}")
                with col2:
                    st.metric("–û–∂–∏–¥–∞–µ–º–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ", f"{ci_results['expected_coverage']:.1%}")
            
            else:
                st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã")
            
            tab_idx += 1
    
    # 5. –ü–∞—Ç—Ç–µ—Ä–Ω—ã –æ—à–∏–±–æ–∫
    if include_error_patterns:
        with tabs[tab_idx]:
            st.subheader("‚ö†Ô∏è –ü–∞—Ç—Ç–µ—Ä–Ω—ã –æ—à–∏–±–æ–∫")
            
            error_patterns = diagnostics.find_error_patterns()
            
            if error_patterns:
                # –ì—Ä–∞—Ñ–∏–∫–∏ –æ—à–∏–±–æ–∫
                fig_errors = make_subplots(
                    rows=2, cols=2,
                    subplot_titles=['–ê–±—Å–æ–ª—é—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏', '–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫',
                                   '–ù–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏', '–ê–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –æ—à–∏–±–æ–∫'],
                    specs=[[{'type': 'scatter'}, {'type': 'histogram'}],
                           [{'type': 'scatter'}, {'type': 'bar'}]]
                )
                
                # –ê–±—Å–æ–ª—é—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏
                abs_errors = np.abs(diagnostics.test_residuals)
                fig_errors.add_trace(
                    go.Scatter(
                        x=list(range(len(abs_errors))),
                        y=abs_errors,
                        mode='lines',
                        name='–ê–±—Å–æ–ª—é—Ç–Ω—ã–µ –æ—à–∏–±–∫–∏',
                        line=dict(color='orange', width=1)
                    ),
                    row=1, col=1
                )
                
                # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫
                fig_errors.add_trace(
                    go.Histogram(
                        x=diagnostics.test_residuals,
                        name='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫',
                        nbinsx=30,
                        marker_color='lightgreen',
                        opacity=0.7
                    ),
                    row=1, col=2
                )
                
                # –ù–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏
                cumulative_errors = np.cumsum(diagnostics.test_residuals)
                fig_errors.add_trace(
                    go.Scatter(
                        x=list(range(len(cumulative_errors))),
                        y=cumulative_errors,
                        mode='lines',
                        name='–ù–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏',
                        line=dict(color='purple', width=2)
                    ),
                    row=2, col=1
                )
                
                # –ê–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –æ—à–∏–±–æ–∫
                try:
                    acf_errors = acf(diagnostics.test_residuals, nlags=20, fft=False)
                    fig_errors.add_trace(
                        go.Bar(
                            x=list(range(len(acf_errors))),
                            y=acf_errors,
                            name='–ê–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è',
                            marker_color='blue',
                            opacity=0.7
                        ),
                        row=2, col=2
                    )
                except:
                    pass
                
                fig_errors.update_layout(
                    height=600,
                    title_text="–ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –æ—à–∏–±–æ–∫",
                    title_x=0.5,
                    showlegend=False,
                    template='plotly_white'
                )
                
                st.plotly_chart(fig_errors, use_container_width=True)
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—à–∏–±–æ–∫
                st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—à–∏–±–æ–∫")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞", f"{error_patterns['max_error']:.4f}")
                with col2:
                    st.metric("–°—Ä–µ–¥–Ω—è—è –∞–±—Å. –æ—à–∏–±–∫–∞", f"{error_patterns['mean_abs_error']:.4f}")
                with col3:
                    st.metric("–ê–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è", f"{error_patterns['error_autocorrelation']:.4f}")
            
            else:
                st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ—à–∏–±–æ–∫")
            
            tab_idx += 1
    
    # 6. SHAP –∞–Ω–∞–ª–∏–∑
    if include_shap and SHAP_AVAILABLE:
        with tabs[tab_idx]:
            st.subheader("üéØ SHAP –∞–Ω–∞–ª–∏–∑")
            
            try:
                if diagnostics.shap_values is None:
                    with st.spinner("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è SHAP –∞–Ω–∞–ª–∏–∑..."):
                        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º NaN –¥–ª—è SHAP
                        X_train_clean = diagnostics.X_train.fillna(diagnostics.X_train.median())
                        explainer = shap.Explainer(diagnostics.model)
                        diagnostics.shap_values = explainer(X_train_clean)
                
                if diagnostics.shap_values is not None:
                    # Summary plot
                    st.info("SHAP summary plot –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑")
                    
                    fig, ax = plt.subplots(figsize=(10, 8))
                    shap.summary_plot(
                        diagnostics.shap_values,
                        X_train_clean,
                        plot_type="dot",
                        show=False,
                        max_display=15
                    )
                    
                    st.pyplot(fig)
                    
                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                    st.info("""
                    **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è SHAP:**
                    - **–í—ã—Å–æ—Ç–∞ —Å—Ç–æ–ª–±—Ü–∞**: –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∞
                    - **–¶–≤–µ—Ç —Ç–æ—á–µ–∫**: –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞ (–∫—Ä–∞—Å–Ω—ã–π - –≤—ã—Å–æ–∫–æ–µ, —Å–∏–Ω–∏–π - –Ω–∏–∑–∫–æ–µ)
                    - **–†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ —Ç–æ—á–µ–∫**: –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑ (–ø—Ä–∞–≤–æ - —É–≤–µ–ª–∏—á–µ–Ω–∏–µ, –ª–µ–≤–æ - —É–º–µ–Ω—å—à–µ–Ω–∏–µ)
                    """)
                    
            except Exception as e:
                st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å SHAP –∞–Ω–∞–ª–∏–∑: {str(e)}")
            
            tab_idx += 1
    
    # 7. –ß–∞—Å—Ç–∏—á–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (PDP)
    if include_pdp and PDP_AVAILABLE:
        with tabs[tab_idx]:
            st.subheader("üìê –ß–∞—Å—Ç–∏—á–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (PDP)")
            
            # –í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è PDP
            if feature_importance is not None and not feature_importance.empty:
                top_features = feature_importance['feature'].head(10).tolist()
                
                selected_features = st.multiselect(
                    "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —á–∞—Å—Ç–∏—á–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π",
                    options=top_features,
                    default=top_features[:3] if len(top_features) >= 3 else top_features
                )
                
                if selected_features and diagnostics.model is not None:
                    try:
                        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º NaN –¥–ª—è PDP
                        X_train_clean = diagnostics.X_train.fillna(diagnostics.X_train.median())
                        
                        fig, ax = plt.subplots(len(selected_features), 1, 
                                              figsize=(10, 4 * len(selected_features)))
                        
                        if len(selected_features) == 1:
                            ax = [ax]
                        
                        for i, feature in enumerate(selected_features):
                            PartialDependenceDisplay.from_estimator(
                                diagnostics.model,
                                X_train_clean,
                                [feature],
                                ax=ax[i],
                                grid_resolution=20
                            )
                            ax[i].set_title(f'–ß–∞—Å—Ç–∏—á–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å: {feature}')
                            ax[i].set_xlabel(feature)
                            ax[i].set_ylabel('–í–ª–∏—è–Ω–∏–µ –Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑')
                        
                        plt.tight_layout()
                        st.pyplot(fig)
                        
                        st.info("""
                        **–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è PDP:**
                        - **–§–æ—Ä–º–∞ –∫—Ä–∏–≤–æ–π**: –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞–∫ –∏–∑–º–µ–Ω—è–µ—Ç—Å—è –ø—Ä–æ–≥–Ω–æ–∑ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞
                        - **–ù–∞–∫–ª–æ–Ω**: —Å–∏–ª–∞ –≤–ª–∏—è–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–∞
                        - **–ù–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å**: –∫—Ä–∏–≤–∞—è –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤–ª–∏—è–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞ –ø—Ä–∏ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥—Ä—É–≥–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
                        """)
                        
                    except Exception as e:
                        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏ PDP: {str(e)}")
                
                else:
                    st.info("–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —á–∞—Å—Ç–∏—á–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π")
            
            else:
                st.info("–°–Ω–∞—á–∞–ª–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            
            tab_idx += 1
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
    st.session_state.diagnostics_results = {
        'diagnostics': diagnostics,
        'best_model_info': best_model_info,
        'model_params': model_params
    }
    
    st.markdown("---")
    
    # –ó–∞–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    st.subheader("üéØ –í—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.info(f"""
        **–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ {best_model_info['–ù–∞–∑–≤–∞–Ω–∏–µ']}:**
        
        - **–¢–∏–ø –º–æ–¥–µ–ª–∏:** {best_model_info['–¢–∏–ø']}
        - **MAE –Ω–∞ —Ç–µ—Å—Ç–µ:** {best_model_info['MAE']:.4f}
        - **–°—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å –æ—Å—Ç–∞—Ç–∫–æ–≤:** {'–î–∞' if diagnostics.adf_results and diagnostics.adf_results.get('stationary', False) else '–ù–µ—Ç'}
        - **–ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏:** {'–•–æ—Ä–æ—à–µ–µ' if residuals_analysis and abs(residuals_analysis['train_mean']) < 0.1 else '–¢—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è'}
        """)
    
    with col2:
        st.info("""
        **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é:**
        
        1. **–î–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏:** —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –∞–Ω—Å–∞–º–±–ª–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã
        2. **–î–ª—è —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç–∏:** –ø—Ä–∏–º–µ–Ω–∏—Ç–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ –∫ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        3. **–î–ª—è –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:** —Å—Ñ–æ–∫—É—Å–∏—Ä—É–π—Ç–µ—Å—å –Ω–∞ —Ç–æ–ø-5 –Ω–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        4. **–î–ª—è –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤:** —É–≤–µ–ª–∏—á—å—Ç–µ –æ–±—ä–µ–º –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        """)
    
    st.success(f"""
    **‚úÖ –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –º–æ–¥–µ–ª–∏ {best_model_info['–ù–∞–∑–≤–∞–Ω–∏–µ']} –∑–∞–≤–µ—Ä—à–µ–Ω–∞!**
    
    **–ß—Ç–æ –±—ã–ª–æ —Å–¥–µ–ª–∞–Ω–æ:**
    1. –ü—Ä–æ–≤–µ–¥–µ–Ω –∞–Ω–∞–ª–∏–∑ –æ—Å—Ç–∞—Ç–∫–æ–≤ –º–æ–¥–µ–ª–∏
    2. –í—ã–ø–æ–ª–Ω–µ–Ω—ã —Ç–µ—Å—Ç—ã –Ω–∞ —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω–æ—Å—Ç—å
    3. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    4. –†–∞—Å—Å—á–∏—Ç–∞–Ω—ã –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
    5. –í—ã—è–≤–ª–µ–Ω—ã –ø–∞—Ç—Ç–µ—Ä–Ω—ã –æ—à–∏–±–æ–∫
    
    **–¢–µ–ø–µ—Ä—å —É –≤–∞—Å –µ—Å—Ç—å –ø–æ–ª–Ω–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏!**
    """)

# ============================================================
# –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# ============================================================

def show_model_diagnostics_interface():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏"""
    
    
    # –û–¢–õ–ê–î–û–ß–ù–´–ô –í–´–í–û–î –í –ö–û–ù–°–û–õ–¨ (–ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ)
    import sys
    print("\n" + "="*50, file=sys.stderr)
    print("[DEBUG] –ù–ê–ß–ê–õ–û –≠–¢–ê–ü–ê 6 - –ü–†–û–í–ï–†–ö–ê –î–ê–ù–ù–´–•", file=sys.stderr)
    print(f"[DEBUG] –í—Å–µ–≥–æ –∫–ª—é—á–µ–π –≤ session_state: {len(st.session_state)}", file=sys.stderr)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö 5 —ç—Ç–∞–ø–∞ (–≤—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –∫–ª—é—á–∏)
    stage5_keys = ['integrated_results', 'advanced_modeling_data', 'model_comparison_results']
    has_stage5_data = any(key in st.session_state for key in stage5_keys)
    
    if not has_stage5_data:
        st.error("""
        ‚ùå **–ù–µ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã –≠—Ç–∞–ø—ã 3-5!**
        
        **–ß—Ç–æ –Ω–∞–π–¥–µ–Ω–æ –≤ session_state:**
        """)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ –∫–ª—é—á–∏
        keys = list(st.session_state.keys())
        for key in keys:
            val = st.session_state[key]
            st.write(f"- `{key}`: {type(val).__name__}")
            
            # –ï—Å–ª–∏ —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –µ–≥–æ –∫–ª—é—á–∏
            if isinstance(val, dict):
                st.write(f"  –ö–ª—é—á–∏ –≤ —Å–ª–æ–≤–∞—Ä–µ: {list(val.keys())[:5]}{'...' if len(val) > 5 else ''}")
        
        st.write("""
        **–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å:**
        1. **–≠—Ç–∞–ø 3:** –ü–æ–¥–±–æ—Ä ML –º–æ–¥–µ–ª–µ–π –∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        2. **–≠—Ç–∞–ø 4:** –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è  
        3. **–≠—Ç–∞–ø 5:** –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–æ–≤
        
        **–û—Å–æ–±–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ:** –í 5 —ç—Ç–∞–ø–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–¥ –æ–¥–Ω–∏–º –∏–∑ –∫–ª—é—á–µ–π:
        - `integrated_results`
        - `advanced_modeling_data` 
        - `model_comparison_results`
        
        **–ü–æ—Ä—è–¥–æ–∫ –¥–µ–π—Å—Ç–≤–∏–π:**
        1. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≠—Ç–∞–ø 3 ‚Üí –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –ø–æ–¥–±–æ—Ä –º–æ–¥–µ–ª–µ–π
        2. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≠—Ç–∞–ø 4 ‚Üí –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
        3. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ –≠—Ç–∞–ø 5 ‚Üí –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
        4. –í–µ—Ä–Ω–∏—Ç–µ—Å—å –Ω–∞ –≠—Ç–∞–ø 6 ‚Üí –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        """)
        return
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –≠—Ç–∞–ø–æ–≤ 1-2
    required_stage1_2 = ['feature_info', 'split_data']
    missing_stage1_2 = [key for key in required_stage1_2 if key not in st.session_state]
    
    if missing_stage1_2:
        st.error(f"""
        ‚ùå –ù–µ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã –≠—Ç–∞–ø—ã 1-2!
        
        –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ: {', '.join(missing_stage1_2)}
        """)
        return
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
    show_model_diagnostics_interface_enhanced()